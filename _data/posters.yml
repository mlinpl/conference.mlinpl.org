- author-name: Bartosz Marcinkowski
  title: "Towards Semantic Embeddings of Cardiological Signals with Diffusion Autoencoders"
  author-title: "MIM Solutions"
  abstract: >- 
    To support the development of wearable medical devices for remote monitoring and treatment of cardiovascular diseases, we tackle the data scarcity problem that hinders the application of machine learning methods. We propose a self-supervised approach applied to cardiological signals, which benefits from existing datasets despite differences between them and inconsistencies within them. We develop a specific implementation: a diffusion autoencoder with a semantic encoder based on linear recurrent units, trained on ECG signals (various leads mixed together) without any annotations. The semantic encoder is evaluated as a feature extractor by measuring classification metrics of a logistic regression on a dataset not included in the self-supervised training. We obtain promising results and propose future directions.
  author-bio: >- 
    Senior Data Scientist at MIM Solutions, with previous experience at Digital Science and RTB House. University of Warsaw graduate.
  co-authors: Jakub Siuta, Ana Candela Celdran, Mena Nadum, Marek Wachnicki, Jerzy Orłowski
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 1
  author-image: images/optimized/cfc-600x600/bartosz_marcinkowski.webp

- author-name: Grzegorz Rypeść
  title: "Gradient Free Continual Learning"
  author-title: "Warsaw University of Technology, RTB House"
  abstract: >- 
    Continual Learning (CL) seeks to train neural networks on sequential tasks without catastrophic forgetting. A key limitation of existing CL methods is their reliance on gradient-based optimization, which breaks down when data from previous tasks is no longer accessible - a common constraint in CL. In this work, we propose a paradigm shift: we hypothesize that the core issue in catastrophic forgetting is not data unavailability, but the inability to compute gradients for prior tasks. To address this, we introduce EvoCL, a novel gradient-free continual learning framework that leverages Evolution Strategies (ES) for optimization. EvoCL memorizes compressed latent features of past tasks and employs an adapter network to approximate their loss, enabling effective learning without relying on stored exemplars or backpropagation through old data. Our approach achieves promising results under the assumption of low number of trainable parameters and opens up new avenues for data-free and gradient-free continual learning.
  author-bio: >- 
    Grzegorz Rypeść obtained a double master's degree in computer science engineering from the Warsaw University of Technology and Kyungpook National University in Korea. He is currently a PhD student at IDEAS-NCBR and the Warsaw University of Technology, where he focuses on continual learning. He has published as the first author at the most prestigious machine learning conferences such as NeurIPS, ICLR, ECCV, and IJCAI.
  co-authors: 
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 2
  author-image: images/optimized/cfc-600x600/grzegorz_rypesc.webp

- author-name: Piotr Ludynia
  title: "Surpassing Complex Models With Simple Graph Feature Extraction"
  author-title: "AGH University of Kraków"
  abstract: >- 
    Peptides, short chains of amino acids, are crucial targets in drug discovery due to their therapeutic relevance in treating cancer, viral infections, and antibiotic-resistant bacteria. In machine learning, peptide datasets have been widely adopted as benchmarks for studying long-range dependencies in graph-based models, serving as testing grounds for increasingly complex long-range Graph Neural Network (GNN) architectures. We challenge this assumption by evaluating count-based molecular fingerprints across 126 datasets and six diverse benchmarks, including Long Range Graph Benchmark (LRGB), Antimicrobial Peptides (AMP) prediction tasks, and general peptide property benchmarks. We evaluate against GNNs, Graph Transformers, and complex multimodal models.  Molecular fingerprints are domain-specific, short-range feature extraction methods that detect substructure occurrences in molecular graphs. We use count variants of ECFP, Topological Torsion, and RDKit fingerprints, paired with LightGBM classifier, to achieve state-of-the-art performance. Our results show that these inherently local representations outperform complex models explicitly designed to capture long-range interactions, including models with global attention mechanisms.  This finding questions the presumed importance of long-range dependencies in peptide property prediction and demonstrates that simple, efficient models can capture essential biochemical patterns. In addition to improving predictive performance, our approach is highly scalable, requires minimal tuning, and is orders of magnitude faster than deep model training. These results emphasize the need to benchmark novel architectures against strong shallow baselines and reconsider assumptions about the role of long-range interactions in molecular graph learning.
  author-bio: >- 
    Piotr is a fresh master graduate in Machine Learning and Data Science at AGH University of Kraków.  He's a member of AGH ML and Chemoinformatics Group where he conducts research on vectorization methods for graph data. He is also one of the creators and current maintainers of scikit-fingerprints, a molecular fingerprint Python library for efficient molecular vectorization.
  co-authors: Jakub Adamczyk, Wojciech Czech
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 3
  author-image: images/optimized/cfc-600x600/piotr_ludynia.webp

- author-name: Joanna Wiekiera
  title: "Continual learning for satellite data analysis"
  author-title: "KP Labs, Silesian University of Technology"
  abstract: >- 
    Data collected during a space mission can change over time, even slightly, due to factors such as sensor degradation or environmental conditions, potentially impacting model performance. To address these challenges, this work explores continual learning techniques for satellite data analysis, focusing on adapting models to evolving conditions without catastrophic forgetting. We implemented and evaluated state-of-the-art approaches, including regularization-based, replay-based, and architectural methods, under class-incremental scenarios for both telemetry and satellite imagery. Experimental results on benchmark datasets demonstrate improved adaptability and robustness compared to static models. These findings highlight the practical potential of continual learning for reliable AI-driven satellite operations under real mission constraints.
  author-bio: >- 
    Joanna Wiekiera holds a Bachelor’s degree in Computer Science from the Silesian University of Technology and is currently pursuing a Master’s degree in Data Science. She has served as President of the Scientific Student Association Data Science for two years, fostering interdisciplinary collaboration and organizing educational initiatives. Professionally, Joanna works as a Machine Learning Specialist at KP Labs, focusing on AI solutions for space-related applications. Her research interests include continual learning, anomaly detection, and AI for scientific discovery. She is particularly interested in applying AI to scientific challenges, such as those in physics.
  co-authors: 
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 4
  author-image: images/optimized/cfc-600x600/joanna_wiekiera.webp

- author-name: Lucas Sancéré
  title: "Context-aware skin cancer cell classification based on GNNs"
  author-title: "University of Cologne"
  abstract: >- 
    Recent advancements in Graph Neural Networks (GNNs) have enabled classification tasks on data with graph structures. However, few GNN applications exist for large-scale medical data, particularly in handling million-node graphs. Here we develop a graph-based approach to classify cells in large microscopy megapixel images (whole slide images) of skin tumor samples. While there exist megapixel image segmentation methods for cell classification, these methods rely only on local information and fail to correctly classify cells that are morphologically similar but yet functionally different. In skin cancer, tumor cells can only be recognized from healthy skin cells based on their surrounding tissue structure. We encode tissue structure in 113 megapixel images of skin tumors as graphs where each node represents a cell, is characterized by its morphological and spatial features and is labelled according to its cell type. We use an individual tissue sample graph as a separate batch during training and train the network to infer cell types of different nodes in the graph. We compared our context-aware graph-based node classification model to state of the art segmentation model and to other GNNs tailored for large graph node classification tasks.  Our study exemplifies how biological structures and their spatial features can be efficiently encoded as nodes within graphs, enabling GNNs to learn rich representations and perform accurate node-level classification.
  author-bio: >- 
    PhD student in AI applied to Medical Images, Bozek Lab CMMC Cologne Germany. Former Engineer in Curie Institute Paris in the same field. I grew up next to the esteemed corn fields of Les Landes,  south-west France.
  co-authors: Katarzyna Bozek
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 5
  author-image: images/empty.png

- author-name: Eryk Zarębski
  title: "Vision Transformers for Enhanced Analysis of X-ray Fluorescence Spectra in Cultural Heritage"
  author-title: "AGH University of Krakow"
  abstract: >- 
    Elemental analysis of cultural heritage artifacts offers profound insights into their history, manufacturing techniques, and current state of preservation. X-ray Fluorescence (XRF) spectroscopy, a widely used non-invasive method, plays a central role in such investigations. However, interpreting XRF data, especially from instruments with moderate energy resolution remains a significant challenge. This is particularly true for spectra acquired using the DETART Full-Field XRF (FF-XRF) scanner, developed at AGH University in collaboration with the Polish National Museum in Krakow. The system’s Gas Electron Multiplier (GEM) detector, while effective, exhibits limited energy resolution, which leads to overlapping elemental peaks and spectral artifacts that complicate analysis.  To address these challenges, I propose a deep learning-based approach, leveraging established computer vision models, specifically Vision Transformers (ViT), to analyze and interpret raw XRF spectra from the DETART system. This research centers on developing and evaluating algorithms for two key tasks: identifying the elements present (classification) and estimating their relative concentrations (regression). By applying these AI techniques directly to raw spectral data, the approach aims to automate and enhance the analytical process, enabling more accurate and detailed interpretations of the elemental composition of historical artifacts, even in the face of detector limitations. This work highlights the potential of deep learning to transform cultural heritage science.
  author-bio: >- 
    Fields medalists, machine learning researcher, 3000 ELO in chess - these words certainly don't describe me!   I am a software engineer with a specialization in scalable, distributed backend systems. Currently, I am pursuing a Master's degree, with my research focusing on machine learning and its applications in physics.
  co-authors: 
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 6
  author-image: images/optimized/cfc-600x600/eryk_zarebski.webp

- author-name: Jan Małaśnicki
  title: "μ-Parametrization for Mixture of Experts"
  author-title: "University of Warsaw"
  abstract: >- 
    Recent years have seen a growing interest and adoption of LLMs, with μTransfer becoming a key technique for tuning hyperparameters in large-scale training. Meanwhile, Mixture-of-Experts (MoE) has emerged as a leading architecture in extremely large models. However, the intersection of these two advancements has remained unexplored. In this work, we derive a μ-Parameterization (μP) for MoE, providing theoretical guarantees for feature learning across model widths in both the router and experts. We empirically validate our parameterization and further investigate how scaling the number of experts and granularity affects the optimal learning rate.
  author-bio: >- 
    Aspiring researcher specializing in Large Language Models (LLMs), specifically pretraining and Mixture of Experts.
  co-authors: Kamil Ciebiera, Mateusz Boruń, Maciej Pióro, Jan Ludziejewski, Maciej Stefaniak, Michał Krutul, Sebastian Jaszczur, Marek Cygan, Kamil Adamczewski, Jakub Krajewski
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 7
  author-image: images/empty.png

- author-name: Piotr Wyrwiński
  title: "WICHER-M : Model for High-Resolution Weather Prediction"
  author-title: "PCSS, PUT"
  abstract: >- 
    Accurate weather prediction offers immense benefits for humanity, enabling better preparation, planning, and decision-making across virtually every sector of society. In agriculture, precision farming relies on localized forecasts to guide irrigation, fertilization, and pest control with high spatial accuracy, helping to optimize yields and reduce input waste. In urban flood management, detailed short-range forecasts are essential to predict localized heavy rainfall and prevent flash flooding, especially in densely populated areas with complex drainage systems. For regional aviation and drone operations, fine-scale predictions of wind, fog, and turbulence are crucial for safety and operational efficiency. In the renewable energy sector, hyper-local forecasts allow grid operators to anticipate fluctuations in energy generation and balance supply and demand more effectively.   For years weather prediction was solved using Numerical Weather Prediction (NWP) methods, resulting in appearance of global climate models such as GFS or ECMWF. Those models provide broad information about climate, however they are unable to give more detailed prognosis. This is why mesoscale models (e.g. WRF) are frequently applied on their outputs to provide more local and accurate predictions of weather. Unfortunately, not only are WRF simulations local, thus not representing the whole globe, but also NWP calculation is compute-intensive, especially for mesoscale models. These shortcomings lead to intensified interest in alternative methods for weather prediction, e.g. AI transformer models.   In recent years there has been a surge of AI models able to match NWP results, such as GraphCast, Aurora or FourCastNet. They all excel in providing accurate weather predictions for whole globe at 0.25° scale, bounded by resolution of prevalent dataset used to train those models, ERA5 (available since 1940), delivering inference speeds thousands of times faster than traditional simulations, while maintaining state-of-the-art accuracy. Some of them tried to mitigate the problem of representing large areas like Poland by only a few pixels by bringing the resolution down to 0.1°. They proposed to fine-tune model on high-resolution IFS HRES dataset, however it is available only from year 2016, with scarce representation of mesoscale areas. Similarly to NWP approach, we believe that the solution of this issue lies in utilization of models such as WRF, which enable us to bring down resolution even more, preserving speed-ups achieved by aforementioned AI models.   We propose WICHER-M (Weather Intelligence through Computational High-resolution Environmental Representation Model) to achieve this goal. We utilize both ERA5 dataset and WRF simulation outcomes matched in time and spatial domain. Using data from 7 years with granularity of 6-hour timesteps we fine-tune global prediction models already proficient in modelling climate to model at lower scale of 0.025°. We adapt decoder architecture of state-of-the-art Aurora to match the desired resolution and train the head to minimize loss on WRF simulation data. Utilizing the fact that Aurora model has a separate pretrained backbone, serving as a simulator of climate model we integrate it into our solution. To the best of our knowledge, predicting weather on the finer scale has only been achieved for single physical variables, whereas our approach attempts to leverage all available climate data.
  author-bio: >- 
    Piotr Wyrwiński is a PhD student at Poznan University of Technology and a Machine Learning Researcher at the Poznan Supercomputing and Networking Center. His research explores neurosymbolic learning, program synthesis, and graph-based deep learning. At PCSS, he develops and applies deep learning models in areas such as weather prediction, medical imaging, and satellite data analysis.
  co-authors: Wiktor Kamzela, Adam Dobosz, Jakub Kubiak, Wojciech Stefaniak
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 8
  author-image: images/optimized/cfc-600x600/piotr_wyrwinski.webp

- author-name: Paulina Tomaszewska
  title: "Leveraging contextual information in Deep Learning"
  author-title: "Warsaw University of Technology, Samsung AI Center Warsaw"
  abstract: >- 
    Recently the term context engineering was introduced. It emphasizes that we should go beyond simple prompt engineering and pay more attention to context. While context is often associated with text processing, its significance extends to other data types, such as images, time series, and video. This talk provides an overview of diverse approaches to integrating contextual information into Deep Learning models. As the illustration, I will describe in more detail a project that explored the value of expert-driven extraction of regions of interest from large tissue images to improve model accuracy in predicting metastasis occurrence within a specific timeframe. The findings revealed that models trained on whole tissue images (containing wider context) outperformed those relying on labor-intensive expert annotations.
  author-bio: >- 
    Paulina Tomaszewska conducts research at MI2.ai at Warsaw University of Technology, focusing on Deep Learning models used in digital pathology, with an emphasis on explainability and spatial context. She also investigates Large Language Models from the Mechanistic Interpretaility perspective in Safety&Alignment Lab in Samsung AI Center. She has gained experience in AI through academic stays and research internships in Singapore, South Korea, Austria and Switzerland. She is a member of the Scientific Committee of the Polish AI Olympiad from the first edition - this year she was a vice-chair.
  co-authors: 
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 9
  author-image: images/optimized/cfc-600x600/paulina_tomaszewska.webp

- author-name: Bartosz Cywiński
  title: "Eliciting hidden knowledge from LLMs using mechanistic interpretability"
  author-title: "Warsaw University of Technology, IDEAS Research Institute"
  abstract: >- 
    As language models grow in power and sophistication, it becomes essential to ensure they remain trustworthy. However, early evidence suggests that some models may try to hide information or even deceive their operators. To explore the ability of current techniques to elicit such hidden knowledge, we create a suite of model organisms engineered with known secrets of varying complexity, such as specific hidden information or a hidden objective. This controlled environment lets us benchmark how models conceal information that they are incentivized to keep hidden. We then compare black-box strategies (such as adversarial prompting) against white-box techniques (such as sparse autoencoders and the logit lens) to see how well each approach elicits hidden knowledge. Our findings highlight the promise of these approaches for eliciting hidden knowledge, even when black-box baselines fall short. Additionally, we assess whether white-box techniques add value to black-box techniques when auditing large language models.
  author-bio: >- 
    I am a PhD student at Warsaw University of Technology working on mechanistic interpretability. I am interested in applied mech interp.
  co-authors: Bartosz Cywiński, Emil Ryd, Senthooran Rajamanoharan, Neel Nanda, Samuel Marks, Arthur Conmy
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 10
  author-image: images/optimized/cfc-600x600/bartosz_cywinski.webp

- author-name: Maciej Pióro
  title: "Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient"
  author-title: "IDEAS NCBR / IPPT PAN"
  abstract: >- 
    Mixture of Experts (MoE) architectures have significantly increased computational efficiency in both research and real-world applications of large-scale machine learning models. However, their scalability and efficiency under memory constraints remain relatively underexplored. In this work, we present joint scaling laws for dense and MoE models, incorporating key factors such as the number of active parameters, dataset size, and the number of experts. Our findings provide a principled framework for selecting the optimal MoE configuration under fixed memory and compute budgets. Surprisingly, we show that MoE models can be more memory-efficient than dense models, contradicting conventional wisdom. To derive and validate the theoretical predictions of our scaling laws, we conduct 270 experiments with up to 2.7B active parameters and up to 5B total parameters. These results offer actionable insights for designing and deploying MoE models in practical large-scale training scenarios.  The work was presented at ICML 2025 in Vancouver.
  author-bio: >- 
    Maciej is a researcher and PhD student at IDEAS NCBR and IPPT PAN. He works on large language models and is particularly interested in topics related to LLM capabilities and efficiency - in both training and inference.
  co-authors: Jan Ludziejewski, Jakub Krajewski, Maciej Stefaniak, Michał Krutul, Jan Małaśnicki, Marek Cygan, Piotr Sankowski, Kamil Adamczewski, Piotr Miłoś (lyzell@gmail.com), Sebastian Jaszczur (sebastian.jaszczur@gmail.com)
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 11
  author-image: images/optimized/cfc-600x600/maciej_pioro.webp

- author-name: Turhan Can Kargin
  title: "Probing the general spatial awareness of vision encoders via equivariance"
  author-title: "Jagiellonian University, GMUM"
  abstract: >- 
    Modern visual encoders show strong performance in a wide range of semantic tasks, yet their ability to capture the underlying 3D geometric structure of a scene is not well understood. Although spatial awareness is typically evaluated through the lens of downstream tasks such as depth estimation, this may favor models that memorize dataset-specific priors instead of developing an abstract, generalizable understanding of spatial relations. In this work, we propose metric for directly evaluating geometric awareness, by measuring whether a model's internal representation is equivariant to controlled geometric transformations in the input data. Since it is challenging to precisely label movements occurring in real-world data, we pair our metric with the environment built in Unreal Engine 5. This environment enables precise control over camera movement, object placement, lighting, occlusion, and scene complexity. This allows us to generate synthetic video sequences depicting everyday objects with full geometric annotations and confounding factors of high variety. Using this data, we systematically evaluate a range of state-of-the-art visual encoders in terms of their ability to represent spatial structure. Our results reveal surprising differences in geometric sensitivity across architectures and training objectives. We are releasing both metric and environment as open tools for scalable, label-light evaluation of geometry-aware representation learning.
  author-bio: >- 
    He is a PhD student in Technical Computer Science at Jagiellonian University, supported by the SONATA BIS grant funded by the Polish National Science Center. His research focuses on self-supervised learning and its applications in robotic perception, with a particular emphasis on developing and evaluating spatially-aware representations. His current work aims to advance the use of synthetic video data and geometric probing techniques to understand better how vision models perceive 3D structure.
  co-authors: Marcin Przewięźlikowski, Wojtek Jasiński, Bartosz Zieliński
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 12
  author-image: images/optimized/cfc-600x600/turhan_can_kargin.webp

- author-name: Maciej Wojtala
  title: "MACTAS: Self-Attention-Based Module for Inter-Agent Communication in Multi-Agent Reinforcement Learning"
  author-title: "University of Warsaw; IDEAS Research Institute"
  abstract: >- 
    Communication is essential for the collective execution of complex tasks by human agents, motivating interest in communication mechanisms for multi-agent reinforcement learning (MARL). However, existing communication protocols in MARL are often complex and non-differentiable. In this work, we introduce a Transformer-based communication module that exchanges information between the agents in MARL by performing self-attention over hidden states of their recursive neural network. Our proposed approach is fully differentiable, allowing agents to learn to generate messages in a reward-driven manner. The module can be seamlessly integrated with any action-value function decomposition method and can be viewed as an extension of such decompositions. Notably, it includes a fixed number of trainable parameters, independent of the number of agents. We also observe the necessity for better exploration techniques for MARL. We introduce a method that connects epsilon-greedy and Boltzmann exploration. Experimental results on the SMAC2v2 benchmark demonstrate the effectiveness of our algorithm, which achieves state-of-the-art performance on several maps. We also achieve a notable increase in performance for the 3s5z_vs_3s6z map after applying the new exploration technique.
  author-bio: >- 
    I'm a machine learning researcher with a strong mathematical background. I finished a Master's degree in machine learning and a Master's degree in mathematics.  I graduated from a class for exceptionally gifted students in XIV LO im. Stanisława Staszica and successfully competed in the Polish Mathematical Olympiad and the International Mathematics Competition.  I conducted research on commutative algebra and algebraic geometry with Dr. Hab. Joachim Jelisiejew, which resulted in the publication "Irreversibility of structure tensors of modules" (https://doi.org/10.1007/s13348-022-00361-w) and the paper "Iarrobino's decomposition for self-dual modules", available on ArXiv (https://arxiv.org/abs/2405.13829).  Now I'm conducting research in machine learning. My specialty field is reinforcement learning. With a group from the Polish Academy of Sciences I co-created the Latent Subgoal Search algorithm (which is yet to be extended). I worked on a proactive cloud solver based on RL for 7bulls.com and developed RL methods for investing in currency pairs for AI Investments.  Currently I'm pursuing a PhD at the University of Warsaw in the topic of reinforcement learning. I'm also employed at the IDEAS Research Institute. We conduct research on the topic of communication for multi-agent reinforcement learning. I'm also working on the application of reinforcement learning for the tension regulation in hanger rods with a group from the Polish Academy of Sciences under an NCBR grant.
  co-authors: Bogusz Stefańczyk, Dominik Bogucki, Łukasz Lepak, Jakub Strykowski, Paweł Wawrzyński
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 13
  author-image: images/optimized/cfc-600x600/maciej_wojtala.webp

- author-name: Jolanta Śliwa
  title: "Benchmark for Ordinal Regression in pen & paper RPG game design"
  author-title: "AGH University of Kraków"
  abstract: >- 
    In recent years, the pen & paper RPG market has experienced significant growth. As a result, companies are increasingly exploring the integration of AI technologies to enhance player experience and gain a competitive edge. While most research on RPG monster design emphasizes emotional and narrative impact, the field of computer science has contributed little to tools for this field. One key challenge is estimating a monster’s challenge level, a task for which no automated solutions currently exist.  To address this gap, we introduce a benchmark based on Pathfinder 2e, focused on predicting monster levels using ordinal regression techniques. The dataset consists of approximately 2,600 monsters sourced from official bestiaries, rulebooks, and supplements. Each instance contains a set of key monster’s attributes selected via domain expertise. The prediction target, monster level, is a discrete, ordered variable, positioning this task at the intersection of classification and regression, an ordinal regression problem.  We evaluate a variety of modelling approaches, including human-inspired model, classical regression with rounding and dedicated ordinal methods. To account for the chronological nature of the data, we employ an expanding-window-inspired evaluation strategy. Tree-based models consistently outperformed other techniques, while neural approaches yielded disappointing results across all metrics. Model performance was assessed using a combination of classification, regression, and ordinal-specific metrics. Despite variations in absolute error and accuracy, all models demonstrated strong ordinal consistency according to Somer’s D. This benchmark provides practical applications for game design automation, monster creation, and educational use in ordinal modelling.
  author-bio: >- 
    I am a new graduate Data Science student from AGH University of Krakow. As part of my engineering and master’s thesis, I co-developed an application that supports the design of opponents in a pen & paper RPG game, using Machine Learning. For this reason, I have recently been spending my free time playing this type of game, and I also immerse myself in the fascinating world of animation.
  co-authors: 
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 14
  author-image: images/optimized/cfc-600x600/jolanta_sliwa.webp

- author-name: Jakub Paszke
  title: "SARA: An LLM-Powered Agent for Scientific Collaborations and Grant Discovery"
  author-title: "Adam Mickiewicz University in Poznań"
  abstract: >- 
    SARA (Search and Research Agent): LLM-based Recommendation System for Scientific Collaborations and Grants   In modern scientific environments, selecting appropriate collaborators and navigating the complex landscape of grant opportunities is both time-consuming and often inefficient. Existing methods heavily rely on informal networks, personal recommendations, and institutional familiarity, making them inherently biased, suboptimal, and inaccessible—especially for early-career researchers. To address these challenges, we propose SARA (Search and Research Agent), an intelligent recommendation system designed to support academic collaboration and funding processes using cutting-edge machine learning techniques.   SARA utilizes a combination of Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) and vector databases to semantically analyze publication metadata, project information, and grant call descriptions. This allows the system to generate meaningful associations between researchers, disciplines, and funding sources, going beyond keyword matching by capturing latent thematic similarities and contextual knowledge. Our system transforms scattered, heterogeneous academic data into a structured, searchable knowledge graph enriched with embeddings. These embeddings enable high-precision recommendations that reflect both the scientific relevance and the collaboration potential of individual researchers.   SARA acts as an interactive advisor, allowing users to ask natural language questions such as “I want to apply for a project on AI and sustainability—who should I work with?” or “Which calls in the next 6 months best match my expertise in deep learning?” The system responds with tailored suggestions, highlighting suitable collaborators, active and upcoming calls, and areas of strategic opportunity. Its architecture includes NLP-based entity recognition and classification, citation network analysis, and dynamic reranking based on topical overlap, project success likelihood, and institutional compatibility.   Unlike existing academic search engines, our approach offers personalized, proactive guidance. The system not only retrieves data but interprets it in the user’s research context. It supports interdisciplinary queries, considers researchers’ grant histories, institutional affiliations, and scientific impact, and includes modules for grant-specific adaptation and call evaluation criteria modeling. A key innovation is the semantic integration of publication networks and grant programs into one framework, enabling robust matching even across different scientific domains.      We present results from a functioning prototype tested on real-world academic and grant data. Preliminary evaluations demonstrate promising outcomes in recommendation quality, explainability, and usability. Our poster will illustrate the full pipeline—from data ingestion and vectorization, through model architecture and interaction design, to deployment challenges and ethical considerations (e.g., bias, data privacy, hallucination risks). We believe that SARA offers a scalable, generalizable model for enhancing the equity, efficiency, and transparency of research team formation and grant application planning.
  author-bio: >- 
    Jakub Paszke is a Master’s student in Artificial Intelligence at Adam Mickiewicz University in Poznań, Poland. His interests include natural language processing, semantic search, and AI-powered recommendation systems. He is currently developing SARA, an LLM-based system for improving scientific collaboration and grant discovery. As an Automation Engineer, Jakub builds intelligent workflows using scripts, RAG systems, AI chatbots, and no-code tools for automations.
  co-authors: Daria Dworzyńska, Miłosz Rolewski, Michał Wujec
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 15
  author-image: images/optimized/cfc-600x600/jakub_paszke.webp

- author-name: Dominik Lewy
  title: "Lost in the Details: GenAI’s Visual Blind Spots and Paths to Clarity"
  author-title: "Lingaro"
  abstract: >- 
    As Large Multimodal Models (LMMs) become increasingly central to visual understanding in retail and marketing contexts, critical limitations in their ability to interpret detailed visual information are emerging. This presentation examines the “visual blind spots” of generative AI systems when applied to tasks requiring high precision and contextual awareness. Use cases such as promotional shelf analysis, point-of-sale marketing material recognition, and full-shelf product parsing reveal common failure modes—including confusion between visually similar products, imprecise localization, and sensitivity to image size and perspective. To mitigate these issues, the presentation explores strategies that leverage classical computer vision techniques to enhance LMM inputs.  These include preprocessing methods such as depth filtering, morphological operations, and perspective normalization, as well as text-guided segmentation and region-of-interest (ROI) refinement. This hybrid approach aims to improve clarity and accuracy in downstream tasks while reducing reliance on large volumes of training data, paving the way for more robust and scalable multimodal systems.
  author-bio: >- 
    Dominik has over 11 years of hands-on experience in Machine Learning, Data Exploration, and Business Analysis projects, primarily in the FMCG industry. As a seasoned technical leader, he excels in setting strategic goals and crafting detailed roadmaps for complex projects.   Dominik holds a PhD with distinction from the Warsaw University of Technology, where he specialized in neural networks for image processing. Passionate about bridging the commercial and academic worlds, he combines cutting-edge research with practical applications to drive innovation.   For over 1.5 years, Dominik has been deeply immersed in the Generative AI space, successfully delivering multiple proof-of-concept projects and advancing several initiatives to production. His expertise and curiosity make him a key driver of transformative AI solutions.
  co-authors: 
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 16
  author-image: images/optimized/cfc-600x600/dominik_lewy.webp

- author-name: Maria Galanty
  title: "Leveraging ECG Foundation Model for ICU Rhythm Classification"
  author-title: "University of Amsterdam"
  abstract: >- 
    Foundation models have demonstrated significant potential across a range of applications by enabling the development of robust and transferable representations. Recently released electrocardiography (ECG) foundation model ECG-FM [2] offers pre-trained and fine-tuned checkpoints that can be adapted to a variety of downstream clinical tasks. In this work, we assess its applicability for classifying cardiac rhythms in intensive care unit (ICU) patients using data from Amsterdam University Medical Center. Our focus is on detecting sinus rhythm (SR) (including normal sinus rhythm, sinus tachycardia, and sinus bradycardia) and atrial fibrillation (AF), a distinction crucial for monitoring in intensive care.  First, we created a dataset reflecting clinical reality. We curated a representative dataset aligned based nursing documentation, where heart rhythm is recorded hourly by nurses. Our dataset includes 592 ten-second ECG segments independently annotated by two junior clinicians with conflicting annotations solved by a senior expert (361 SR, 113 AF and 118 other rhythm samples). Additionally, we constructed a larger weakly labelled ECG dataset based on structured nursing documentation. We evaluated ECG-FM performance across three settings: (1) out-of-the-box inference using two ECG-FM models fine-tuned on large-scale public datasets PhysioNet Challenge 2021 [3] and MIMIC-IV-ECG [1]; (2) targeted fine-tuning using two high-quality datasets from PhysioNet Challenge 2021: PTB-XL and Chapman-Shaoxing datasets, which were selected based on their internal label consistency; and (3) fine-tuning using PTB-XL and Chapman-Shaoxing datasets along with a weakly annotated in-house dataset.  Model fine-tuned on high-quality PhysioNet datasets, specifically PTB-XL and Chapman, outperformed those trained on broader but noisier sources, including the full PhysioNet repository and the MIMIC-IV-ECG dataset. The PhysioNet-fine-tuned model achieved the following performance on internal AMC data, with F1 scores of 0.45 for SR and 0.80 for AF. The MIMIC-IV-fine-tuned model performed slightly better for SR (F1 = 0.68) but worse for AF (F1 = 0.52). In contrast, fine-tuning the model specifically for SR and AF using two selected datasets resulted in significantly improved performance, F1 scores of 0.91 for SR and 0.82 for AF on the AMC test set. Augmenting training with weakly labelled in-house data did not yield further gains, with F1 scores of 0.93 (SR) and 0.81 (AF), comparable to the model trained without additional data.  These findings underscore the potential of ECG foundation models for clinical use but also highlight the need for institution-specific validation. While these models are capable of learning powerful and generalizable representations, their performance is ultimately constrained by the quality of the data they are trained on. Public datasets vary widely in annotation accuracy and labelling standards, which can significantly affect downstream model performance, generalizability, and safety. As such, even with strong pre-trained foundations, deployment in critical care settings must be accompanied by careful local evaluation and, when necessary, additional fine-tuning.  References: [1] B. Gow et al., MIMIC-IV-ECG: Diagnostic ECG Matched Subset, 2023. [2] K. McKeen et al., ECG-FM: An Open ECG Foundation Model, arXiv:2408.05178, 2024. [3] M. A. Reyna et al., PhysioNet/CinC Challenge 2021, Comput. Cardiol., 2021.
  author-bio: >- 
    Maria Galanty holds two Bachelor’s degrees (BSc) from the University of Warsaw, in Mathematics and Cognitive Science. She later earned her Master’s degree (MSc) in Artificial Intelligence from Utrecht University. In June 2022, she joined the qurAI Group as a PhD candidate within the Intensive Care Lab, under the supervision of Clarisa Sanchez. Her PhD is part of the University of Amsterdam’s Research Priority Agenda AI for Health Decision-Making, a cross-disciplinary collaboration between the Faculties of Medicine, Science, Humanities, and Law. Her research explores bias in healthcare, the documentation practices of medical datasets, and applications in intensive care settings—particularly those involving electrocardiography (ECG).
  co-authors: Björn van der Ster, Alexander P. Vlaar, Clara I. Sánchez
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 17
  author-image: images/optimized/cfc-600x600/maria_galanty.webp

- author-name: Michał Brzozowski
  title: "Representation-based Broad Hallucination Detectors Fail to Generalize Out of Distribution"
  author-title: "Samsung AI Center Warsaw, Safety & Alignment Lab"
  abstract: >- 
    We critically assess the efficacy of the current SOTA in hallucination detection and find that its performance on the RAGTruth dataset is largely driven by a spurious correlation with data. Controlling for this effect, state-of-the-art performs no better than supervised linear probes, while requiring extensive hyperparameter tuning across datasets. Out-of-distribution generalization is challenging, with all of the analyzed methods performing close to random. We propose a set of guidelines for hallucination detection and its evaluation. The work has been accepted to EMNLP Findings.
  author-bio: >- 
    Mathematician turned AI researcher. PhD in probability from Warsaw University. I am a senior research engineer at Samsung Warsaw AI Center. I work in Safety & Alignment Lab focusing on natural language processing, hallucination detection and mechanistic interpretability. In my free time I write science-fiction and grotesque short stories.
  co-authors: Zuzanna Dubanowska, Maciej Żelaszczyk, Paolo Mandica, Michał Karpowicz
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 18
  author-image: images/optimized/cfc-600x600/michal_brzozowski.webp

- author-name: Mathilde Vergnaud
  title: "Quantitative approaches in vessel morphology analysis in corneal eye diseases"
  author-title: "University of Cologne"
  abstract: >- 
    Healthy cornea is transparent, avascular and without strong immune responses. When the immunologic privilege is broken by the apparition of the blood vessels in the cornea, the chances of recovery from an eye disease diminish.  In this project we quantify the degree of vascularization in the human eye and use it as a biomarker of disease progression and response to treatment. We base our analysis on the slit lamp microscope images – a non-invasive and affordable technique to capture neovessels in the cornea. We analyze 160 images from 30 patients imaged over a time span of 6 months. Different cohorts of patients received varying dose of an antisense oligonucleotide (GS-101) as a local traitement N=1 to inhibit corneal neo-vascularisation.  Segmentation of blood vessels in these images is a challenging task since vessels can be very similar to the crypts in the iris or to the suture points of patients after cornea transplant. We developped a UNet-based solution with  adapted loss weighting scheme that penalizes errors in the image regions that are particularly challenging to segment.   In the resulting segmentation maps we quantify a range of morphometric parameters that capture the density and structure of the underlying vascular system. We next compare the parameter value change across patients over time and develop predictive methods that based on the time-resolved vessel maps predict further disease development.  Our approach, by combining several machine learning approaches rerpesents the first fully automated and systematic approach to cornea blood vessel structure quantification and its use in patient outcome prediction.
  author-bio: >- 
    I have a master degree in image processing applied to biomedical. Since 2024, I am a PhD student in Computer Science at the Bozek Lab, University of Cologne. My research focuses on the development of machine learning methods to characterize and quantify eyes diseases from medical images.
  co-authors: Katarzyna Bozek, Felix Bock, Katrina Crompton
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 19
  author-image: images/optimized/cfc-600x600/mathilde_vergnaud.webp

- author-name: Joanna Ceklarz
  title: "Explainable AI for Pharmacophore-Based Drug Activity Prediction"
  author-title: "UCT Prague"
  abstract: >- 
    Pharmacophores are molecular representations containing information about steric and electronic features necessary for biological activity of drugs. They are used by medicinal chemists to identify and visualize important fragments and generalize between groups with similar functionalities. Therefore, using pharmacophores as representations of molecules for Graph Neural Network (GNN) training is an interesting prospect which has been largely unexplored, yet.  We compare performance of selected GNNs trained on pharmacophore representations of molecules with those trained on conventional atomic representations, as well as with a baseline model. Then, we investigate how those models compare when trained on datasets of varied sizes, and on ones containing different numbers of clusters of molecules. Finally, GNN-specific xAI methods have been developed to answer questions about both feature and structural importance of functional groups in known bioactive compounds. In our case study, pharmacophore features attributed with the highest importance for the activity were directly compared with protein-ligand crystal structures, where interactions described by the pharmacophore models of molecules are experimentally revealed. The results helped us to identify areas for further improvement in our molecular featurization – some areas experimentally recognized as important for function were not encoded with appropriate features when default feature definitions were applied. Interestingly, we found that different GNN models rely on overlapping, yet not identical, pharmacophore features when making predictions, while all being in partial agreement with experimental data.
  author-bio: >- 
    Joanna holds a Master's degree in Medicinal Chemistry from Jagiellonian University in Kraków, Poland (2021). After graduation, she joined the AstraZeneca R&D Graduate Programme in Gothenburg, Sweden. There she became interested in the intersection of machine learning and drug discovery. This led her to transition from traditional laboratory-based research into chemoinformatics and ML. In 2024, she began her PhD at the University of Chemistry and Technology in Prague, focusing on the application of ML into drug development, with a particular interest in model explainability techniques.
  co-authors: Krystyna Waniová, Agnieszka Wojtuch, Wim Dehaen, Tomasz Danel, Martin Šícho
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 20
  author-image: images/optimized/cfc-600x600/joanna_ceklarz.webp

- author-name: Florian Bürger
  title: "Explainable Prediction of Molecular Events in Microscopic Videos"
  author-title: "University of Cologne"
  abstract: >- 
    A central challenge in cancer treatment is that a subpopulation of tumor cells survives the initial therapeutic treatment, eventually leading to relapse and regrowth. To address this challenge and improve treatments, it is essential to determine the features that distinguish surviving from non-surviving cells.   In this study, we investigate non-genetic predictors of cell fate using a genetically identical population of cells exposed to uniform treatment conditions. Although genetically and environmentally identical, the cells display distinct outcomes, with some undergoing apoptosis (death) and others mitosis (division).  We introduce a Transformer model that predicts cell fate (death or division) based on 93-hour-long time-lapse recordings of 21898 cells that were treated with a chemotherapeutic drug. The time-lapse data comprises cell morphology, its neighborhood, and expression of several functional markers. We also mask up to 50% of the ends of the sequences to obtain a generalized model.  Our model predicts cell fate with an F1-score of $0.93$ on the test set. We next introduce a novel explainability approach that leverages the self-attention mechanism, allowing us to uncover and analyze the most predictive visual cues for each outcome. We quantify morphology, protein expression, and neighborhood features of each cell over time and, using self-attention, statistically compare these features in the predictive vs. remaining time points. Importantly, attention consistently peaks within a very narrow time window: from 1 hour before cell division up to the moment of division, and from 10 hours before death leading up to the moment of death. We identify the most important cell characteristics that occur during these time windows as primarily features relating to cell size, but also shape descriptors and specific biological markers.  Our study demonstrates a Transformer-based predictive model with a rigorous explainability pipeline and points to yet unknown cancer cell features that are key for the cell response to chemotherapeutic treatment.
  author-bio: >- 
    Since 2023: PhD student in Computer Science at the Bozek Lab at the University of Cologne 2020 - 2023: M.Sc. in Computer Science at the University of Paderborn 2016 - 2020: B.Sc. in Computer Science at the University of Paderborn
  co-authors: Adrián E. Granada, Katarzyna Bozek
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 21
  author-image: images/empty.png

- author-name: Konrad Duraj
  title: "Graph-Unet-Transformer for predicting pressure drops in cardiovascular networks"
  author-title: "Hemolens Diagnostics"
  abstract: >- 
    Predicting pressure drops across arterial networks is critical for noninvasive assessment of vascular health and the early detection of potential hemodynamic dysfunctions. Computational fluid dynamics (CFD) approaches offer high fidelity but come with high computational cost and the need for detailed anatomical models. Patient‐specific vascular geometries are represented as attributed graphs, where nodes correspond to vessel cross‐ sections (with features such as diameter and cross‐sectional area), and edges represent the length of each segment. In this study, we propose a hybrid deep‐learning framework that combines a UNET-style graph convolutional neural network (GCN) encoder with a Transformer architecture for pressure drop prediction. The UNET-GCN encodes the topological structure and geometrical features of arterial trees, while the Transformer captures long‐range dependencies among vessel segments. Our model achieves a root mean squared error (RMSE) of 5.65 mmHg and an intersection over union (IoU) associated with fractional flow reserve (FFR) of 0.94 on the validation set, demonstrating that the combination of GCNs and Transformers offers a promising and scalable solution for rapid, noninvasive hemodynamic assessment in personalized medicine.
  author-bio: >- 
    A graduate of the Silesian University of Technology with a specialization in the application of AI in medicine. His extensive commercial experience includes participation in a variety of projects, where he had the opportunity to develop, among others: an algorithm for detecting, identifying, and counting bacteria in images of Petri dishes; a library for training and evaluating satellite image super-resolution techniques; a device for monitoring vital signs in home settings; an algorithm for assessing the correctness and safety of exercises performed by athletes; and a system for monitoring methane emissions from flare stacks at extraction facilities.  He is the author of numerous publications and studies related to the use of advanced deep learning algorithms for comprehensive processing of medical data.
  co-authors: Szymon Kopeć, Jakub Chojnacki, Maciej Zamorski
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 22
  author-image: images/empty.png

- author-name: Marek Skiba
  title: "SAEPER: Sparse AutoEncoders Projection for Reliable PERsonalization in Diffusion Models"
  author-title: "University of Warsaw"
  abstract: >- 
    Diffusion models are the leading architecture for text-to-image generation due to their ability to synthesize highly detailed images and their flexibility for adaptation through fine-tuning. However, reliably personalizing these models to generate consistent and precise visual concepts remains a challenge. Existing personalization approaches either use zero-shot methods, which often lack visual accuracy and consistency, or fine-tuning techniques, which can suffer from training instability, concept entanglement, and extensive parameter tuning. We propose SAEPER, a novel personalization approach for transformer-based diffusion models that integrates Sparse Autoencoders (SAEs) directly into the fine-tuning process. By leveraging the powerful ability of SAEs to disentangle polysemantic representations into sparse ones, we can isolate and target the specific features relevant for personalization while minimally altering global image semantics. Our experiments demonstrate that incorporating SAEs not only increases the precision and visual fidelity of personalized concepts but also provides a consistently stable training environment. This work establishes that SAEs are not just tools for interpretability, but also emerge as a reliable and powerful component for fine-tuning and personalization, marking entirely new directions for future research.
  author-bio: >- 
    Marek Skiba is a machine learning researcher and software engineer currently pursuing an MSc in Machine Learning at the University of Warsaw. He has a strong background in AI, diffusion models, and large-scale software development. Marek previously led a quantitative research team, focusing on large-scale financial data analytics. He is a passionate competitive programmer and a bronze medalist at the International Olympiad in Informatics. His research interests include text-to-image diffusion models, explainable AI, and efficient deep learning for edge devices.
  co-authors: Jowita Drozdowicz (equal contributor),<br>Vladimir Zaigrajew, Przemysław Biecek, Piotr Sankowski
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 23
  author-image: images/optimized/cfc-600x600/marek_skiba.webp

- author-name: Jan Dubiński
  title: "Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models"
  author-title: "Warsaw University of Technology; NASK National Research Institute"
  abstract: >- 
    Image generative models have become increasingly popular, but training them requires large datasets that are costly to collect and curate. To circumvent these costs, some parties may exploit existing models by using the generated images as training data for their own models. In general, watermarking is a valuable tool for detecting unauthorized use of generated images. However, when these images are used to train a new model, watermarking can only enable detection if the watermark persists through training and remains identifiable in the outputs of the newly trained model — a property known as radioactivity. We analyze the radioactivity of watermarks in images generated by diffusion models (DMs) and image autoregressive models (IARs). We find that existing watermarking methods for DMs fail to retain radioactivity, as watermarks are either erased during encoding into the latent space or lost in the noising-denoising process (during the training in the latent space). Meanwhile, despite IARs having recently surpassed DMs in image generation quality and efficiency, no radioactive watermarking methods have been proposed for them. To overcome this limitation, we propose the first watermarking method tailored for IARs and with radioactivity in mind — drawing inspiration from techniques in large language models (LLMs), which share IARs' autoregressive paradigm. Our extensive experimental evaluation highlights our method's effectiveness in preserving radioactivity within IARs, enabling robust provenance tracking, and preventing unauthorized use of their generated images.
  author-bio: >- 
    Jan Dubiński works on developing safe and trustworthy artificial intelligence. His research focuses on generative models, such as large language models and generative vision systems. His work has been published at leading AI conferences, including NeurIPS, CVPR, ICML, AAMAS, and WACV. Jan is currently pursuing a PhD at the Doctoral School of Warsaw University of Technology. He works at NASK National Research Institute at the Department of Security and Transparency of Artificial Intelligence.
  co-authors: Michel Meintz, Franziska Boenisch, Adam Dziedzic
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 24
  author-image: images/optimized/cfc-600x600/jan_dubinski.webp

- author-name: Piotr Wójcik
  title: "LumiMotion: Improving Gaussian Relighting with Scene Dynamics"
  author-title: "University of Cologne"
  abstract: >- 
    In 3D reconstruction, the problem of inverse rendering, namely recovering the illumination of the scene and the material properties, is fundamental. Existing Gaussian Splatting-based methods primarily target static scenes and often assume simplified or moderate lighting to avoid entangling shadows with surface appearance. This limits their ability to accurately separate lighting effects from material properties, particularly in real-world conditions. We address this limitation by leveraging dynamic elements - regions of the scene that undergo motion - as a supervisory signal for inverse rendering. Motion reveals the same surfaces under varying lighting conditions, providing stronger cues for disentangling material and illumination. To this end, our contributions are threefold. First, we present the first Gaussian-based approach, LumiMotion, for inverse rendering in dynamic scenes. Our method learns a dynamic 2D Gaussian Splatting representation that promotes smooth normals and temporal surface consistency. Combined with a deferred shading pipeline, this enables accurate material estimation. Second, we introduce a set of novel constraints on the deformation network, which encourage dynamic regions to deform while keeping static regions stable, promoting consistent albedo estimation. Third, we release a new synthetic benchmark comprising five scenes under four lighting conditions, each in both static and dynamic variants, enabling systematic evaluation of inverse rendering methods in dynamic environments.
  author-bio: >- 
    I am a PhD student at the University of Cologne, currently working at the Center for Molecular Medicine. My research focuses on unsupervised learning, explainable AI, and the analysis of biomedical images.
  co-authors: Joanna Kaleta, Kacper Marzol, Tomasz Trzcinski, Kacper Kania, Marek Kowalski
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 25
  author-image: images/optimized/cfc-600x600/piotr_wojcik.webp

- author-name: Wojciech Zarzecki
  title: "Interpretable Protein Design: Disentangling RFDiffusion Features using Sparse Autoencoders"
  author-title: "Computational Medicine Group, MIMUW"
  abstract: >- 
    Controllable de novo design of protein backbones poses a critical challenge. Recent advances in protein design such as RFDiffusion can generate high‐quality structures, but offer little insight into which internal representations encode specific structural or functional attributes. To address this challenge, we applied a Sparse Autoencoder (SAE) to the internal activations of the chosen RFDiffusion block. Through systematic ablation studies, we first identified the specific network block that most strongly encodes information about subcellular localization and enzymatic function. We then trained SAE on this block's activations to disentangle its complex representations into interpretable neuron-level features. We trained probing models to identify neurons corresponding to specific biological properties of interest. We plan to make interventions by blocking or reinforcing selected features hoping to influence generation and extend this study by examining the secondary structure of generated proteins. We identified the block responsible for our target properties and we aim to disentangle its channels into ones responsible for the properties of interest.
  author-bio: >- 
    Wojciech Zarzecki is a Computer Science student at the Warsaw University of Technology and a member of the Computational Medicine Group at MIMUW led by Prof. Ewa Szczurek. In his research he investigates internal representations of deep learning models for life sciences.
  co-authors: Paulina Szymczak, Ewa Szczurek, Kamil Deja
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 26
  author-image: images/optimized/cfc-600x600/wojciech_zarzecki.webp

- author-name: Zuzanna Gawrysiak
  title: "Invisible Yet Invincible: A Fast Deep Learning Approach to Image Watermarking"
  author-title: "Vestigit, Poznan University of Technology"
  abstract: >- 
    We introduce a novel deep learning architecture for image watermarking, designed for high efficiency and robustness. Our approach integrates a skip-layer excitation module to enhance feature representation efficiently and uses conditional batch normalisation to adapt the watermarking process to different messages. We leverage message spreading and mask generation techniques to embed the watermark with minimal perceptual distortion. The resulting architecture is not only lightweight and fast but also highly robust against common distortions like blur, cropping, and JPEG compression. Evaluations on standard benchmark datasets confirm our model's competitive performance. By effectively balancing perceptual fidelity, robustness, and computational speed, this work offers a practical solution for applications in digital rights management and content authentication.
  author-bio: >- 
    Zuzanna Gawrysiak is an AI engineer and PhD student at Poznan University of Technology, working on deep learning for image and video processing. She currently works at Vestigit, developing efficient video watermarking methods. Her research interests are focused on computer vision, specifically neuro-symbolic autoencoders and domain-aware machine learning methods.
  co-authors: Tomasz Hawro, Mateusz Gabor
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 27
  author-image: images/optimized/cfc-600x600/zuzanna_gawrysiak.webp

- author-name: Lukasz Popek
  title: "Smart Flattening: AI-Assisted Unwrapping of 3D Guitar Body Geometry for Custom Graphic Application"
  author-title: "Warsaw University of Technology"
  abstract: >- 
    Applying 2D images onto 3D objects with complex shapes remains a major challenge in custom product design, especially in industries where shapes are detailed and unusual. Manually turning 3D objects exported from CAD software into accurate 2D grid layouts (called UV unwrapping) for texture mapping can be difficult and time-consuming. It often requires model remeshing to achieve more regular geometry and prevent image stretching. In this paper, we propose an AI-powered framework that automates and optimizes the UV unwrapping process of guitar body geometries. By leveraging the knowledge of diverse guitar body shapes and mapping techniques, our system finds the best way to unwrap the 3D model while keeping the proportions and minimizing texture stretching. This approach supports the designer’s workflow and supports a broader vision of automating the electric guitar production process. The approach was developed in collaboration with the Ruf Guitars ltd and will serve as a use case technology within the company's pipeline. It will allow for scalable manufacturing of custom instruments with high-fidelity graphic visualizations.
  author-bio: >- 
    Łukasz Popek is a PhD candidate at Warsaw University of Technology, with a dual Master’s background from WUT and the University of Warsaw. His research concerns applying generative AI in industrial processes, focusing on photorealistic texture generation for composite electric guitars. He has worked across startups and applied research projects, delivering AI-driven solutions in UAV safety, thermal vision, and creative automation.
  co-authors: Julian Konowalski
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 28
  author-image: images/optimized/cfc-600x600/lukasz_popek.webp

- author-name: Jarosław Janas
  title: "A Multi-bit Watermarking Scheme for LLM-Generated Short Texts"
  author-title: "Institute of Computer Science Polish Academy of Sciences"
  abstract: >- 
    The rapid advancement of Large Language Models (LLMs) has established them as a foundational technology for many AI- and ML-powered human–computer interactions. A critical challenge in this context is the attribution of LLM-generated text—for example, identifying the specific language model that generated it or the individual user who prompted the model. This capability is essential for combating misinformation, fake news, misinterpretation, and plagiarism. One of the key techniques for addressing this challenge is digital watermarking.  We propose a multi-bit watermarking scheme, in which multi-bit information (e.g., a user’s ID) is embedded into LLM-generated text. In particular, we target short texts (around 100 words), where other methods do not offer a very high matching rate. Our approach could be especially useful for dealing with fake product reviews, social media posts, and customer feedback, where malicious actors often deploy automated systems to generate deceptive content at scale.
  author-bio: >- 
    I am a PhD student at the Doctoral School of Information and Biomedical Technologies, Polish Academy of Sciences (TIB PAN), where I conduct research on data privacy and ownership in generative neural networks, with a particular focus on Stable Diffusion and Large Language Models. I hold an MSc in Artificial Intelligence from the University of Galway (2023, First Class Honours), where my thesis explored Vision Transformer-based semantic segmentation of bone composition. My current research investigates membership inference attacks and watermarking techniques in generative models, addressing critical issues related to data ownership in AI systems. I have industry experience as a software engineer and teaching assistant, with strong expertise in Python, deep learning frameworks including PyTorch and TensorFlow, and machine learning applications.
  co-authors: Paweł Morawiecki, Josef Pieprzyk
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 29
  author-image: images/optimized/cfc-600x600/jaroslaw_janas.webp

- author-name: Emilia Kaczmarczyk
  title: "Analyzing Latent Representations in Time Series Foundation Models"
  author-title: "University Of Warsaw, Faculty of Physics"
  abstract: >- 
    Time series foundation models are becoming important tools for solving a wide range of time series problems. As these models become more widely used, it is increasingly important to study and understand their internal representations and the concepts they learn. One method for exploring these internal mechanisms is through the use of steering vectors, which allow targeted interventions in the model’s latent space. For concepts that are linearly represented in the latent space, steering vectors are defined at each layer as the difference between the median activation matrices of contrasting time series concepts. By modifying the model’s internal representations using these vectors, we can influence or adjust its predictions. This study aims to analyze dependencies between various steering vectors using hyperspherical coordinates. In addition, we plan to invetigate how both linear and nonlinear correlations are represented in latent space, and whether additive relationships between time series might be preserved. This approach offers a novel perspective for interpreting concept representations and their interactions, with the goal of making time series foundation models more transparent and interpretable.
  author-bio: >- 
    Emilia Kaczmarczyk is a Master's student at the Faculty of Physics, University of Warsaw. She has experience in quantitative trading and neuroscience and currently actively participates in research at the Auton Lab at Carnegie Mellon University and the MI2 Lab at Warsaw University of Technology.
  co-authors: Michał Wiliński, Artur Dubrawski
  date: 16.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 1
  id: 30
  author-image: images/optimized/cfc-600x600/emilia_kaczmarczyk.webp

- author-name: Cezary Dołęga
  title: "Practical Deep ANN implementations on embeded devices"
  author-title: "Neurosoft Sp. z o.o."
  abstract: >- 
    In the era of AI, embedded systems require high-performance, low-power solutions for real-time signal processing. This poster presents practical implementations of deep artificial neural networks (Deep ANN) on embedded platforms using Ambarella CV22s and Hailo-8™ neural coprocessors. We detail Ambarella CV2x’s energy-efficient video analytics (< 2 W) and Hailo-8’s up to 26 TOPS at 3 TOPS/W, along with their software stacks enabling seamless model deployment.  Applications include Automatic Number Plate Recognition (ANPR) for tolling and enforcement, Make and Model Recognition (MMR) to detect vehicle attributes when plates are occluded, and vehicle tracking across camera networks for trajectory generation and analytics.  Additionally, we explore multi-sensor fusion architectures that integrate data from 3D LiDAR, stereoscopic cameras, and inertial measurement units (IMU) to enhance perception capabilities in drone applications. Leveraging neural coprocessors for on-device sensor fusion enables real-time depth mapping, obstacle avoidance, and precise state estimation under strict power and latency constraints. We demonstrate a pipeline where point clouds from a miniaturized LiDAR and disparity maps from stereo vision are synchronized with IMU readings. This approach proves the feasibility of deploying advanced sensor fusion on edge devices for autonomous UAVs, enabling robust navigation and situational awareness even in GPS-denied or cluttered scenarios.
  author-bio: >- 
    Founder and co-owner of Neurosoft. Holds an M.Sc. in Electronics Engineering, graduating from Wrocław University of Science and Technology in 1990. Served as a research associate in the Faculty of Electronics at the Institute of Technical Cybernetics from 1990 to 1999. Since the company’s founding, he has been Vice President of the Management Board and Director of Research and Development.
  co-authors: Paweł Mrówka, Michał Pietrasik
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 31
  author-image: images/optimized/cfc-600x600/cezary_dolega.webp

- author-name: Jeremy Cochoy
  title: "Contrastive Forecasting: Latent-Space Prediction for Time Series via Joint Embedding"
  author-title: "Redtone Solution OU"
  abstract: >- 
    This talk introduces Contrastive Forecasting, an unsupervised method for time series prediction that learns entirely in latent space. The approach is grounded in contrastive divergence and uses a joint-embedding predictive architecture (JEPA) to align predicted future states with actual outcomes while distinguishing them from carefully selected negative samples.  We will detail the model architecture, which combines RWKV or Transformer-based forecasters with Residual encoders. The training objective encourages accurate representation learning by pulling forecasted embeddings toward future targets and pushing them away from dissimilar contexts.  The talk will cover practical aspects of training, the design of contrastive losses for temporal data, and the handling of multivariate and long-horizon forecasting challenges. This session is intended for researchers and practitioners interested in self-supervised learning, representation learning, and time series modeling.
  author-bio: >- 
    Jérémy Cochoy is an expert in technology with a strong academic background. Holding a PhD in Computer Science and Mathematics with a focus on Persistent Homology, he leveraged his expertise to co-found Symphonia, an app that creatively transforms voices into music. Currently, as CEO of Redstone Solutions, Cochoy applies his skills in deep learning to the field of financial market forecasting. His career is a testament to the fusion of advanced scientific knowledge and practical technological applications, underscoring his commitment to driving innovation in complex fields. Beyond his professional realm, Cochoy's interests in music and other artistic pursuits reflect a multifaceted personality, equally engaged in intellectual and creative endeavors.
  co-authors: 
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 32
  author-image: images/optimized/cfc-600x600/jeremy_cochoy.webp

- author-name: Julia Kiczka
  title: "Beyond Reconstruction Error: Leveraging Latent Representations for Anomaly Detection in Time Series"
  author-title: "University of Wroclaw"
  abstract: >- 
    (Ongoing Master's Thesis Work) Anomaly detection in time series data is critical in domains such as healthcare, finance, and system monitoring. While many popular methods rely on reconstruction error from models like Autoencoders, Transformers, or Diffusion Models, my thesis investigates whether the latent space itself can carry meaningful information for this task beyond what reconstruction error reveals.  I explore how to modify and structure latent representations to make them more informative, for example through contrastive learning. I also test whether simple statistics in the embedding space, such as distances to nearest neighbors, can already provide useful anomaly scores.  Another key aspect of my work is the definition of meaningful anomalies - cases that are not just outliers in amplitude or easily detectable with simple statistics, but represent subtle or structural deviations. To handle such cases, I propose techniques for anomaly injection and analysis that go beyond standard benchmarks. Finally, I address challenges in modeling multivariate, correlated time series by introducing masked training and separate decoders per feature dimension, which improve the model’s capacity to capture diverse signal characteristics.
  author-bio: >- 
    Julia Kiczka obtained a Bachelor’s degree in Individual Studies in Mathematics and Computer Science at the University of Wrocław, currently pursuing Master’s in Computer Science and Mathematics.
  co-authors: 
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 33
  author-image: images/optimized/cfc-600x600/julia_kiczka.webp

- author-name: Alessandro Crimi
  title: "Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings"
  author-title: "AGH University of Krakow"
  abstract: >- 
    Nowadays, epilepsy is still heavily under-diagnosed in low-income countries due to the limited availability of neurologists and the high cost of diagnostic tools. To address this, in this study we propose a graph-based deep learning framework for detecting epileptic subjects using electroencephalogram (EEG) and artificial intelligence (AI) from low-cost accessible hardware, testing recordings from Nigeria and Guinea-Bissau. The contribution is focused both on fair and accessible automatic assessment of epilepsy and on explainability of the characteristics with the goal of shedding further light on biomarkers for epilepsy. Those goals are achieved by modeling EEG signals as spatio-temporal graphs, then by both classifying and identifying interchannel relationships and temporal dynamics by using graph attention networks (GAT). We employ the GAT approach, which is inherently node-based, to focus on edges to be more aimed at connectivity biomarkers. In this context of explainable AI, we identified the most discriminant connection using the portable EEG device as being within the frontal cortex and between the frontal and temporal cortex. In summary, we propose a combination of signal preprocessing techniques suitable for low-fidelity recordings and design a lightweight GAT architecture tailored for deployment on resource-constrained devices with full training on Google Colab Cloud and deployment on RaspberryPi devices. The approach achieves promising classification performance, outperforming a standard classifier based on Random Forest and graph convolutional networks in terms of accuracy and robustness over multiple sessions, but also highlighting specific connections in the fronto-temporal region. The results highlight the potential of GATs to provide insightful and scalable diagnostic support for epilepsy in underserved regions, paving the way for affordable and accessible neurodiagnostic tools. The innovative aspects for the ML community will be the investigation of GAT and GCN for brain connectivity analysis as we show what the attention weight represent in the brain.
  author-bio: >- 
    Alessandro Crimi, after completing his studies in engineering at the university of Palermo (Italy), obtained the Ph.D. in machine learning applied for medical imaging from the University of Copenhagen, and an MBA in healthcare management from the University of Basel.   He is currently a professor at AGH Krakow and worked as a post-doctoral researcher at the French Institute for Research in Computer Science (INRIA), Technical School of Switzerland (ETH-Zurich), Italian Institute for Technology (IIT), and University Hospital of Zurich.
  co-authors: Szymon Mazurek, Stephen Moore
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 34
  author-image: images/optimized/cfc-600x600/alessandro_crimi.webp

- author-name: Jakub Adamczyk
  title: "ML in agrochemistry and ecotoxicology"
  author-title: "AGH University of Krakow"
  abstract: >- 
    Machine learning is widely used in the pharmaceutical industry, where molecular ML and chemoinformatics have supported safer and faster drug development for decades. In contrast, the equally important field of agrochemistry has received far less attention. Yet it has incredible potential with both predictive and generative models, e.g. predicting pesticide toxicity or generating novel, safer agrochemicals. With growing regulatory pressure and a shift toward more sustainable agriculture, there is a pressing need to accelerate the development of alternative pesticides, and ML can play a crucial role in meeting this challenge.  In this talk, I will explore how and why machine learning can be applied in agrochemistry, with a particular focus on ecotoxicology - a critical and highly regulated aspect of modern agrochemical development. In particular, I will present ApisTox, a novel dataset on pesticides toxicity to honey bees, and demonstrate how the methods and workflows can be adapted to other molecular ML applications. We'll then review a range of predictive ML models suited to this kind of data, e.g. molecular fingerprints, graph kernels, and graph neural networks (GNNs). In particular, we will cover our insights for non-traditional molecular structures beyond typical pharmaceutical targets, such as pesticides. Finally, I will discuss potential opportunities for ML in agrochemistry and ecotoxicology areas.
  author-bio: >- 
    He is a PhD candidate in Computer Science at AGH University of Krakow and a member of the Graph ML and Chemoinformatics Group at the Faculty of Computer Science. His research focuses on fair evaluation, graph representation learning, graph classification, chemoinformatics, and molecular property prediction. He is also interested in time series, natural language processing (NLP), and MLOps, and teaches these subjects at AGH. He works at Placewise as a Data Science Engineer, where he addresses various machine learning challenges in tabular data, computer vision, and NLP, along with their end-to-end MLOps implementations. Outside of his professional work, he trains in Historical European Martial Arts (HEMA), specializing in messer and longsword, and enjoys reading and tabletop role-playing games.
  co-authors: 
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 35
  author-image: images/optimized/cfc-600x600/jakub_adamczyk.webp

- author-name: Witold Drzewakowski
  title: "Lightweight Latent Verifiers for Efficient Meta-Generation Strategies"
  author-title: "ELLIS Unit Warsaw, University of Warsaw"
  abstract: >- 
    Verifiers are auxiliary models that assess the correctness of outputs generated by base large language models (LLMs). They play a crucial role in many strategies for solving reasoning-intensive problems with LLMs. Typically, verifiers are LLMs themselves, often as large (or larger) than the base model they support, making them computationally expensive. In this work, we introduce a novel lightweight verification approach, LiLaVe, which reliably extracts correctness signals from the hidden states of the base LLM. A key advantage of LiLaVe is its ability to operate with only a small fraction of the computational budget required by traditional LLM-based verifiers. To demonstrate its practicality, we couple LiLaVe with popular meta-generation strategies, like best-of-n or self-consistency. Moreover, we design novel LiLaVe-based approaches, like conditional self-correction or conditional majority voting, that significantly improve both accuracy and efficiency in generation tasks with smaller LLMs. Our work demonstrates the fruitfulness of extracting latent information from the hidden states of LLMs, and opens the door to scalable and resource-efficient solutions for reasoning-intensive applications.
  author-bio: >- 
    Witold Drzewakowski holds a Bachelor's degree in Computer Science and a Master's in Machine Learning from the University of Warsaw. He has gained research experience at IDEAS NCBR and Snowflake, with a focus on natural language processing. Recently accepted into the ELLIS PhD program, his research interests center on applying large language models to multiagent games and reasoning tasks. He also leads the NLP problem track of the Polish AI Olympiad and serves as a coach for the Polish team for the International Olympiad in AI.
  co-authors: Bartosz Piotrowski, Konrad Staniszewski, Piotr Miłoś
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 36
  author-image: images/optimized/cfc-600x600/witold_drzewakowski.webp

- author-name: Alicja Dobrzeniecka
  title: "Auxiliary Embedding Space Measures as Interventions for Improving Continual Multimodal Learning"
  author-title: "NASK National Research Institute"
  abstract: >- 
    Machine learning models are usually trained using static data, which means updating them is expensive when new data or distribution shifts occur. Furthermore, many applications require models that can adapt continuously. Continual learning (CL) addresses this issue by enabling models to learn over time instead of being retrained from scratch. A central challenge in CL is balancing the ability to learn new information with the stability of retaining old knowledge, while also preventing catastrophic forgetting, whereby new learning erases prior knowledge.  A common strategy in CL is to introduce regularisation through loss-based interventions to improve model accuracy. However, my analysis of some of these works revealed that many of these interventions only improve accuracy slightly, with the main improvements coming from different sources, such as replay mechanisms. This suggests that focusing solely on output metrics can lead to a failure to recognise deeper representational dynamics within the model. The structure of the embedding space, particularly in multimodal models such as CLIP, plays a crucial role in how knowledge is stored and updated over time. When tasks share a parameter space, their interactions can significantly influence this shared embedding. Previous research by [1] has shown that CLIP's embedding space tends to form a cone-like structure, with the vision and text modalities distributed at opposite ends; however, much of the space remains underutilised. Recent approaches (such as [2], [3] and [4]) have therefore proposed allocating tasks to distinct subspaces to reduce interference and improve continual learning performance. This demonstrates the potential benefits of focusing on embedding space aspects when designing new interventions.  My research focuses on a task-agnostic approach, in which tasks use a shared parameter space within an additional adapter located above a frozen CLIP. My work focuses on improving our understanding of how CLIP’s embedding space evolves during continual learning, and on using this information to enhance the representation space — and ultimately, the model’s performance. Among other measures, I am utilising centroid distance, average pairwise distance and angle rotation. I am also extending the evaluation to include not only the training and test sets, but also out-of-distribution and retrieval tasks, to provide a more robust and useful assessment of model quality and generalization capabilities after training. Preliminary results demonstrate the potential of using auxiliary embedding space measures to control flexibility and stability in the CLIP model.  [1] Ni, Z., Wei, L., Tang, S., Zhuang, Y., and Tian, Q. (2023). Continual vision-language representation learning with off-diagonal information. In Proceedings of the 40th International Conference on Machine Learning, ICML’23. JMLR.org. [2] Chaudhry, A., Khan, N., Dokania, P., & Torr, P. (2020). Continual learning in low-rank orthogonal subspaces. In Proceedings of the 34th International Conference on Neural Information Processing Systems. Curran Associates Inc.. [3] Guo, Y., Hu, W., Zhao, D., & Liu, B. (2022). Adaptive Orthogonal Projection for Batch and Online Continual Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 36(6), 6783-6791. https://doi.org/10.1609/aaai.v36i6.20634. [4] Kaushik Roy, Christian Simon, Peyman Moghadam, & Mehrtash Harandi. (2023). Subspace Distillation for Continual Learning.
  author-bio: >- 
    Alicja Dobrzeniecka has been studying and researching AI for a number of years. She holds a Master of Science in Artificial Intelligence from Vrije Universiteit Amsterdam and a Bachelor of Arts in Philosophy from the University of Gdańsk. She has professional experience working as a data scientist, developing machine learning and deep learning models for businesses. She is currently a PhD student and researcher at the NASK National Research Institute. Her research focuses on a more trustworthy approach to Continual Learning for multi-modal models.
  co-authors: Bartłomiej Twardowski, Sebastian Cygert, Szymon Łukasik
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 37
  author-image: images/empty.png

- author-name: Maciej Stefaniak
  title: "Projected Compression: Trainable Projection for Efficient Transformer Compression"
  author-title: "University of Warsaw"
  abstract: >- 
    Large language models have steadily increased in size to achieve improved performance; however, this growth has also led to greater inference time and computational demands. Consequently, there is rising interest in model size reduction methods. To address this issue, we propose Projected Compression, a novel model compression technique, that reduces model weights by utilizing projection modules. Specifically, we first train additional trainable projections weights and preserve access to all the original model parameters. Subsequently, these projections are merged into a lower-dimensional product matrix, resulting in a reduced-size standard Transformer-based model. Unlike alternative approaches that require additional computational overhead, our method matches the base model's per-token computation step in FLOPs. Experimental results show that Projected Compression outperforms the comparable hard pruning and retraining approach on higher quality models. Moreover, the performance margin scales well with the number of tokens.
  author-bio: >- 
    Since 2024, I have been collaborating with the research team at IDEAS NCBR on computationally efficient methods for Large Language Models (LLMs), focusing particularly on scaling Mixture-of-Experts models and designing new Transformer-based architectures. I am a co-author of the publication Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient (ICML 2025). Currently, my research focuses on LLM compression methods, including structured pruning, knowledge distillation, and post-compression retraining techniques. Previously, I worked on a research project at Poznan University of Technology exploring how LLMs can be used to generate missing knowledge in Case-Based Reasoning systems. I also worked as a Research Scientist and Machine Learning Engineer at TIDK on R&D projects funded by the National Centre for Research and Development (NCBR), where I was responsible for implementing, training, and evaluating AI algorithms in cloud environments, as well as MLOps tasks. I am currently pursuing a Ph.D. in Computer Science at the University of Warsaw. Earlier, I completed an M.Sc. in Computer Science at Poznan University of Technology within the AITech program.
  co-authors: Michał Krutul, Jan Ludziejewski, Kamil Adamczewski, Marek Cygan, Sebastian Jaszczur, Maciej Pióro, Jan Małaśnicki, Jakub Krajewski
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 38
  author-image: images/optimized/cfc-600x600/maciej_stefaniak.webp

- author-name: Aleksandra Krasnodębska
  title: "PL-Guard: Benchmarking Language Model Safety for Polish"
  author-title: "NASK"
  abstract: >- 
    Despite increasing efforts to ensure the safety of large language models (LLMs), most existing safety assessments and moderation tools remain heavily biased toward English and other high-resource languages, leaving majority of global languages underexamined. To address this gap, we introduce a manually annotated benchmark dataset for language model safety classification in Polish. We also create adversarially perturbed variants of these samples designed to challenge model robustness. We conduct a series of experiments to evaluate LLM-based and classifier-based models of varying sizes and architectures. Specifically, we fine-tune three models: Llama-Guard-3-8B, a HerBERT-based classifier (a Polish BERT derivative), and PLLuM, a Polish-adapted Llama-8B model. We train these models using different combinations of annotated data and evaluate their performance, comparing it against publicly available guard models. Results demonstrate that the HerBERT-based classifier achieves the highest overall performance, particularly under adversarial conditions.
  author-bio: >- 
    Aleksandra Krasnodębska is a Senior NLP Specialist at NASK National Research Institute, where she focuses on large language model (LLM) alignment, safety evaluation—particularly for the Polish language—and data preparation for model training. She holds a Master’s degree in Mathematical Statistics from Warsaw University of Technology and has prior experience in NLP and AI research across various organizations.
  co-authors: Karolina Seweryn, Szymon Łukasik, Wojciech Kusa
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 39
  author-image: images/optimized/cfc-600x600/aleksandra_krasnodebska.webp

- author-name: Zofia Hendrysiak
  title: "Teaching Small Models Big Math: A Curriculum Learning Approach for Bielik"
  author-title: "University of Warsaw"
  abstract: >- 
    Small Language Models (SMLs) often exhibit significant deficiencies in complex reasoning, limiting their utility in specialized domains like mathematics. This work addresses this limitation within the context of Polish language models by investigating curriculum learning (CL) as a data and compute-efficient fine-tuning strategy. The research focuses on the Bielik-1.5B and Bielik-4.5B models, which have documented weaknesses in mathematical problem-solving. This poster posits that a structured curriculum, which presents training examples in order of increasing difficulty, enables more effective and efficient skill acquisition compared to standard fine-tuning on randomly shuffled data. The proposed methodology leverages the five distinct difficulty levels of the MATH dataset to construct a progressive learning curriculum. The Bielik models are fine-tuned using a fixed-pace schedule, completing a set number of epochs on each difficulty tier before advancing to the next. To establish a rigorous baseline for comparison, models of the same scale are fine-tuned on the identical dataset but presented in a conventional, non-sequential order. The evaluation protocol is designed for a multi-faceted analysis of performance and efficiency. First, mathematical proficiency is quantified on a held-out test split of the MATH dataset. Second, the generalization of reasoning skills are assessed using the English MT-Bench and its validated Polish adaptation, MT-Bench-PL. This dual-benchmark approach measures skill retention in non-mathematical domains and tests the cross-lingual transfer of logical-mathematical abilities from English-centric training data to Polish. Finally, the computational efficiency of CL is compared against the baseline by measuring time-to-convergence and total FLOPs. The findings provide a resource-efficient blueprint for specializing models on complex tasks, offering a practical path for developing advanced, domain-specific AI capabilities within the Polish language ecosystem.
  author-bio: >- 
    Zosia is a Master's student in Cognitive Science within the Interfaculty Individual Studies in Mathematics and Science program at University of Warsaw. Her academic journey is complemented by over two years of practical experience at a startup, where they contribute to the creation of a novel intelligent assistant. This work bridges the gap between theoretical cognitive principles and real-world machine learning applications. Outside of research, she is a passionate reader, pianist, and hiker.
  co-authors: 
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 40
  author-image: images/empty.png

- author-name: Marek Jeliński
  title: "Auditing Large Language Models for Intentional Manipulations"
  author-title: "NASK"
  abstract: >- 
    Large Language Models (LLMs) are increasingly embedded in decision-making processes, raising concerns about intentional manipulations that go beyond known demographic or gender biases. These manipulations may include preferential promotion of brands, ideologies, or lifestyles, posing subtle but significant risks to users.   Most existing approaches to detecting such manipulation rely on prior knowledge of biased datasets, limiting their ability to uncover previously unknown or novel manipulative behavior. To address this, we propose a new auditing method that does not require labeled biased data.   Our approach compares an audited model to a trusted reference LLM by analyzing shifts in word embedding spaces. We construct a large semantic dictionary to quantify how word representations deviate between models, and we evaluate their alignment with curated positive and negative semantic subspaces. In parallel, we analyze token-level generation probabilities to capture distributional changes in outputs.   We demonstrate the effectiveness of our approach through a case study auditing the Mistral 7B model for potential intentional manipulations.
  author-bio: >- 
    Marek Jeliński focuses his research on natural language processing, with a particular emphasis on large language models and AI safety. In his research, he actively engages with topics related to artificial intelligence security, focusing on developing secure and resilient LLM-based systems.
  co-authors: 
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 41
  author-image: images/empty.png

- author-name: Jakub Chojnacki
  title: "MT-SAS: Multi-Task Structure Aware Segmentation of Anatomical Regions"
  author-title: "Independent Researcher"
  abstract: >- 
    The incorporation of automated analysis for anatomical structures, derived from medical imaging modalities such as magnetic resonance imaging (MRI) or computed tomography (CT), has become an indispensable component of contemporary radiological workflows. Although various methods exist, the current gold standard in automatic analysis is based on deep learning approaches that utilize the U-Net architecture to accomplish segmentation, regression, or classification tasks employing conventional supervised learning methodologies. However, by concentrating solely on a single task at a time, the methods' capacity to effectively utilize shared information is diminished, disregarding the mutually beneficial interaction between tasks. In response to the growing demand for scalable and precise diagnostic assistance, multi-task systems are emerging as a promising paradigm to exploit shared information between tasks.  In this work, we present a Multi-Task Structure Aware Segmentation (MT-SAS) - a method tailored for concurrently segmenting and classifying regions within anatomical structures. Our approach is based on latent representation augmentation with region-specific information derived from different tasks.  Thereby, by leveraging task-joint representation, the accuracy and robustness are enhanced across diverse tasks. We evaluate the proposed method on spinal diagnosis by performing vertebral segmentation, measurements, and the generation of a comprehensive report that quantifies the segmented radiologically significant regions. The outcomes of experiments conducted on the SPIDER dataset demonstrate that our model exhibits superior performance in both segmentation and classification tasks to the current leading single-task learning methodologies.
  author-bio: >- 
    An AI engineer and medical imaging researcher developing machine learning tools that help clinicians with disease assessment and treatment guidance. His projects range from coronary artery disease analysis based on CTA imaging—including vessel segmentation, stenosis quantification, calcium scoring, and fractional flow reserve estimation with physics-aware networks—to tracking brain changes across multiple MRI contrasts and detecting breast cancer lesions on ultrasound.
  co-authors: Miłosz Gajowczyk, Kacper Kupczak, Karolina Szałata, Patryk Rygiel
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 42
  author-image: images/optimized/cfc-600x600/jakub_chojnacki.webp

- author-name: Filip Ręka
  title: "LoRA-based Adapter Tuning for Arbitrary Class Specialisation in Embedding Models"
  author-title: "AGH"
  abstract: >- 
    Embedding models like CLIP offer general-purpose representations across diverse visual and textual domains, but adapting them to specific use cases often compromises generality or requires extensive finetuning. In this work, we propose a parameter-efficient approach using LoRA adapters to specialise a frozen embedding backbone for arbitrary target classes. Each class receives its own LoRA module, enabling modular, per-class adaptation without disrupting the global representation space or retraining shared parameters.  This setup allows new semantic classes to be introduced incrementally, with only small, specialised adapters added per class. We show how this method preserves inter-class structure while allowing for class-specific expressivity, and explore the conditions under which these local adapters diverge or interfere. To support dynamic use at inference, we also discuss routing mechanisms for selecting the appropriate adapter based on input similarity.  Finally, we explore potential methods for aligning the resulting class-specific embedding subspaces, enabling compatibility between adapted and non-adapted representations in a shared global embedding space.
  author-bio: >- 
    Phd student working on medical LLMs with main focus on language guided therapy for cancer treatment. I hold a Masters degree in Data Science.
  co-authors: 
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 43
  author-image: images/optimized/cfc-600x600/filip_reka.webp

- author-name: Tomasz Ponitka
  title: "The Pseudo-Dimension of Contracts"
  author-title: "Tel Aviv University"
  abstract: >- 
    Algorithmic contract design studies scenarios where a principal incentivizes an agent to exert effort on her behalf. In this work, we focus on settings where the agent's type is drawn from an unknown distribution, and formalize an offline learning framework for learning near-optimal contracts from sample agent types. A central tool in our analysis is the notion of pseudo-dimension from statistical learning theory. Beyond its role in establishing upper bounds on the sample complexity, pseudo-dimension measures the intrinsic complexity of a class of contracts, offering a new perspective on the tradeoffs between simplicity and optimality in contract design. Our main results provide essentially optimal tradeoffs between pseudo-dimension and representation error (defined as the loss in principal's utility) with respect to linear and bounded contracts. Using these tradeoffs, we derive sample- and time-efficient learning algorithms, and demonstrate their near-optimality by providing almost matching lower bounds on the sample complexity. Conversely, for unbounded contracts, we prove an impossibility result showing that no learning algorithm exists. Finally, we extend our techniques in three important ways. First, we provide refined pseudo-dimension and sample complexity guarantees for the combinatorial actions model, revealing a novel connection between the number of critical values and sample complexity. Second, we extend our results to menus of contracts, showing that their pseudo-dimension scales linearly with the menu size. Third, we adapt our algorithms to the online learning setting, where we show that, a polynomial number of type samples suffice to learn near-optimal bounded contracts. Combined with prior work, this establishes a formal separation between expert advice and bandit feedback for this setting.
  author-bio: >- 
    I am a PhD student working on Economics and Computation.
  co-authors: Paul Duetting, Michal Feldman, Ermis Soumalias
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 44
  author-image: images/optimized/cfc-600x600/tomasz_ponitka.webp

- author-name: Tomasz Szczepański
  title: "GEPAR3D: Geometry Prior-Assisted Learning for 3D Tooth Segmentation"
  author-title: "Sano Centre for Computational Medicine"
  abstract: >- 
    Tooth segmentation in Cone-Beam Computed Tomography (CBCT) remains challenging, especially for fine structures like root apices, which is critical for assessing root resorption in orthodontics. We propose GEPAR3D, a novel approach that unifies instance detection and multi-class segmentation into a single, geometrically-informed step. Our method combines a Statistical Shape Model as a geometric prior with a 3D energy-based watershed formulation, where each tooth is modeled as a separate energy basin defined by voxel-wise distances to boundaries. Our method is trained on a public CBCT dataset and evaluated across diverse external test sets from multiple centers, demonstrating strong generalization and robustness to variations in imaging protocols and patient anatomy, while consistently achieving state-of-the-art segmentation quality. A key application is the analysis of root resorption, a pathological shortening of tooth roots often induced by orthodontic treatment. As resorption detection relies on comparing sequential scans to a stable baseline, accurate apex segmentation is critical, since under-segmentation may obscure early signs of root loss. GEPAR3D’s improvements in root-level accuracy may support such clinical workflows and demonstrate the value of geometrical and anatomical priors for fine-grained 3D medical segmentation.
  author-bio: >- 
    Tomasz Szczepański holds an MSc in Computer Science (2022) and a BEng in Photonics Engineering, both from the Warsaw University of Technology (WUT). His master's thesis addressed the issue of data bias in chest X-ray datasets of COVID-19 patients. He is currently a PhD candidate jointly affiliated with the Sano Centre for Computational Medicine in Kraków and the Warsaw University of Technology (WUT). At Sano, he is a member of the Medical Imaging and Robotics group. His research interests include medical imaging, multimodal data integration, and geometric approaches to 3D image segmentation. His research has been presented at MICCAI ('24, '25) and ICCS ('22), and published in high-impact journals such as IEEE Transactions on Medical Imaging (TMI, '24) and Medical Image Analysis (MEDIA, '25).
  co-authors: Szymon Płotka, Michał K. Grzeszczyk, Arleta Adamowicz, Piotr Fudalej, Przemysław Korzeniowski, Tomasz Trzciński, Arkadiusz Sitek
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 45
  author-image: images/optimized/cfc-600x600/tomasz_szczepanski.webp

- author-name: Kacper Marzol
  title: "VeGaSMedical - Spatiotemporal Gaussian Modeling for Ultrasound Interpolation and Anatomical Mesh Generation"
  author-title: "Jagiellonian University"
  abstract: >- 
    Medical imaging remains one of the most critical components in modern diagnostics. Among the various modalities, ultrasound (US) stands out for its safety, real-time feedback, and non-invasive nature. However, it is often limited in spatial and temporal resolution, and certain regions may be underrepresented due to operator error, occlusion, or rapid tissue movement. Traditional methods for enhancing ultrasound data often rely on heuristic filtering or deep learning models that lack physical consistency and generalizability across patient anatomies.    We address this problem by introducing VeGaSMedical, a novel approach to medical image processing that applies recent advances in video representation to two challenges in medical imaging: expressive interpolation of sparse ultrasound data and high-fidelity 3D mesh generation from annotated medical images. This work builds upon the foundation of Gaussian Splatting, a revolutionary method in computer vision, and introduces modifications tailored specifically to the structure and demands of medical imaging workflows. By incorporating Folded Gaussians, VeGaS (Video Gaussian Splatting) demonstrates significantly improved capability in reconstructing and interpolating video data. It achieves that with modified family of time-conditioned Gaussian functions designed to model nonlinear dynamics across video frames, created to capture dynamics in a sequence of images and model frames by 2D Gaussians derived as conditional distributions. Medical imaging (ultrasound, CT scans, MRI) can also be considered as video, as it is a sequence of images. Hence our work, VeGaSMedical, uses the findings of previous authors to perform precise image interpolation, while also enabling downstream 3D modeling with enhanced accuracy and anatomical consistency. We enhance the quality of interpolated output, by incorporating self-supervision during the training stage. We achieve this by using basic interpolation between ground truth frames as additional input to the model.   Beyond interpolation, VeGaSMedical facilitates high-fidelity 3D mesh reconstruction from limited annotated slices. By generating intermediate frames between annotated images, our method increases volumetric data density, enabling more detailed and anatomically plausible 3D modeling through standard reconstruction techniques, such as marching cubes. This leads to the creation of anatomically faithful 3D meshes from as little as a few annotated slices, reducing annotation burden while increasing geometric detail.  Preliminary evaluations indicate strong potential, with full benchmarks forthcoming. VeGaSMedical offers a promising direction for future development in diagnostic visualization, temporal tracking, and surgical planning. By bridging sparse input data with anatomically coherent interpolation and enabling mesh generation from limited annotations, this framework addresses critical challenges in medical imaging workflows. This work creates promising foundation for advancing real-time analysis, surgical planning, and accessible 3D visualization - especially in settings where high-resolution data or extensive labeling is limited.
  author-bio: >- 
    CS Master’s student at Jagiellonian University. Passionate about machine learning and computer vision, with a strong interest in Gaussian Splatting and its real-world applications. Always curious and eager to turn ideas into impactful solutions.
  co-authors: Ignacy Kolton, Weronika Smolak-Dyżewska, Przemysław Spurek
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 46
  author-image: images/empty.png

- author-name: Szymon Płotka
  title: "Mamba Goes HoME: Hierarchical Soft Mixture-of-Experts for 3D Medical Image Segmentation"
  author-title: "University of Warsaw"
  abstract: >- 
    In recent years, artificial intelligence has significantly advanced medical image segmentation. However, challenges remain, including efficient 3D medical image processing across diverse modalities and handling data variability. In this work, we introduce Hierarchical Soft Mixture-of-Experts (HoME), a two-level token-routing layer for efficient long-context modeling, specifically designed for 3D medical image segmentation. Built on the Mamba state-space model (SSM) backbone, HoME enhances sequential modeling through sparse, adaptive expert routing. The first stage employs a Soft Mixture-of-Experts (SMoE) layer to partition input sequences into local groups, routing tokens to specialized per-group experts for localized feature extraction. The second stage aggregates these outputs via a global SMoE layer, enabling cross-group information fusion and global context refinement. This hierarchical design, combining local expert routing with global expert refinement improves generalizability and segmentation performance, surpassing state-of-the-art results across datasets from the three most commonly used 3D medical imaging modalities and data quality.
  author-bio: >- 
    Szymon Płotka obtained his PhD in Computer Science in 2024 from the Informatics Institute at the University of Amsterdam, where his research focused on applying deep learning to enhance prenatal care.  Szymon’s research interests lie at the intersection of computer vision, machine learning, and deep learning-based algorithms for medical image analysis. He is particularly interested in developing innovative AI-driven solutions to improve diagnostic accuracy, integrate multimodal data sources, and optimise healthcare workflows. His work aims to bridge the gap between cutting-edge artificial intelligence and real-world clinical applications, contributing to more efficient and accessible medical imaging technologies.
  co-authors: Gizem Mert, Maciej Chrabaszcz, Ewa Szczurek, Arkadiusz Sitek
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 47
  author-image: images/empty.png

- author-name: Piotr Wyrwiński
  title: "Learning to Synthesize Expressions: Symbolic Regression via Iterative Graph Expansion"
  author-title: "PUT, PCSS"
  abstract: >- 
    Symbolic regression (SR) is a fundamental problem in machine learning and scientific discovery, where the objective is to recover an explicit analytical expression that fits observed data. Unlike conventional regression, SR does not assume a predefined model structure -- instead, it requires synthesizing both the form and parameters of a symbolic expression from scratch. In this sense, SR can be viewed as a constrained form of program synthesis from examples, where the desired output is a compact and interpretable program (in the form of a mathematical expression) that approximates an unknown target function. This task is notoriously difficult: the space of candidate programs grows exponentially with formula depth, and small syntactic changes can lead to abrupt and unpredictable changes in semantics, making the search space highly discontinuous and non-differentiable. As a result, gradient-based methods are ineffective, and even evaluating the quality of partially constructed programs can be unreliable due to their brittleness and poor generalization. These challenges mirror core issues in symbolic program synthesis, highlighting the need for learned, structure-aware guidance. To address this, we propose a neurosymbolic algorithm that frames symbolic regression as an iterative process of neural-guided graph expansion. The method incrementally expands a computational graph where each node represents a symbolic expression constructed so far, and edges reflect their compositional structure. A graph neural network (GNN) is queried throughout this process to identify which candidate subexpressions should be expanded, thereby guiding the bottom-up synthesis of increasingly complex models. To support effective guidance, each node is equipped with a learned embedding that represents the symbolic expression associated with that node. These embeddings capture both the syntactic structure of the expression (e.g., its composition and position in the graph) and its semantic behavior across training data (i.e., the outputs it produces on input examples). They are further enriched via a transformer-style attention module, which aggregates information across all input–output examples. This enables the model to form contextualized, task-aware representations of candidate expressions. The attention-guided message passing mechanism within the GNN allows the system to prioritize substructures that are not only structurally plausible but also exhibit behavior consistent with the target values. We evaluate the proposed method on a large synthetic benchmark of symbolic regression problems as well as the AI Feynman suite -- a collection of equations derived from physics. The results show that neural guidance dramatically improves success rates over unguided variants, demonstrating the benefits of solving symbolic regression iteratively and compositionally, rather than in a single step as in many purely neural approaches.
  author-bio: >- 
    Piotr Wyrwiński is a PhD student at Poznan University of Technology and a Machine Learning Researcher at the Poznan Supercomputing and Networking Center. His research explores neurosymbolic learning, program synthesis, and graph-based deep learning. At PCSS, he develops and applies deep learning models in areas such as weather prediction, medical imaging, and satellite data analysis.
  co-authors: Krzysztof Krawiec
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 48
  author-image: images/optimized/cfc-600x600/piotr_wyrwinski.webp

- author-name: Joanna Kaleta
  title: "PR-ENDO: Physically Based Relightable Gaussian Splatting for Endoscopy"
  author-title: "SANO Poland; Warsaw University of Technology"
  abstract: >- 
    Endoluminal endoscopic procedures are essential for diagnosing colorectal cancer and other severe conditions in the digestive tract, urogenital system, and airways. 3D reconstruction and novel-view synthesis from endoscopic images are promising tools for enhancing diagnosis. Moreover, integrating physiological deformations and interaction with the endoscope enables the development of simulation tools from real video data.  However, constrained camera trajectories and view-dependent lighting create artifacts, leading to inaccurate or overfitted reconstructions. We present PR-ENDO, a novel 3D reconstruction framework leveraging the unique property of endoscopic imaging, where a single light source is closely aligned with the camera.  Our method separates light effects from tissue properties. PR-ENDO enhances 3D Gaussian Splatting with a physically based relightable model. We boost the traditional light transport formulation with a specialized MLP capturing complex light-related effects while ensuring reduced artifacts and better generalization across novel views.  PR-ENDO achieves superior reconstruction quality compared to baseline methods on both public and in-house datasets. Unlike existing approaches, PR-ENDO enables tissue modifications while preserving a physically accurate response to light, making it closer to real-world clinical use.
  author-bio: >- 
    Joanna Kaleta is a Computer Science graduate from Warsaw University of Technology who is currently a Ph.D. student at Sano - Center for Computational Medicine. Her research interest lies in the exploration of innovative Computer Vision applications for computed assisted surgery and diagnosis.
  co-authors: Weronika Smolak-Dyżewska, Dawid Malarz, Diego Dall'Alba, Przemyslaw Korzeniowski, Przemysław Spurek
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 49
  author-image: images/empty.png

- author-name: Michał Sala
  title: "PAST LIME: Explaining Code Generation via AST-Based Perturbations"
  author-title: "Uniwersytet Warszawski"
  abstract: >- 
    Code-generation models such as Stable-Code-3B have shown strong performance in tasks like code completion, bug fixing, and refactoring. However, their black-box nature limits users’ ability to understand the factors that influence the model’s output. This lack of interpretability poses challenges in software engineering, where trustworthy and semantically coherent explanations are essential.  We propose PAST LIME (Perturbed Abstract Syntax Tree LIME), a model-agnostic interpretability method that identifies which code fragments affect the probability assigned to a fixed continuation. Most existing approaches either operate at the token level without considering code structure, or attempt to align token probabilities with semantic representations without using perturbation-based analysis. In contrast, PAST LIME assigns importance scores to code fragments -- corresponding to a subset of nodes in the abstract syntax tree -- indicating whether the presence of each fragment increases or decreases the likelihood of the given continuation.  PAST LIME perturbs semantically meaningful, non-overlapping code segments and queries the model’s conditional probability distribution, without requiring access to model gradients or internal parameters. Its output is independent of the sampling strategy used during generation and reflects the sensitivity of the continuation probability to structural changes in the code. Despite operating locally, the method scales to large codebases and remains computationally efficient.  Beyond standard explainability, PAST LIME enables analysis of arbitrary continuations, offering new opportunities for uncovering hidden biases, evaluating model behavior, and supporting model debugging. Through experiments on Stable-Code-3B, we show that PAST LIME yields explanations more aligned with code semantics than token-level baselines, providing developers with interpretable insights into the model’s decision-making process.
  author-bio: >- 
    A human being. Interested in ML, distributed systems, programming languages & formal verification.
  co-authors: Karol Kuźniak
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 50
  author-image: images/optimized/cfc-600x600/michal_sala.webp

- author-name: Pawel Struski
  title: "Competitive Market Behaviour of LLMs"
  author-title: "University of Warsaw"
  abstract: >- 
    This study explores the competitive market behaviour of Large Language Models (LLMs). We find that LLM agents exhibit systematic biases in economic decision-making tasks. In a simulated competitive market, we find that LLM buyer agents frequently bid their maximum reservation price, despite being instructed to buy at the lowest possible price. This leads to transaction prices above the competitive market equilibrium – a striking divergence from human behaviour in the same setting.  We arrive at this result by replicating Smith’s (1962) classic behavioural economics experiment using LLM agents (GPT-4.1-mini-2025-04-14). We simulate a market for a fictitious good, populated by two types of agents: buyers and sellers, each with a predefined reservation price. Buyers are tasked with purchasing at the lowest possible price (but not above their reservation price), and sellers with selling at the highest possible price (but not below their reservation price). Reservation prices are structured so as to create a downward-sloping demand curve and an upward-sloping supply curve. Economic theory, supported by Smith’s original experiments, predicts that such a market should converge to a competitive equilibrium where supply equals demand.  In our experiments, however, transaction prices and traded quantities consistently converge to levels above the competitive market equilibrium. Our preliminary analysis indicates that this deviation is primarily driven by non-competitive behaviour among buyer agents. Despite being instructed to maximize profits, buyers frequently bid their maximum price when asked to submit a bid, thus violating the standard assumption that agents seek to maximise utility (profits). Interestingly, this behaviour is not observed among sellers, despite near-identical (role-adjusted) prompts.  This asymmetry suggests that the LLM encodes a role-based behavioural bias: associating sellers with competitive behaviour and buyers with cooperative behaviour. When this bias is accounted for, the observed price deviation aligns with theoretical predictions from economics.  To our knowledge, this is the first study to apply economic theory as a tool for analysing LLM behaviour. Economic theory provides objective, consistent and tractable predictions about equilibrium outcomes in multi-agent systems. This offers a new lens for diagnosing and understanding LLM biases and decision-making patterns.   Looking ahead, we plan to extend our analysis to other models (including open-source models) and apply mechanistic interpretability techniques to identify the internal representations that drive this behaviour. Ultimately, this research could inform the design and control of LLM-powered multi-agent systems, guided by principles from mechanism design – a field at the intersection of economics and game theory.  References Smith, V. L. (1962). An Experimental Study of Competitive Market Behavior. Journal of Political Economy, 70(2), 111–137. https://doi.org/10.1086/258609
  author-bio: >- 
    Pawel Struski is a PhD student at the University of Warsaw. His research lies at the intersection of economics and machine learning.  He holds an MPhil degree in Economic Research from the University of Cambridge (2019) and a BSc degree in Economics from UCL (2018). He has previously worked as research assistant at the Institute for Fiscal Studies and as an economist in the financial sector.
  co-authors: 
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 51
  author-image: images/optimized/cfc-600x600/pawel_struski.webp

- author-name: Katarzyna Woźnica
  title: "SeFNet: Linking tabular datasets with semantic feature nets"
  author-title: "Warsaw University of Technology"
  abstract: >- 
    Tabular datasets play a significant role in wide range of machine learning applications. However, although they often address similar problems, tabular datasets are typically treated as standalone tasks. The opportunities of using previously solved problems are limited due to the lack of structured contextual information about their features and the lack of understanding of the relations between them. To overcome this limitation, we propose a new methodology called Semantic Feature Net (SeFNet), capturing the semantic meaning of the analyzed tabular features. By leveraging existing ontologies and domain knowledge, SeFNet opens up new opportunities for sharing insights between diverse predictive tasks. One such opportunity is the Dataset Ontology-based Semantic Similarity (DOSS) measure, which quantifies the similarity between datasets using relations across their features. In this paper, we present an example of SeFNet’s application prepared for a collection of predictive tasks in healthcare, with the features’ relations derived from the SNOMED-CT ontology. The proposed SeFNet methodology and the accompanying DOSS measure address the issue of limited contextual information in tabular datasets. By incorporating domain knowledge and establishing semantic relations between features, we enhance the potential for meta-learning and enable valuable insights to be shared across different predictive tasks.
  author-bio: >- 
    Katarzyna is a researcher at Warsaw University of Technology with a PhD in Computer Science. Her work centers on AutoML, hyperparameter optimization, and meta-learning, with a focus on human-in-the-loop methods and Automated Data Science. She collaborates with physicians to develop machine learning solutions for medical applications.
  co-authors: Piotr Wilczyński, Przemysław Biecek
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 52
  author-image: images/empty.png

- author-name: Stanisław Pawlak
  title: "Backdoor Vectors: a Task Arithmetic View on Backdoor Attacks and Defenses"
  author-title: "Warsaw University of Technology"
  abstract: >- 
    Model merging (MM) recently emerged as an effective method for combining large deep learning models. However, it poses significant security risks. Recent research shows that it is highly susceptible to backdoor attacks, which introduce a hidden trigger into a single fine-tuned model instance that allows the adversary to control the output of the final merged model at inference time. In this work, we propose a simple framework for understanding backdoor attacks by treating the attack itself as a task vector. Backdoor Vector (BV) is calculated as the difference between the weights of a fine-tuned backdoored model and fine-tuned clean model. BVs reveal new insights into attacks understanding and a more effective framework to measure their similarity and transferability. Furthermore, we propose a novel method that enhances backdoor resilience through merging dubbed Sparse Backdoor Vector (SBV) that combines multiple attacks into a single one. We identify the core vulnerability behind backdoor threats in MM: inherent triggers that exploit adversarial weaknesses in the base model. To counter this, we propose Injection BV Subtraction (IBVS) -- an assumption-free defense against backdoors in MM. Our results show that SBVs surpass prior attacks and is the first method to leverage merging to improve backdoor effectiveness. At the same time, IBVS provides a lightweight, general defense that remains effective even when the backdoor threat is entirely unknown.
  author-bio: >- 
    Stanisław Pawlak is a Ph.D. student and AI researcher working at Warsaw University of Technology. He received a M.Sc. degree in data science and a B.Sc. in applied computer science from the Warsaw University of Technology. Stanisław coauthored multiple publications on world top-tier AI conferences, including NeurIPS 2023 and CVPR 2024. He also worked as a programmer, AI engineer building ML-powered applications, and AI consultant. His research focuses on continual learning, generative models, and ML security. His latest efforts aim to understand backdoors in model merging learning paradigm.
  co-authors: Jan Dubiński, Daniel Marczak, Bartłomiej Twardowski
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 53
  author-image: images/optimized/cfc-600x600/stanislaw_pawlak.webp

- author-name: Bartosz Jezierski
  title: "Comparing Different Jailbreak Detection Methods"
  author-title: "Warsaw University of Technology"
  abstract: >- 
    As Large Language Models (LLMs) are increasingly deployed in production, their vulnerability to novel 'jailbreak' attacks poses a significant security risk. Popular safeguards often fail to generalize to these unseen threats, creating a critical security gap. We evaluate this generalization failure by comparing prominent open-source safeguards against targeted, data-efficient fine-tuning of an encoder only (ModernBERT) and a decoder only (Gemma 3) model. Our experiments on the established benchmark indeed confirm the critical generalization gap against unseen jailbreaks. Guardrails like Llama Guard 2 and 3 achieve less than 55% accuracy on the unseen RedTeams2K dataset. We discover that resource-efficient fine-tuning models yield superior performance compared to baseline open-source safeguards. While even simple head-tuning of ModernBERT surpasses the baseline, more comprehensive LoRA fine-tuning on Gemma yields the best results. However, the largest performance gain, which boosts detection accuracy to over 95%, comes from introducing a small, curated set of just 200 similar jailbreak examples. By breaking down performance by category, our analysis exposed a significant, shared blind spot. We found that detecting prompts designed to violate privacy was a critical challenge that affected every model we tested. Our findings demonstrate that effective LLM safety is found not in large, static guardrails, but in an agile strategy that prioritizes rapidly fine-tuning smaller, general-purpose models on new, similar attack patterns as they appear.
  author-bio: >- 
    Data Science student at Warsaw University of Technology.
  co-authors: Mateusz Jarosz, Vladimir Zaigrajew
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 54
  author-image: images/empty.png

- author-name: Paulina Kaczyńska
  title: "Immunogenic cell death detection and classification with Machine Learning"
  author-title: "IPPT PAN"
  abstract: >- 
    Viral infection can lead to regulated cell deaths that may have both non-immunogenic (apoptosis) or immunogenic character (pyroptosis or necroptosis). As immunogenic deaths allow adaptive immune responses to develop, differentiating and describing these processes would give us important insights to the development of immunogenic responses during various viral infections.  Current tools predominantly detect apoptosis or general cell death, with relatively few methods capable of distinguishing between specific types. In particular, pyroptosis remains underexplored. Some recent approaches attempt to differentiate between apoptosis and ferroptosis or necrosis, but these typically operate at the image level rather than at single-cell resolution. Moreover, most existing methods rely on fluorescent markers that either translocate to dying cells or respond to caspase activity specific to a given death pathway. This fluorescence-based approach is constrained by the practical limit of using only a few simultaneous markers, reducing the ability to visualize other critical aspects of virus-cell interactions.  To address these limitations, we developed a dataset for detecting and classifying apoptosis and pyroptosis based on cell morphology in brightfield microscopy images. Pyroptotic cells were manually annotated by experts using morphological criteria, while propidium iodide staining provided reference information on cell death. The dataset supports two use cases: image classification (single cells and their immediate surroundings) and object detection with bounding boxes. All data were collected from live-cell time-lapse microscopy, enabling temporal analysis. Quantitative features extracted from the cells are also available in tabular format.  We evaluate the performance of deep convolutional neural networks on this dataset—first in the classification setting and then in the object detection task. Finally, we explore several strategies for incorporating temporal information to improve detection and classification performance over time.
  author-bio: >- 
    Paulina is currently in the first year of her PhD at the Institute of Fundamental Technological Research of the Polish Academy of Sciences (IPPT PAN). Her research focuses on modeling regulatory networks at single-cell resolution using machine learning methods. She holds a Bachelor's degree in Physics and a Bachelor's degree in Cognitive Science, both obtained through the College of Inter-Faculty Individual Studies in Mathematics and Natural Sciences (MISMaP) at the University of Warsaw. She later completed a Master's degree in Machine Learning at the University of Warsaw, where her thesis explored the visualization of node features using Accumulated Local Effects in Graph Neural Networks.
  co-authors: Nazanin Amirinejad, Tomasz Lipniacki
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 55
  author-image: images/empty.png

- author-name: Ryszard Staruch
  title: "Adapting LLMs for Minimal-edit Grammatical Error Correction"
  author-title: "Adam Mickiewicz University"
  abstract: >- 
    Decoder-only large language models have shown superior performance in the fluency-edit English Grammatical Error Correction, but their adaptation for minimal-edit English GEC is still underexplored. To improve their effectiveness in the minimal-edit approach, we explore the error rate adaptation topic and propose a novel training schedule method. Our experiments set a new state-of-the-art result for a single-model system on the BEA-test set. We also detokenize the most common English GEC datasets to match the natural way of writing text. During the process, we find that there are errors in them. Our experiments analyze whether training on detokenized datasets impacts the results and measure the impact of the usage of the datasets with corrected erroneous examples. To facilitate reproducibility, we have released the source code used to train our models.
  author-bio: >- 
    Ryszard is a PhD student at Adam Mickiewicz University and a machine learning researcher at the Center for Artificial Intelligence AMU. His main research areas are grammatical error correction and information retrieval. He is the author of papers presented at international NLP conferences and the winner of the multilingual grammatical error correction shared task MultiGEC-2025.
  co-authors: Filip Graliński, Daniel Dzienisiewicz
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 56
  author-image: images/optimized/cfc-600x600/ryszard_staruch.webp

- author-name: Łukasz Niedźwiedzki
  title: "Exploiting Spatial Structure with Time Series Foundation Models"
  author-title: "University of Warsaw/Taxus IT"
  abstract: >- 
    Multivariate time series data is pervasive in real-world applications, from climate monitoring and traffic forecasting to clinical diagnostics. Despite this, current foundation models like MOMENT often fall short in capturing the complex structure inherent to such data. In particular, MOMENT processes each channel independently during operations like patching, which limits its ability to model the rich inter-variable relationships that are often critical in real-world settings. Many domains exhibit strong spatial or functional dependencies between variables - for example, between nearby sensors in a physical environment - which are ignored by treating channels in isolation.  This project addresses these limitations by integrating graph neural networks with MOMENT to explicitly model relationships between channels. By embedding spatial and inter-variable dependencies into the model architecture, we aim to better capture the underlying structure of multivariate time series data. This integration introduces structural inductive biases that encourage the model to learn more meaningful representations and to generalize more effectively across different datasets and domains.  We conduct extensive evaluations to assess both the predictive performance and the internal representations learned by the model. Through a variety of analyses, we investigate how incorporating graph-based relational modeling impacts the way MOMENT encodes and utilizes cross-variable information, shedding light on the mechanisms that drive improved performance.
  author-bio: >- 
    Łukasz Niedźwiedzki is a Master's student at the Faculty of Physics, University of Warsaw. He also works as a Machine Learning Engineer at Taxus IT and actively participates in research at the Auton Lab at Carnegie Mellon University and the MI2 Lab at Warsaw University of Technology.
  co-authors: Abigail Turner, Mononito Goswami, Artur Dubrawski
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 57
  author-image: images/optimized/cfc-600x600/lukasz_niedzwiedzki.webp

- author-name: Hubert Plisiecki
  title: "Words Apart: Mapping Psychological Differences Through Semantic Space"
  author-title: "Polish Academy of Science"
  abstract: >- 
    This study introduces a new method for analyzing how word meanings shift across psychological groups, using 1300 essays from participants who also completed measures of attitudes like collective narcissism and trust in science. We examine how people high versus low on these psychological dimensions use language differently when discussing topics such as national identity, migration, and climate change. Our word2vec-based technique identifies how key concepts take on different meanings between contrasting groups by comparing word associations in their respective language samples. By retro-fitting target words based on an external pretrained word2vec model, we bypass the common word2vec data sparsity problem, allowing us to capture meaningful shifts in language use. The method provides two valuable insights for psychological research: (1) statistical inference (p-values) of semantic differences between groups through, and (2) visualization of how concepts relate differently across psychological divides by examining nearby words in each group's semantic space. This method expands the applications of machine learning based NLP methods within the realm of social sciences, offering a new window into how individual differences manifest in language use, but can also serve as inspiration for repurposing older NLP methods to new tasks.
  author-bio: >- 
    Hubert Plisiecki is an AI researcher specializing in the application of machine learning and NLP to research in social sciences, particularly in modeling psychological phenomena in text. Currently completing his PhD at the Polish Academy of Sciences, Hubert has authored multiple publications on innovative machine learning approaches in social sciences, including articles in journals such as Behavior Research Methods. He is also a co-founder of the Society for Open Science, promoting research quality and transparency in Poland and abroad.
  co-authors: Paweł Lenartowicz, Artur Pokropek, Maria Flakus
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 58
  author-image: images/optimized/cfc-600x600/hubert_plisiecki.webp

- author-name: Dawid Plaskowski
  title: "Beyond Context Limits: Retrieval-Augmented Time Series Forecasting with Prior-data Fitted Networks and Time Series Foundation Models"
  author-title: "Auton Lab @ Carnegie Mellon Univeristy / Łukasiewicz Research Network"
  abstract: >- 
    In-context learning has emerged as a powerful paradigm in large language models, enabling few-shot generalization from carefully chosen examples. We are interested in investigating this capability beyond language, focusing on the generalization of Prior-data Fitted Networks (PFNs), pretrained only on synthetic data for tabular tasks, to time series. Prior work on tabular foundation models such as TabPFN, applied to time series forecasting tasks, shows that on GIFT-eval only ~40% of the context window is effectively used, and adding more in-context examples can sharply degrade performance. This motivates the question: can retrieval better utilize context, matching or exceeding performance with fewer examples and extending the effective context window through targeted selection? We propose a retrieval-augmented forecasting framework for tabular foundation models such as TabPFN and Mitra adapting principles from Retrieval-Augmented Generation (RAG) in LLMs. Our approach uses MOMENT, a time-series foundation model, as the retrieval module, drawing from both domain-specific sources and large-scale corpora such as TimeSeriesPile to select semantically relevant time series at test time, which are then incorporated into the model’s in-context examples.
  author-bio: >- 
    I am an aspiring researcher exploring the inner workings of neural networks through interpretability and neural scaling laws. My experience spans applied machine learning in both academic and industrial settings, including two research internships at Carnegie Mellon University’s Robotics Institute Summer Scholars program, work at the Łukasiewicz Research Network on natural language processing projects, and contributions at a drone technology startup.
  co-authors: Willa Potosnak, Michał Williński, Artur Dubrawski
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 59
  author-image: images/optimized/cfc-600x600/dawid_plaskowski.webp

- author-name: Julian Kędys
  title: "Interpretable Coupling Structure Beyond Deep Learning: Probabilistic and Energy-Based Modelling of Multivariate (Neural) Dynamics"
  author-title: "Poznan Supercomputing and Networking Center, PAS"
  abstract: >- 
    Many scientific problems present high-dimensional, noisy and small-N observations where deep nets can be data-hungry and opaque. I will present a set of methods that combines energy-based models and probabilistic/Bayesian inference to model multivariate dynamics with interpretable coupling structure. Concretely, we use the pairwise maximum-entropy model (PMEM) - the Ising/Boltzmann machine without hidden units - as an undirected Markov random field over binary (or binarised) variables, giving a principled, minimum-assumption distribution that matches empirical first- and second-order statistics.   Methodologically, I will cover three complementary estimators that trade off bias, variance and compute: (i) exact maximum likelihood via full state enumeration for small systems; (ii) a scalable pseudo-likelihood optimiser with safeguarded line search and L2 regularisation; and (iii) a variational Bayes formulation that places Gaussian priors on fields and couplings to yield posterior means/precisions and credible intervals-useful when data are limited. Sampling-based MCMC (Numba-accelerated Metropolis, adaptive multi-chain with R-hat) serves both for model checking and for deriving kinetic summaries.   Beyond fitting, the methodology turns parameters into mechanistic diagnostics. We compute phase-diagram analyses in (μ,σ) space of the coupling matrix to place subjects/groups relative to critical regimes (qualitative characterisation of the system's dynamics' organisation); derive energy landscapes and disconnectivity graphs that expose stable states and transition barriers; and construct state-to-state transition matrices, dwell times and transition pathways using single-spin-flip kinetics, providing a kinetic extension of the equilibrium model. Bootstrap + ridge shrinkage give robust control baselines, while balanced objective weights stabilise subject positioning.   Strengths include (a) interpretability by design (explicit couplings and energy), (b) small-data suitability (max-entropy constraints, VB uncertainty, PL scalability), and (c) generative capability (the model defines p(s); MCMC draws synthetic trajectories). I will also outline practical limitations-e.g., binarisation assumptions, scaling to very large N, and equilibrium vs. real-world dynamics-and discuss mitigations (regularisation, block bootstrap uncertainty, kinetic extensions, and when deep learning is preferable).   Although the talk will be illustrated on resting-state neural dynamics in neurodevelopmental cohorts - mapping altered basins, abnormal couplings between regions, and temporal signatures - the methodology is domain-agnostic. It applies to any system with meaningful binary (or discretised) states: genomics (gene on/off), proteomics contacts, ecology, and complex systems in physics or social science. The focus is on the general principles and reusable methods, not domain specifics.   The session will include a short illustration of the visual analytics (phase diagrams; probability fit indices; barrier distributions) and several engineering improvements (adaptive samplers; robust contour-based positioning) that make these classical models practical for modern hypothesis-testing and ML-enabled research workflows. Overall, the talk advocates a probabilistic and energy-based alternative - complementary to deep learning - whenever interpretability, uncertainty, and mechanistic structure are primary goals, including in scientific contexts.
  author-bio: >- 
    Julian earned a B.Sc. in Artificial Intelligence from Poznań University of Technology in 2024, where he was an active member of the GHOST (“Group of Horribly Optimistic STatisticians”) Student Scientific Group. During the programme, he spent two semesters at the University of Luxembourg, where he also completed a three-month research placement in applied reinforcement learning and computer vision.  Since graduating, Julian has been building on his machine-learning background by pivoting into computational neuroscience. In late 2024, he undertook a three-month research internship at the International Research Center for Neurointelligence (IRCN), University of Tokyo, studying abnormal brain dynamics in neurodevelopmental conditions, including autism spectrum disorder (ASD), through latent-representation analysis and mathematical modelling with tools drawing on statistical physics and machine learning.  Since December 2024, he has been affiliated with the Poznań Supercomputing and Networking Center (PSNC), PAS, Department for Digital Medicine. His work spans computational neuroscience, deep-learning applications for computational biology and medicine, and exploratory analyses of quantum-computing applications in the life sciences and engineering.
  co-authors: Cezary Mazurek
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 60
  author-image: images/optimized/cfc-600x600/julian_kedys.webp

- author-name: Kajetan Dymkiewicz
  title: "Unpacking the Potential: Refining and Evaluating Language Models Across Dimensions"
  author-title: "University of Cambridge"
  abstract: >- 
    Large Language Models (LLMs) demonstrate strong performance across tasks and languages, but the mechanisms of cross-dimensional transfer, how gains in one capability, task, or language influence others, remain poorly understood. In this work, we consider four such dimensions - language, task type, model family, and model size - and systematically evaluate transfer patterns across them. We present a systematic evaluation of transfer patterns across seven state-of-the-art models from the LLaMA 3 and Qwen 2.5 families, spanning sizes from 0.5B to 8B parameters. Using multilingual benchmarks covering reasoning, factuality, coding, fairness, and math, we fine-tune models on individual task–language pairs and evaluate their performance across the entire evaluation space. Our analysis reveals a consistent asymmetry: within-task, cross-lingual transfer is broadly beneficial, while cross-task transfer frequently incurs collateral harm. Transfer is structured by donor–recipient roles: certain hub languages (e.g., Turkish, Dutch) and tasks (e.g., Factuality, Fairness) export substantial gains but often degrade others, whereas Coding and Math act as comparatively benign donors yet brittle recipients. The results suggest that effective fine-tuning strategies must explicitly account for these dynamics, balancing on-task improvements with the risk of off-task degradation to unlock the full potential of LLMs across languages and capabilities.
  author-bio: >- 
    Kajetan is a PhD student at the Language Technology Lab at University of Cambridge. He obtained his MSc in AI at King's College London and a BSc in Computer Science at Wrocław University of Science and Technology. His research focuses on the intersection of LLM efficiency and AI Safety.
  co-authors: Ivan Vulic, Helen Yannakoudakis, Eilam Shapira, Roi Reichart
  date: 17.10.2025
  time: 12:15 - 13:45
  room: 
  session: Poster Session 2
  id: 61
  author-image: images/optimized/cfc-600x600/kajetan_dymkiewicz.webp
