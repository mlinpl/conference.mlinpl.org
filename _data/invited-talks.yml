- title: Towards Real-World Fact-Checking with Large Language Models
  abstract: >-
    Misinformation poses a growing threat to our society. It has a severe impact on public health by promoting fake cures or vaccine hesitancy, and it is used as a weapon during military conflicts to spread fear and distrust. Current research on natural language processing (NLP) for fact-checking focuses on identifying evidence and predicting the veracity of a claim. People’s beliefs, however, often do not depend on the claim and rational reasoning but on credible content that makes the claim seem more reliable, such as scientific publications or visual content that was manipulated or stems from unrelated contexts. To combat misinformation, we need to show (1) “Why was the claim believed to be true?“, (2) “Why is the claim false?“, (3) “Why is the alternative explanation correct?“. In this talk, I will zoom in on two critical aspects of such misinformation supported by credible though misleading content. Firstly, I will present our efforts to dismantle misleading narratives based on fallacious interpretations of scientific publications. Secondly, I will show how we can use multimodal large language models to (1) detect misinformation based on visual content and (2) provide strong alternative explanations for the visual content.
  time: 12:15 - 13:15
  room: Main Hall
  date: Thursday / 7 November
  id: 1
  author-name: Iryna Gurevych
  author-title: Technical University of Darmstadt
  author-image: images/optimized/speakers-600x600/IrynaGurevych.webp
  author-bio: >-
    Iryna Gurevych is Professor of Ubiquitous Knowledge Processing in the Department of Computer Science at the Technical University of Darmstadt in Germany. She also is an adjunct professor at MBZUAI in Abu-Dhabi, UAE, and an affiliated professor at INSAIT in Sofia, Bulgaria. She is widely known for fundamental contributions to and innovative applications of natural language processing and machine learning. Professor Gurevych is a past president of the Association for Computational Linguistics (ACL), the leading professional society in the field of natural language processing. Her many accolades include being a Fellow of the ACL, an ELLIS Fellow, and the recipient of an ERC Advanced Grant.
  google-scholar: https://scholar.google.com/citations?user=t3A39e8AAAAJ&hl=en

- title: "Evolving programs with LLMs"
  abstract: >-
    In this talk I will present FunSearch, a method to search for new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated “evaluator”, which guards against hallucinations and incorrect ideas. By iterating back-and-forth between these two components, initial solutions “evolve” into new knowledge. I will present the application of FunSearch to a central problem in extremal combinatorics — the cap set problem — where we discover new constructions of large cap sets going beyond the best known ones, both in finite dimensional and asymptotic cases. This represents the first discoveries made for established open problems using LLMs. Then, I will present the application of FunSearch to an algorithmic problem, online bin packing, which showcases the generality of the method. In this use case, FunSearch finds new heuristics that improve upon widely used baselines. I will conclude the talk by discussing the implications of searching in the space of code.
  time: 12:15 - 13:15
  room: Halls A & B
  date: Thursday / 7 November
  id: 2
  author-name: Bernardino Romera Paredes
  author-title: Google DeepMind
  author-image: images/optimized/speakers-600x600/BernardinoRomeraParedes.webp
  author-bio: >-
    Bernardino is a researcher at Google DeepMind, where he has been a core team member of AlphaFold2 for protein folding, and AlphaTensor for matrix multiplication algorithms. More recently, he initiated FunSearch, a system which uses Large Language Models for program search and has discovered new mathematical knowledge. Long before that, in 2009, Bernardino started his AI journey by studying the MSc Computational Statistics and Machine Learning at UCL. In 2010 he started a PhD, also at UCL, supervised by Prof. Massimiliano Pontil and Prof. Nadia Berthouze, and in 2013 he also did an internship at Microsoft Research. After finishing his PhD in 2014, he joined the Torr Vision Group as a Postdoc at the University of Oxford, researching about semantic segmentation and zero-shot learning. He has several papers published in Nature, as well as in machine learning conferences like NeurIPS and ICML. His main motivation is to leverage the power of AI to bring light to important scientific problems.
  google scholar: https://scholar.google.com/citations?user=_LC9U6EAAAAJ

- title: "Explainable AI for LLMs"
  abstract: >-
    Large Language Models are prone to biased predictions and hallucinations, underlining the paramount importance of understanding their model-internal reasoning process. However, achieving faithful explanations for the entirety of a black-box transformer model and maintaining computational efficiency is difficult. This talk will present a recent extension of the Layer-wise Relevance Propagation (LRP) attribution method to handle attention layers, which addresses this challenge effectively. Our method is the first to faithfully and holistically attribute not only input but also latent representations of transformer models with the computational efficiency similar to a singular backward pass. Since the LRP is a model-aware XAI method, it not only identifies the relevant features in input space (e.g., pixels or words) but also provides deep insights into the model’s representation and the reasoning process. Through extensive evaluations against existing methods on Llama 2, Flan-T5 and the Vision Transformer architecture, we demonstrate that our proposed approach surpasses alternative methods in terms of faithfulness and enables the understanding of latent representations, opening up the door for concept-based explanations.
  time: 14:45 - 15:45
  room: Halls A & B
  date: Thursday / 7 November
  id: 3
  author-name: Wojciech Samek
  author-title: Technical University of Berlin
  author-image: images/optimized/speakers-600x600/WojciechSamek.webp
  author-bio: >-
    Wojciech Samek is a Professor in the EECS Department at TU Berlin and is jointly heading the AI Department at Fraunhofer HHI. He is a Fellow at BIFOLD - Berlin Institute for the Foundation of Learning and Data, the ELLIS Unit Berlin, and the DFG Research Unit DeSBi. Furthermore, he is a Senior Editor for IEEE TNNLS, an Associate Editor for Pattern Recognition, and an elected member of the IEEE MLSP Technical Committee and Germany's Platform for AI. He also serves as a member of the scientific advisory board of IDEAS NCBR - Polish Centre of Innovation in the Field of Artificial Intelligence. Wojciech has co-authored more than 200 papers and was the leading editor of the Springer book "Explainable AI: Interpreting, Explaining and Visualizing Deep Learning" (2019), and co-editor of the open access Springer book “xxAI – Beyond explainable AI” (2022). He has served as Program Co-Chair for IEEE MLSP'23, and as Area Chair for NAACL'21 and NeurIPS'23, and is a recipient of multiple best paper awards, including the 2020 Pattern Recognition Best Paper Award and the 2022 Digital Signal Processing Best Paper Prize.
  google scholar: https://scholar.google.com/citations?user=7aQwO08AAAAJ

- title: "Perceiving, Understanding, and Interacting through Touch"
  abstract: >-
    Touch is a crucial sensor modality in both humans and robots. Recent advances in tactile sensing hardware have resulted -- for the first time -- in the availability of mass-produced, high-resolution, inexpensive, and reliable tactile sensors. In this talk, I will argue for the importance of creating a new computational field of "Touch processing" dedicated to the processing and understanding of touch through the use of Artificial Intelligence. This new field will present significant challenges both in terms of research and engineering, but also significantly opportunities in digitizing a new sensing modality. To conclude, I will present some applications of touch in robotics and discuss other future applications.
  time: 09:30 - 10:30
  room: Main Hall
  date: Friday / 8 November
  id: 4
  author-name: Roberto Calandra
  author-title: Technical University of Dresden
  author-image: images/optimized/speakers-600x600/RobertoCalandra.webp
  author-bio: >-
    Roberto Calandra is a Full (W3) Professor at the Technische Universität Dresden where he leads the Learning, Adaptive Systems and Robotics (LASR) lab. Previously, he founded at Meta AI (formerly Facebook AI Research) the Robotic Lab in Menlo Park. Prior to that, he was a Postdoctoral Scholar at the University of California, Berkeley (US) in the Berkeley Artificial Intelligence Research (BAIR) Lab. His education includes a Ph.D. from TU Darmstadt (Germany), a M.Sc. in Machine Learning and Data Mining from the Aalto university (Finland), and a B.Sc. in Computer Science from the Università degli Studi di Palermo (Italy). His scientific interests are broadly at the conjunction of Robotics and Machine Learning, with the goal of making robots more intelligent and useful in the real world. Among his contributions is the design and commercialization of DIGIT -- the first commercial high-resolution compact tactile sensor, which is currently the most widely used tactile sensor in robotics. Roberto served as Program Chair for AISTATS 2020, as Guest Editor for the JMLR Special Issue on Bayesian Optimization, and has previously co-organized over 16 international workshops (including at NeurIPS, ICML, ICLR, ICRA, IROS, RSS). In 2024, he received the IEEE Early Academic Career Award in Robotics and Automation.
  google scholar: https://scholar.google.ch/citations?user=fA0rYxMAAAAJ

- title: "molecule.one: Candid Stories and Hard Lessons from our Journey Building an AI for Science Startup"
  abstract: >-
    For the first time, we’re sharing the story behind Molecule.One. Founded in 2018 to make making medicines faster, we built the first generative deep learning product for chemistry. We battled — as early as in 2019 — problems that we know understand as hallucination and alignment. We then almost went under. We raised back building the most comprehensive reaction dataset in our highly automated laboratory, just to face another almost fatal adversity. In the process, we found ourselves immersed in a broader and sweeping change in the AI landscape. We offer a candid look at ups and downs, distilling insights and giving broader predictions about the future of AI-first companies.
  time: 09:30 - 10:30
  room: Hall A
  date: Friday / 8 November
  id: 5
  author-name: Stanisław Jastrzębski
  author-title: Molecule.one
  author-image: images/optimized/speakers-600x600/StanislawJastrzebski.webp
  author-bio: |-
    Stanislaw Jastrzebski serves as the CTO and Chief Scientist at Molecule.one, a biotech startup in the drug discovery space. He is passionate about improving the fundamental aspects of deep learning and applying it to automate scientific discovery. He completed his postdoctoral training at New York University in deep learning.
    
    His PhD thesis was based on work on foundations of deep learning done during research visits at MILA (with Yoshua Bengio) and the University of Edinburgh (with Amos Storkey). He received his PhD from Jagiellonian University, advised by Jacek Tabor. Beyond academia, he gained industrial experience at Google, Microsoft and Palantir. In his scientific work, he has published at leading machine learning venues (NeurIPS, ICLR, ICML, JMLR, Nature SR). He is also actively contributing to the machine learning community as an Area Chair (most recently NeurIPS '23) and as an Action Editor for TMLR. At Molecule.one, he leads technical teams working on software for synthesis planning based on deep learning, public data sources, and experiments from a highly automated laboratory.
  google-scholar: https://scholar.google.com/citations?user=YQ5rrk4AAAAJ

- title: Inductive Biases for Robot Reinforcement Learning
  abstract: >-
    Autonomous robots that can assist humans in situations of daily life have been a long standing vision of robotics, artificial intelligence, and cognitive sciences. A first step towards this goal is to create robots that can learn tasks triggered by environmental context or higher level instruction. However, learning techniques have yet to live up to this promise as only few methods manage to scale to high-dimensional manipulator or humanoid robots. In this talk, we investigate a general framework suitable for learning motor skills in robotics which is based on the principles behind many analytical robotics approaches. To accomplish robot reinforcement learning learning from just few trials, the learning system can no longer explore all learn-able solutions but has to prioritize one solution over others – independent of the observed data. Such prioritization requires explicit or implicit assumptions, often called ‘induction biases’ in machine learning. Extrapolation to new robot learning tasks requires induction biases deeply rooted in general principles and domain knowledge from robotics, physics and control. Empirical evaluations on a several robot systems illustrate the effectiveness and applicability to learning control on an anthropomorphic robot arm. These robot motor skills range from toy examples (e.g., paddling a ball, ball-in-a-cup) to playing robot table tennis, juggling and manipulation of various objects.
  time: 16:10 - 17:10
  room: Hall A
  date: Friday / 8 November
  id: 6
  author-name: Jan Peters
  author-title: Technical University of Darmstadt
  author-image: images/optimized/speakers-600x600/JanPeters.webp
  author-bio: >-
    Jan Peters is a full professor (W3) for Intelligent Autonomous Systems at the Computer Science Department of the Technische Universitaet Darmstadt.
    Jan Peters has received the Dick Volz Best 2007 US PhD Thesis Runner-Up Award, the Robotics: Science & Systems – Early Career Spotlight, the INNS Young Investigator Award, and the IEEE Robotics & Automation Society’s Early Career Award as well as numerous best paper awards. In 2015, he received an ERC Starting Grant and in 2019, he was appointed as an IEEE Fellow and in 2020 an ELLIS fellow.
  google-scholar: https://scholar.google.pl/citations?hl=en&user=-kIVAcAAAAAJ

- title: "RLHF as conditioning on human preferences"
  abstract: >-
    The dominant approach to aligning large language models with human preferences is reinforcement learning from human feedback (RLHF): finetuning an LLM to maximise a reward function representing human preferences. In this talk, I will try to present a complementary perspective: that we can also think about LLM alignment not in terms of reward maximisation but in terms of conditioning LMs on evidence about human preferences. First, I will explain how minimizing the classic RLHF objective is equivalent to approximate Bayesian inference. Then, I will go on to argue that the conditioning view also inspires other approaches to LLM alignment. I will discuss three: minimising different f-divergences from a target distribution, learning from feedback expressed in natural language and aligning LMs already during pretraining by directly learning a distribution conditional on alignment score. I will end the talk discussing how they correspond to conditioning subsequent priors on subsequent pieces of evidence about human preferences.
  time: 16:10 - 17:10
  room: Hall B
  date: Friday / 8 November
  id: 7
  author-name: Tomek Korbak
  author-title: UK AI Safety Institute
  author-image: images/optimized/speakers-600x600/TomaszKorbak.webp
  author-bio: >-
    Tomek Korbak is a Senior Research Scientist at the UK AI Safety Institute working on safety cases for frontier models. Previously, he was a Member of Technical Staff at Anthropic working on honesty. Before that, he did a PhD at the University of Sussex focusing on RL from human feedback (RLHF) and spent time as a visiting researcher at NYU working with Ethan Perez, Sam Bowman and Kyunghyun Cho. He studied cognitive science, philosophy and physics at the University of Warsaw.
  google scholar: https://scholar.google.com/citations?user=YQ5rrk4AAAAJ

- title: "Unveiling the Potential of AI-enabled In-silico Trials in Medical Innovation"
  abstract: >-
    The rapid introduction of novel medical technologies necessitates swift, reliable scientific validation of their safety and efficacy to protect patient welfare. Traditional clinical trials, while essential, face challenges such as detecting low-frequency side effects, high costs, and practical limitations, especially with paediatric patients, rare diseases, and underrepresented ethnic groups. In-silico trials (IST), powered by Computational Medicine, offer a promising solution by using computer simulations to test medical products on virtual patient populations. This approach allows for the a-priori optimisation of clinical outcomes, thorough risk assessment, and failure mode analysis before human trials. Although in-silico evidence is still emerging, it has the potential to revolutionise health and life sciences R&D and regulatory processes.
  time: 09:30 - 10:30
  room: Main Hall
  date: Saturday / 9 November
  id: 8
  author-name: Alejandro Frangi
  author-title: University of Manchester
  author-image: images/optimized/speakers-600x600/AlejandroFrangi.webp
  author-bio: |- 
    Prof. Alejandro Frangi FREng, holds the Bicentennial Turing Chair in Computational Medicine at the University of Manchester, UK, with joint appointments in the Schools of Computer Science and Health Science. Additionally, he is the Royal Academy of Engineering Chair in Emerging Technologies, specialising in Precision Computational Medicine for in silico trials of medical devices. He serves as the Director of the Christabel Pankhurst Institute for Health Technology Research and Innovation and is a Fellow at the Alan Turing Institute. Recently, his research vision was recognised with an ERC Advanced Grant from the European Research Council. He leads the InSilicoUK Pro-Innovation Regulations Network (www.insilicouk.org). 
    
    Professor Frangi's main research interests lie at the crossroads of medical image analysis and modelling with an emphasis on machine learning (phenomenological models) and computational physiology (mechanistic models). His work has had a profound impact on the field, particularly in the areas of cardiovascular, musculoskeletal and neurosciences. He is particularly interested in statistical methods applied to population imaging and in silico clinical trials. 
    
    Prof. Frangi's contributions to the field have been widely recognised. He has received numerous accolades, including the IEEE Engineering in Medicine and Biology Technical Achievement Award (2021) and Early Career Award (2006). In 2011, he was honored with the UPF Medal for his service as Dean of the Escuela Politècnica Superior. He also received the ICREA-Academia Prize from the Institució Catalana de Recerca i Estudis Avançats (ICREA) in 2008, a President's International Initiative Award from the Chinese Academy of Science in 2019. Prof. Frangi has also edited a textbook on Medical Image Analysis, published in the MICCAI-Elsevier Book Series by Academic Press.
  google scholar: https://scholar.google.com/citations?user=ieLRNKMAAAAJ

- title: "Modern Bayesian Experimental Design"
  abstract: >-
    Bayesian experimental design (BED) provides a powerful and general framework for optimizing the design of experiments. However, its deployment often poses substantial computational challenges that can undermine its practical use. In this talk, I will outline how recent advances have transformed our ability to overcome these challenges and thus utilize BED effectively, before discussing some key areas for future development in the field.   time: 09:30 - 10:30
  room: Hall A
  date: Saturday / 9 November
  id: 9
  author-name: Tom Rainforth
  author-title: University of Oxford
  author-image: images/optimized/speakers-600x600/TomRainforth.webp
  author-bio: >-
    Tom is a Senior Researcher in Machine Learning and leader of the RainML Research Lab at the Department of Statistics in the University of Oxford. He is the principal investigator for the ERC Starting Grant Data-Driven Algorithms for Data Acquisition. His research covers a wide range of topics in and around machine learning and experimental design, with areas of particular interest including Bayesian experimental design, deep learning, representation learning, generative models, Monte Carlo methods, active learning, probabilistic programming, and approximate inference.
  google scholar: https://scholar.google.com/citations?user=ieLRNKMAAAAJ

- title: "Computer Vision in the age of LLMs"
  abstract: >-
    I will discuss how computer vision has changed with the integration of language and the advent of LLMs, with focus on the recent works of our group. Depending on the audience's familiarity, I may spend most of the time covering the way these modalities are integrated via SigLIP, CapPa, and PaLI, as well as touch on some fairness and cultural diversity aspects ("No Filter" paper), or spend more time on the advanced way in which classically "typical vision" tasks such as detection, segmentation, monocular depth, are finding their way into VLMs and the standard language-modeling approach, covering UViM, RL-tuning, GIVT, and more recent approaches towards fully end-to-end multimodal learning.
  time: 16:10 - 17:10
  room: Hall A
  date: Saturday / 9 November
  id: 10
  author-name: Lucas Beyer
  author-title: Google DeepMind
  author-image: images/optimized/speakers-600x600/LucasBeyer.webp
  author-bio: >-
    Lucas grew up in Belgium wanting to make video games and their AI. He went on to study mechanical engineering at RWTH Aachen in Germany, then did a PhD in robotic perception and computer vision there too. Now, he is a staff research scientist at Google DeepMind (formerly Brain) in Zürich, leading multimodal vision-language research.
  google-scholar: https://scholar.google.com/citations?user=p2gwhK4AAAAJ

- title: Improving Foundation Models (with academic compute)
  abstract: >-
    I will talk about how we can build on top of pretrained Foundation Models to achieve better models for vision, language, audio and multi-modal tasks. First I will show that despite its strong performance, DINOv2 and other vision backbones often lack spatial understanding of images. To counteract this, we use NeCo, a new post-pretraining approach based on patch-nearest neighbors, which significantly improves the dense performances of this and any other model despite using only 16 GPU hours. Next I will introduce two parameter-efficient finetuning methods for LLMs and for VLMs that significantly reduce the amount of parameters required for successfully tuning these models. Finally, I will present our latest work, where we show that gradients from self-supervised losses can be successfully used as features for improved retrieval performances across vision, audio and text.
  time: 16:10 - 17:10
  room: Hall B
  date: Saturday / 9 November
  id: 11
  author-name: Yuki Asano
  author-title: University of Technology Nuremberg
  author-image: images/optimized/speakers-600x600/YukiAsano.webp
  author-bio: >-
    Yuki Asano is the head of the Fundamental AI (FunAI) Lab and full Professor at the University of Technology Nuremberg. Prior to this, Yuki lead the QUVA lab at the University of Amsterdam, where he closely collaborated with Qualcomm AI Research. His PhD was at the Visual Geometry Group (VGG) at the University of Oxford, where he worked with Andrea Vedaldi and Christian Rupprecht. Also, he loves running, the mountains, and their combination.
  google scholar: https://scholar.google.com/citations?user=CdpLhlgAAAAJ