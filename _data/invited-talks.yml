# TEMPLATE
# - title:
#  abstract: >-
#  time:
#  room:
#  date:
#  id:
#  author-name:
#  author-title:
#  author-image:
#  author-bio: >-
#  google-scholar:
#  slides:

- title: Causal representation learning in temporal settings with actions
  abstract: |-
    Causal inference reasons about the effect of unseen interventions or external manipulations on a system. Similar to classic approaches to machine learning, it typically assumes that the causal variables of interest are given from the outset. However, real-world data often comprises high-dimensional, low-level observations (e.g., pixels in a video) and is thus usually not structured into such meaningful causal units. Causal representation learning aims at addressing this gap by learning high-level causal variables along with their causal relations directly from raw, unstructured data, e.g. images, videos or text.

    In this talk I will focus on learning causal representations from temporal sequences, e.g. sequences of images that capture the state of an environment. In particular I will describe some of our work in which we leverage perturbations of an underlying system, e.g. the effects of actions performed by an agent in an environment, to provably identify causal variables and their relations from high-dimensional observations up to component-wise transformations and permutations in an unsupervised way. This allows us to apply our methods to realistic simulated environments for embodied AI, in which an agent is performing actions in an environment for which it only receives unstructured high-dimensional observations. In this setting our methods learn a latent representation that allows us to identify individually each causal variable, e.g. the different attributes or states of each object in the environment, as well as learn their interactions and the interactions with the agent in the form of causal relations. By reverse engineering the underlying causal system directly from visual inputs and actions, we can then provide a potential first step towards AI systems that reason about the world causally without supervision.
  time: 12:20 - 13:20
  room: Hall A
  date: Wednesday / 15 October
  id: 1
  author-name: Sara Magliacane
  author-title: University of Amsterdam
  author-image: images/optimized/speakers-600x600/SaraMagliacane.webp
  author-bio: |-
    Sara Magliacane is an assistant professor in the Amsterdam Machine Learning Lab at the University of Amsterdam and an ELLIS Scholar in the Interactive Learning and Interventional Representations program. During Spring 2022, she visited the Simons Institute in Berkeley for a semester on Causality.
    The goal of her research is to find how causality can improve current machine learning (ML) algorithms, especially in terms of robustness, generalization across domains/tasks, and safety. Her research focuses on three directions: causal representation learning (i.e. learning causal factors from high-dimensional data, e.g. sequences of images), causal discovery (i.e. learning causal relations from data), and causality-inspired ML, e.g. how can ideas from causality help ML/RL adapt to new domains, nonstationarity and varying number of objects with different latent parameters, even when we cannot guarantee that we identified the true causal factors.

    Previously, she was a Research Scientist at MIT-IBM Watson AI lab and a postdoctoral researcher at IBM Research NY, working on methods to design experiments that would allow one to learn causal relations in a sample-efficient and intervention-efficient way. She received a PhD at VU Amsterdam on learning causal relations jointly from different experimental settings, even with latent confounders and small samples. During her PhD, she interned at Google Zürich and NYC. Previously, she studied Computer Engineering at Politecnico di Milano and Torino and at the University of Trieste.
  google-scholar: https://scholar.google.com/citations?user=H3j_zQ4AAAAJ&hl=en
  slides:

- title: TBA
  abstract: |-
    TBA
  time: 12:20 - 13:20
  room: Hall B
  date: Wednesday / 15 October
  id: 2
  author-name: Shreya Pathak
  author-title: Google DeepMind
  author-image: images/optimized/speakers-600x600/ShreyaPathak.webp
  author-bio: |-
    Shreya Pathak is a research engineer at Google DeepMind, currently on the Gemma team. She works particularly on exploring different architectures for Gemma, optimising for on-device use cases. Prior to this, she had worked on multimodal understanding of video-language models. She graduated from IIT Bombay with a bachelor's in computer science and engineering.
  slides:

- title: TBA
  abstract: |-
    TBA
  time: 16:15 - 17:15
  room: Hall A
  date: Wednesday / 15 October
  id: 3
  author-name: Adel Bibi
  author-title: University of Oxford / Kellog College / Softserve
  author-image: images/optimized/speakers-600x600/AdelBibi.webp
  author-bio: |-
    Adel Bibi is a senior researcher in machine learning and computer vision at the Department of Engineering Science of the University of Oxford, a Research Fellow (JRF) at Kellogg College, and a member of the ELLIS Society. Bibi is also an R&D Distinguished Advisor with Softserve.
    Previously, Bibi was a senior research associate and a postdoctoral researcher with Philip H.S. Torr since October 2020. He received his MSc and PhD degrees from King Abdullah University of Science & Technology (KAUST) in 2016 and 2020, respectively, advised by Bernard Ghanem.

    Bibi was awarded the CRG grant by KAUST to work on robust deep learning, an Amazon Research Award in 2022 in the Machine Learning Algorithms and Theory track, the Google Gemma 2 Academic Award in 2024, and the Systemic AI Safety grant of by the UK AI Security Institute in 2025. Bibi received four best paper awards; a NeurIPS23 workshop, an ICML23 workshop, a 2022 CVPR workshop, and one at the Optimization and Big Data Conference in 2018. His contributions include over 30 papers published in top machine learning and computer vision conferences. He also received four outstanding reviewer awards (CVPR18, CVPR19, ICCV19, ICLR22) and a Notable Area Chair Award in NeurIPS23 and acts as a senior area chair NeurIPS.
  slides:

- title: Bridging perception and causality with causal representations
  abstract: |-
    TBA
  time: 16:15 - 17:15
  room: Hall B
  date: Wednesday / 15 October
  id: 4
  author-name: Francesco Locatello
  author-title: ISTA
  author-image: images/optimized/speakers-600x600/FrancescoLocatello.webp
  author-bio: |-
    Francesco Locatello is a tenure-track assistant professor at the Institute of Science and Technology Austria (ISTA) and an AI resident at the Chan Zuckerberg Initiative. Before, he was a senior applied scientist at Amazon Web Services, leading the Causal Representation Learning team. He received his PhD from ETH Zürich co-advised by Gunnar Rätsch and Bernhard Schölkopf. His research received several awards, including the ICML 2019 Best Paper award, the Hector Foundation award for outstanding achievements in machine learning from the Heidelberg Academy of Science in 2023, and the Google Research Scholar Award in 2024.
  google-scholar: https://scholar.google.com/citations?user=wQanfTIAAAAJ&hl=en
  slides:

- title: "Beyond the screen: capturing, understanding and generating 3D scenes"
  abstract: |-
    TBA
  time: 11:15 - 12:15
  room: Hall A
  date: Thursday / 16 October
  id: 5
  author-name: Federico Tombari
  author-title: Google / Technical University of Munich
  author-image: images/optimized/speakers-600x600/FedericoTombari.webp
  author-bio: |-
    Federico Tombari is Research Director at Google where he leads an applied research team in Computer Vision and Machine Learning across North America and Europe. With his team he contributed Computer Vision and ML technology to Google products such as Lens, Maps, Android, ARCore, Pixel. He is also a Lecturer (PrivatDozent) at the Technical University of Munich (TUM). He has 300+ peer-reviewed publications in CV/ML and applications to robotics, autonomous driving, healthcare and augmented reality. He got his PhD from the University of Bologna and his Venia Legendi (Habilitation) from Technical University of Munich (TUM). In 2018-19 he was co-founder and managing director of a startup on 3D perception for AR and robotics, then acquired by Google.
  slides:

- title: "Reliable and Sustainable AI: From Mathematical Foundations to Next Generation AI Computing"
  abstract: |-
    The current wave of artificial intelligence is transforming industry, society, and the sciences at an unprecedented pace. Yet, despite its remarkable progress, today’s AI still suffers from two major limitations: a lack of reliability and excessive energy consumption.

    This lecture will begin with an overview of this dynamic field, focusing first on reliability. We will present recent theoretical advances in the areas of generalization and explainability, which are core aspects of trustworthy AI that also intersect with regulatory frameworks such as the EU AI Act. From there, we will explore fundamental limitations of existing AI systems, including challenges related to computability and the energy inefficiency of current digital hardware. These challenges highlight the pressing need to rethink the foundations of AI computing.

    In the second part of the talk, we will turn to neuromorphic computing; a promising and rapidly evolving paradigm that emulates biological neural systems using analog hardware. We will introduce spiking neural networks, a key model in this area, and share some of our recent mathematical findings. These results point toward a new generation of AI systems that are not only provably reliable but also sustainable.
  time: 11:15 - 12:15
  room: Hall B
  date: Thursday / 16 October
  id: 6
  author-name: Gitta Kutyniok
  author-title: DLR / University of Tromsø / LMU Munich
  author-image: images/optimized/speakers-600x600/GittaKutyniok.webp
  author-bio: |-
    Gitta Kutyniok currently holds a Bavarian AI Chair for Mathematical Foundations of Artificial Intelligence at the Ludwig-Maximilians-Universität München, and is in addition affiliated with the German Aerospace Center, DLR and the University of Tromsø. Her research work covers the areas of applied and computational harmonic analysis, artificial intelligence, compressed sensing, deep learning, imaging sciences, inverse problems, and applications to life sciences, robotics, and telecommunication
  slides:

- title: Unleashing Creativity using AI Agent Networks
  abstract: |-
    TBA
  time: 17:30 - 18:30
  room: Main Hall
  date: Thursday / 16 October
  id: 7
  author-name: Mihaela van der Schaar
  author-title: University of Cambridge
  author-image: images/optimized/speakers-600x600/MihaelaVanDerSchaar.webp
  author-bio: |-
    Mihaela van der Schaar is the John Humphrey Plummer Professor of Machine Learning, Artificial Intelligence and Medicine at the University of Cambridge. In addition to leading the van der Schaar Lab, Mihaela is founder and director of the Cambridge Centre for AI in Medicine (CCAIM). 

    Mihaela was elected IEEE Fellow in 2009 and Fellow of the Royal Society in 2024. She has received numerous awards, including the Johann Anton Merck Award (2024), the Oon Prize on Preventative Medicine from the University of Cambridge (2018), a National Science Foundation CAREER Award (2004), 3 IBM Faculty Awards, the IBM Exploratory Stream Analytics Innovation Award, the Philips Make a Difference Award and several best paper awards, including the IEEE Darlington Award. She was a Turing Fellow at The Alan Turing Institute in London between 2016 and 2024. In 2025, she was appointed as Spinoza Guest Professor at Amsterdam University Medical Center. 

    Mihaela is personally credited as inventor on 35 USA patents, many of which are still frequently cited and adopted in standards. She has made over 45 contributions to international standards for which she received 3 ISO Awards. In 2019, a Nesta report determined that Mihaela was the most-cited female AI researcher in the U.K. 
  google-scholar: https://scholar.google.com/citations?user=DZ3S--MAAAAJ&hl=en
  slides:

- title: "Training LLMs: Do We Understand Our Optimizers?"
  abstract: |-
    Why does Adam so consistently outperform SGD when training Transformer language models? Despite many proposed explanations, this optimizer gap is still not fully understood. In this talk, we will present results from two complementary studies. First, using over 2000 language model training runs, we compare Adam with simplified variants such as signed gradient and signed momentum. We find that while signed momentum is faster than SGD, it still lags behind Adam; however, we crucially notice that constraining Adam’s momentum parameters to be equal (beta1 = beta2) retains near-optimal performance. This is of great practical importance and also reveals a new insight: Adam in this form has a robust statistical interpretation and a clear link to mollified sign descent. Second, through carefully tuned comparisons of SGD with momentum and Adam, we show that SGD can actually match Adam in small-batch training, but loses ground as batch size grows. Analyzing both Transformer experiments and quadratic models with stochastic differential equations, we shed new light on the role of batch size in shaping training dynamics.
  time: 17:30 - 18:30
  room: Hall A
  date: Thursday / 16 October
  id: 8
  author-name: Antonio Orvieto
  author-title: ELLIS Institute Tübingen
  author-image: images/optimized/speakers-600x600/AntonioOrvieto.webp
  author-bio: |-
    Antonio studied Control Engineering in Italy and Switzerland. He holds a PhD in Computer Science from ETH Zürich and spent time at Deepmind (UK), Meta (US), MILA (CA), INRIA (FR), and HILTI (LI). He is currently a Hector Endowed Fellow and Principal Investigator (PI) at the ELLIS Institute Tübingen and Independent Group Leader of the MPI for Intelligent Systems, where he leads the Deep Models and Optimization group. He received the ETH medal for outstanding doctoral theses and the Schmidt Sciences AI2050 Early Career Fellowship.

    In his research, Antonio strives to improve the efficiency of deep learning technologies by pioneering new architectures and training techniques grounded in theoretical knowledge. His work encompasses two main areas: understanding the intricacies of large-scale optimization dynamics and designing innovative architectures and powerful optimizers capable of handling complex data. Central to his studies is exploring innovative techniques for decoding patterns in sequential data, with implications in biology, neuroscience, natural language processing, and music generation.
  google-scholar: https://scholar.google.com/citations?user=xkuLyHoAAAAJ&hl=it
  slides:

- title: TBA
  abstract: |- 
    TBA
  time: 17:30 - 18:30
  room: Hall B
  date: Thursday / 16 October
  id: 9
  author-name: Sander Dieleman
  author-title: Google DeepMind
  author-image: images/optimized/speakers-600x600/SanderDieleman.webp
  author-bio: |-
    Sander Dieleman is a Research Scientist at Google DeepMind in London, UK, where he has worked on the development of AlphaGo, WaveNet, Imagen 4, Veo 3, and more. He obtained his PhD from Ghent University in 2016. His current research interests include representation learning and generative modelling of audio, images and video.
  slides:

- title: TBA
  abstract: |-
    TBA
  time: 11:15 - 12:15
  room: Hall A
  date: Friday / 17 October
  id: 10
  author-name: Jenia Jitsev
  author-title: LAION / Juelich Supercomputer Center / ELLIS
  author-image: images/optimized/speakers-600x600/JeniaJitsev.webp
  author-bio: >-
    Jenia Jitsev is co-founder and scientific lead of LAION e.V, the German non-profit research organization committed to research on open large-scale foundation models and datasets. He also leads Scalable Learning & Multi-Purpose AI (SLAMPAI) lab at Juelich Supercomputer Center, Research Center Juelich, Helmholtz Association, Germany and is a member of ELLIS. His background is in machine learning and neuroscience, aiming to understand learning as a generic process of incrementally building up a useful model of the surrounding world from available sensory observations and executed actions. His current research focus is on using scaling laws for measuring and understanding generalization and strong transfer in open foundation models. Jenia is most known for his work on open language-vision foundation models like openCLIP and open datasets like LAION-400M/5B, Re-LAION, DataComp. 

    Recently, he also has been studying reasoning and measuring generalization with works on open reasoning datasets/models OpenThoughts/OpenThinker and on discovering generalization weaknesses using AIW problems. Jenia coordinates acquisition of large-scale compute grants for conducting collaborative research on open foundation models across various supercomputing facilities, including EuroHPC. Using these resources, together with the community he is driving and democratizing research on scalable systems for generalist, transferable multi-modal learning, leading to foundation AI models capable of strong transfer and therefore easily adaptable to a broad range of desired tasks and hardware resource settings. For his work, Dr. Jitsev received Best Paper Award at IJCNN 2012, Outstanding Paper Award at NeurIPS 2022 and Falling Walls Scientific Breakthrough of the Year 2023 Award.
  slides:

- title: From pixels to nucleotides
  abstract: >-
    TBA
  time: 11:15 - 12:15
  room: Hall B
  date: Friday / 17 October
  id: 11
  author-name: Alexey Dosovitskiy
  author-title: Inceptive
  author-image: images/optimized/speakers-600x600/AlexeyDosovitskiy.webp
  author-bio: >-
    Alexey Dosovitskiy is a distinguished researcher in computer vision and machine learning. He earned his MSc and PhD in mathematics from Moscow State University in 2009 and 2012, respectively. From 2013 to 2015, he was a postdoctoral researcher at the University of Freiburg’s Computer Vision Group under Prof. Thomas Brox, focusing on deep learning applications in unsupervised learning, image generation, and motion estimation. Between 2017 and 2019, he served as a research scientist at Intel Labs in Munich, Germany, working on deep learning for computer vision and robotics. In 2019, Dosovitskiy joined Google Research, where he played a pivotal role in applying transformer architectures to computer vision tasks, notably as a lead author of the influential paper “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,” which introduced the Vision Transformer (ViT) model. 

    His research interests include artificial intelligence, machine learning, and pattern recognition, with significant contributions to areas such as optical flow estimation, image generation, and object detection. In February 2024, Dosovitskiy joined Inceptive as a Member of Technical Staff, focusing on machine learning for RNA.
  slides:

- title: What’s the next wave of disruption in science and engineering?
  abstract: >-
    In the era of LLMs, one gets notoriously confronted with the question of where we stand with applicability of large-scale deep learning models within scientific or engineering domains. The discussion starts by reiterating on recent triumphs in weather and climate modeling, making connections to computer vision, physics-informed learning and neural operators. Secondly, we discuss breakthroughs in multi-physics modeling, computational fluid dynamics, and related fields, putting an emphasis on what it takes to build reference models for whole industry verticals. We relate those breakthroughs to advancements in engineering and much faster process cycles.
  time: 16:00 - 17:00
  room: Main Hall
  date: Friday / 17 October
  id: 12
  author-name: Johannes Brandstetter
  author-title: Johannes Kepler University / Emmi AI
  author-image: images/optimized/speakers-600x600/JohannesBrandstetter.webp
  author-bio: >-
    Johannes Brandstetter leads the "AI for Data-Driven Simulations" group at the Institute for Machine Learning, JKU - Johannes Kepler Universität Linz, with the aim of advancing data-driven simulations at industry scale. Additionally, he is a Co-founder and Chief Scientist at Emmi AI — a push towards the data-driven revolution in science and engineering.
  google-scholar: https://scholar.google.com/citations?user=KiRvOHcAAAAJ&hl=de
  slides:

- title: TBA
  abstract: >-
    TBA
  time: 16:00 - 17:00
  room: Hall A
  date: Friday / 17 October
  id: 13
  author-name: Bartłomiej Papież
  author-title: University of Oxford
  author-image: images/optimized/speakers-600x600/BartłomiejPapież.webp
  author-bio: >-
    Bartek Papież leads multidisciplinary research at the intersection of artificial intelligence, biomedical imaging, and health data science. As Principal Investigator and Group Lead of the Machine Learning & Biomedical Data Research Lab at Oxford’s Big Data Institute, his work bridges the theoretical and applied dimensions of AI and machine learning. His research spans the development of novel algorithms in image analysis, data fusion, optimization, and robustness&fairness. A core focus of his lab is the integration of imaging with non-imaging modalities, including genetic data, electronic health records, and natural language, driving forward impactful applications in medicine, biology, and population health. 

    Papież’s projects address key challenges in longitudinal disease monitoring, multimodal cancer imaging, radiogenomics, and the discovery of therapeutic targets. By combining cutting-edge ML techniques with real-world biomedical data, his research aims to enhance disease understanding, early diagnosis, and precision treatment.
  slides:

- title: Modular learning for improving AI assistants
  abstract: >-
    Recent years have seen massive success in AI, from generative modelling to deep reinforcement learning. However, success has mostly been limited to domains where data is cheap and plentiful, or where models can be pre-trained on massive data sets. This excludes many domains of practical importance, such as tasks involving scientific data, real-world infrastructure, or robotics. In this talk, I will advocate for a modular approach, where complex behaviour is composed out of simpler elements. I will give examples of three recent projects, where a modular approach was adopted to increase generalisation, data efficiency, and/or instructability of artificial agents. Concluding, I will give my outlook on future developments of AI systems according to these principles, laying the foundations for more capable AI assistants.
  time: 16:00 - 17:00
  room: Hall B
  date: Friday / 17 October
  id: 14
  author-name: Herke van Hoof
  author-title: University of Amsterdam
  author-image: images/optimized/speakers-600x600/HerkeVanHoof.webp
  author-bio: >-
    Herke van Hoof is currently associate professor at the University of Amsterdam in the Netherlands, where he is part of the Amlab. He is interested in modular reinforcement learning. Reinforcement learning is a very general framework, but this tends to result in extremely data-hungry algorithms. Exploiting modular structures, including hierarchical structures, allows sharing information between tasks and exploiting prior knowledge, to learn more with less data.

    Before joining the University of Amsterdam, Herke van Hoof was a postdoc at McGill University in Montreal, Canada, where he worked with Professors Joelle Pineau, Dave Meger, and Gregory Dudek. He obtained his PhD at TU Darmstadt, Germany, under the supervision of Professor Jan Peters, where he graduated in November 2016. Herke got his bachelor and master degrees in Artificial Intelligence at the University of Groningen in the Netherlands.
  slides: