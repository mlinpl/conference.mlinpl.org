- title: 'Gaussian Splatting'
  date: Sunday / 10 November
  time: 9:00 - 13:00
  room: TBA
  id: 1
  desc-md: >-
    In this hands-on tutorial, we will introduce you to Gaussian Splatting, an advanced technology for generating detailed 3D scenes from 2D images. You will begin the session by creating your own dataset, where we will capture you or your chosen object. Each participant will work then on their own dataset.
    Throughout the tutorial, you will dive deep into the practical aspects of Gaussian Splatting. We’ll guide you step-by-step through the entire workflow, from preparing the dataset from videos to training the model and refining your final 3D objects. By the end of the session, you will not only have your own 3D scene but also a solid understanding of the technology behind it. You will gain insight into critical techniques for optimizing the splatting process, addressing common challenges, and achieving high-quality 3D results.
    Whether you are a beginner or have some experience with computer graphics, this tutorial will equip you with the skills to employ Gaussian Splatting technology in your own projects. Join us for an exciting journey into the world of cutting-edge 3D scene reconstruction!



    **Prerequisites:** You must know 3D Gaussian distribution and how to train fully connected neural networks.
  authors: 
    - name: Przemysław Spurek
      title: IDEAS NCBR / GMUM, Jagiellonian University
      image: images/optimized/cfc-600x600/przemyslaw_spurek.webp
    
    - name: Weronika
      title: Jagiellonian University
      image: images/empty.png

    - name: Piotr Borycki
      title: Jagiellonian University
      image: images/optimized/cfc-600x600/PiotrBorycki.webp

    - name:  Joanna
      title: Jagiellonian University
      image: images/empty.png

    - name:  Dawid
      title: Jagiellonian University
      image: images/empty.png
  author-bio: >-
    Przemysław Spurek is the leader of the Neural Rendering research team at IDEAS NCBR and a researcher in the GMUM group operating at the Jagiellonian University in Krakow. In 2014, he defended his PhD in machine learning and information theory. In 2023, he obtained his habilitation degree and became a university professor. He has published articles at prestigious international conferences such as NeurIPS, ICML, IROS, AISTATS, ECML. He co-authored the book Głębokie uczenie. Wprowadzenie [Deep Learning. Introduction] – a compendium of knowledge about the basics of AI. He was the director of PRELUDIUM, SONATA, OPUS and SONATA BIS NCN grants. Currently, his research focuses mainly on neural rendering, in particular NeRF and Gaussian Splatting models.


    Weronika is currently pursuing her PhD in Technical Computer Science at Jagiellonian University in Kraków. Her main area of interest is neural rendering models for 3D scene reconstruction, especially Gaussian Splatting. She employs it in different areas from physical simulations to medical data.



    Piotr Borycki is currently pursuing a Master’s degree in Computer Mathematics at Jagiellonian University in Kraków. His research focuses on 3D object representation, particularly using Neural Radiance Fields (NeRF) and Gaussian Splatting.



    Joanna is pursuing her PhD in Technical Computer Science at Jagiellonian University in Kraków, where she focuses on object representation in computer vision. Her research primarily revolves around models based on Gaussian Splatting, enabling fast rendering and modification of visual data. In recent years, she has had the privilege of collaborating with CERN and the University of Cambridge, while also participating in the first edition of AI Tech program at Wrocław University of Technology.



    Dawid has three years of experience working as a Machine Learning Engineer and is now focused on research in 3D object reconstruction using Neural Radiance Fields (NeRF) and Gaussian Splatting. His work aims to enhance the efficiency and accuracy of 3D object representation techniques in modern computer vision applications.

- title: 'How LLMs are Revolutionizing the cybersecurity field'
  date: Sunday / 10 November
  time: 9:00 - 13:00
  room: TBA
  id: 2
  desc-md: >-
    The ever-evolving threat landscape demands constant adaptation. Traditional methods struggle. Large Language Models (LLMs) emerge, wielding the power of language. This talk explores LLMs' revolution in cybersecurity. LLMs are AI models trained on massive text and code datasets. This grants them an understanding of complex linguistic patterns, invaluable in cybersecurity. Firstly, LLMs excel at advanced threat detection. Analyzing vast amounts of data, they identify subtle anomalies indicating brewing attacks. Traditional methods rely on pre-defined rules, vulnerable to novel attack vectors. LLMs, with their ability to learn and adapt, identify unseen threats, providing a crucial early warning system. Secondly, LLMs offer proactive threat analysis. By ingesting vast quantities of threat intelligence data, including past attack methods and attacker motivations, LLMs uncover patterns and predict future attack vectors. This allows security teams to take a pre-emptive approach, focusing resources on fortifying potential weaknesses before attackers exploit them. Imagine an LLM analyzing a hacker forum, identifying discussions about targeting a specific software vulnerability. This foresight empowers security professionals to patch the vulnerability before a widespread breach. Furthermore, LLMs can revolutionize vulnerability research . Traditionally, identifying vulnerabilities is time-consuming and laborious. LLMs, with their ability to analyze vast code repositories, pinpoint potential vulnerabilities through code patterns and language constructs associated with known weaknesses. This streamlines the vulnerability discovery process, allowing security teams to address critical issues before attackers identify them. While LLMs offer a powerful new frontier, challenges remain. Issues surrounding explainability, bias in training data, and potential misuse require careful consideration. However, the potential benefits are undeniable. As these models continue to evolve and integrate with existing security solutions, they hold the promise of a more secure and resilient digital landscape.



    **Prerequisites:** Participants for this LLM for cybersecurity tutorial ideally should have: Basic understanding of cybersecurity concepts: Familiarity with common threats, vulnerabilities, and security practices is helpful. No prior knowledge of LLMs is required: The tutorial will introduce the concept and core functionalities of LLMs. However, a basic understanding of artificial intelligence (AI) and machine learning (ML) could be beneficial. Regarding the needed software, they should install jupyter notebook or any Python framework. Langchain python library should also be installed for processin cybersecurity tasks with LLM.


  author-name: Natasha Alkhatib
  author-title: Symbio
  author-image: images/optimized/cfc-600x600/NatashaAlkhatib.webp
  author-bio-md: >-
    Dr. Natasha Alkhatib is a seasoned expert in automotive cybersecurity with a Ph.D. in Artificial Intelligence. Their doctoral research focused on developing cutting-edge intrusion detection systems for autonomous vehicles, demonstrating a deep understanding of the unique challenges and vulnerabilities within this domain. 
    Following their academic pursuits, Natasha joined ETAS Bosch as a cybersecurity consultant, where they contributed to the development and implementation of various tools and services to enhance automotive security. Their expertise in this field allowed them to play a pivotal role in safeguarding critical automotive systems.
    Currently, Natasha holds the position of Automotive Cybersecurity Leader at Symbio, a leading provider of fuel cell systems for the automotive industry. In this role, they leverage their extensive knowledge and experience to ensure the security of Symbio's hydrogen-based fuel cell technology, protecting both consumers and manufacturers from potential cyber threats.



- title: 'Beyond transformers - new sequence processing architectures'
  date: Sunday / 10 November
  time: 9:00 - 13:00
  room: TBA
  id: 3
  desc-md: >-
    The transformer neural architecture took by storm the AI community and is now used in many applications, from language models to image generation. With its widespread use we start to better understand transformer’s operating principles, limitations, and possible solutions to them. This tutorial aims to offer a clear picture of where transformer models are today and where they might be heading in the future or what might replace them. This tutorial will open with an overview of how transformers work, their strengths, their weaknesses, and recent theoretical findings about their capabilities, such as their ability to simulate different types of computations and their scalability with hardware. We will next cover important topics about how transformers handle context and attention and compare them with newly proposed alternatives, such as state-space models, to highlight the differences and trade-offs. We will discuss learning mechanisms both in the case of learning from training data during pre-training and in-context learning doing evaluation. We’ll look at techniques for handling long contexts and speculate on the relationship between in-context and from data learning. This will lead us to open questions about the future of AI models, such as understanding where knowledge is actually stored in sequence prediction models and is there a potential for models with an almost unlimited learning capacity.	



    **Prerequisites:** Familiarity with transformer architecture. Python, PyTorch, Colab.	

  authors:
    - name: Michał Bartoszkiewicz
      title: Pathway
      image: images/optimized/cfc-600x600/MichalBartoszkiewicz.webp

    - name: Jan Chorowski
      title: Pathway
      image: images/optimized/cfc-600x600/JanChorowski.webp

    - name: Adrian Kosowski 
      title: Pathway
      image: images/optimized/cfc-600x600/AdrianKosowski.webp

    - name: Adrian Łańcucki
      title: NVIDIA
      image: images/optimized/cfc-600x600/AdrianLancucki.webp

    - name: Przemysław Uznański
      title: Pathway
      image: images/optimized/cfc-600x600/PrzemyslawUznanski.webp

  author-bio-md: >-
    Michał Bartoszkiewicz designs the Pathway data processing framework. He is a competitive programmer with a long list of achievements including Topcoder finals, Google Code Jam and Facebook HackerCup. He co-founded nasza-klasa.pl, the first Polish social network.



    Jan Chorowski is the CTO at Pathway working on realtime data processing frameworks. He received his M.Sc. degree in electrical engineering from Wrocław University of Technology and Ph.D. from University of Louisville. He has worked at the University of Wroclaw and has collaborated with several research teams, including Google Brain, Microsoft Research and Yoshua Bengio's lab.



    Adrian Kosowski specializes in network theory, discrete dynamical systems, graph navigability, and graph learning. He obtained his PhD in Computer Science at the age of 20, and has co-authored over 100 publications across Theoretical Computer Science, Physics, and Biology. Before co-founding Pathway, he was a tenured researcher at Inria and an associate professor at Ecole Polytechnique. He is also a co-founder of Spoj.com.



    Adrian Łańcucki is a senior engineer at NVIDIA. His research focuses on representation learning and generative modeling for text and speech, as well as improving quality and efficiency at scale. In 2019, Adrian obtained a Ph.D. in machine learning from the University of Wroclaw, Poland. Since then, he has actively collaborated with academia.



    Przemek Uznański is the streaming algorithms and data structure expert at Pathway, and a former competitive programmer (finalist of ACM ICPC, TopCoder Open and Facebook HackerCup). He did his PhD at the INRIA Bordeaux on the topic of distributed computing, then was a Post-doc at ETH Zurich, Aalto (Finland), and in Marseille. He was an assistant professor at University of Wrocław

- title: 'Machine learning on molecules and molecular fingerprints'
  date: Sunday / 10 November
  time: 9:00 - 13:00
  room: TBA
  id: 4
  desc-md: >-
    Machine learning on molecules is a vital subject in chemoinformatics and de novo drug design. Tasks like molecular property prediction and virtual screening are crucial in modern pharmaceutical workflows. However, molecules are nontrivial to process, typically being represented as attributed graphs. As such, they are naturally non-Euclidean and have no notion of distance, requiring vectorization before performing classification, regression, or other ML tasks. Dedicated embedding methods are required, in order to encode relevant structural and functional information. Molecular fingerprints are the most popular group of algorithms in this regard, offering efficient solutions for many problems. One of the most recent developments in this area is scikit-fingerprints, a scikit-learn compatible library for easy and efficient computation of molecular fingerprints, which will be extensively used during the tutorial. This workshop will introduce participants to machine learning on molecules, molecular fingerprints, and how to apply them to practical problems. We will cover basics of chemoinformatics, reading and processing data, how molecular fingerprints work, and how to apply them to molecular property prediction or virtual screening. As a bonus, participants will learn why graph neural networks (GNNs) are not a silver bullet, and why molecular fingerprints are still very much relevant in the era of GNNs popularity.



    **Prerequisites:** We assume reasonably good Python programming knowledge, as well as general familiarity with machine learning and popular data science libraries, e.g. NumPy, Pandas, matplotlib, scikit-learn. Any previous experience with chemoinformatics is not required. We will work with Jupyter Notebooks, and attendees can use either local development environment or Google Colab.

  authors:
    - name: Jakub Adamczyk
      title: AGH University of Krakow / Placewise
      image: images/optimized/cfc-600x600/jakub_adamczyk.webp

    - name: Piotr Ludynia
      title: AGH University of Krakow
      image: images/optimized/cfc-600x600/piotr_ludynia.webp
  author-bio-md: >-
    Jakub Adamczyk is a PhD candidate in Computer Science at AGH University of Krakow. His research concerns graph representation learning, graph classification, chemoinformatics, and molecular property prediction. He also works at Placewise as Data Science Engineer, focusing on various ML problems in tabular learning, CV and NLP, and their end-to-end MLOps. Besides his professional work, he does Historical European Martial Arts (HEMA) and likes reading.

    

    Piotr Ludynia is currently pursuing a Master’s degree at AGH University of Cracow - Poland, specializing in machine learning with a focus on graph and molecular learning. He also works on deep learning research and neural network acceleration at Intel. In his free time he writes, plays modern metal guitar and produces music.


- title: 'Multi-Agent Reinforcement Learning Tutorial for Optimal Urban Route Choice Using TorchRL'
  date: Sunday / 10 November
  time: 14:30 - 18:30
  room: TBA
  id: 5
  desc-md: >-
    In this tutorial, we will demonstrate how to implement Multi-Agent Reinforcement Learning (MARL) scenarios in an urban setting using our custom PettingZoo framework, RouteRL. We will showcase a simplified traffic route choice environment integrating Simulation of Urban MObility (SUMO), an open-source traffic simulation, with the reinforcement learning library, TorchRL. This framework aims to replicate the daily decision-making process involved in route selection. It incorporates two types of agents: human drivers, which are modeled using human route choice behavioral models from transportation research, and Automated Vehicles (AVs), RL agents with individual or collective goals. We will present our environment and its functionality as well as experiments with different state-of-the-art RL algorithms aiming to assess how the agents learn and compare the learning of human agents and AVs.


    **Prerequisites:** Participants should have a basic understanding of reinforcement learning concepts before attending this tutorial. Additionally, they should prepare their development environment by installing and setting up the necessary tools. This includes creating and activating a Conda environment with Python 3.12. Within this environment, they should use pip to install the required libraries: Gym, PettingZoo, and torchrl.

  authors:
    - name: Anastasia Psarou
      title: Jagiellonian University
      image: images/optimized/cfc-600x600/anastasia_psarou.webp

    - name: Ahmet Onur Akman
      title: Jagiellonian University
      image: images/optimized/cfc-600x600/onur_akman.webp

  author-bio-md: >-
    Anastasia Psarou is a PhD student in the Faculty of Mathematics and Computer Science at Jagiellonian University. Currently, she is working as part of the COeXISTENCE team towards discovering what happens in the future cities when intelligent machines (autonomous vehicles) and humans share limited resources of urban mobility.



    Ahmet Onur Akman is a Computer Engineer with a specialization in Artificial Intelligence. Currently, he is a PhD student in the Faculty of Mathematics and Computer Science at Jagiellonian University interested in foreseeing what happens when our cities are shared with autonomous, intelligent robots, competing with human drivers for limited resources.


