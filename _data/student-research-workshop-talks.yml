- author-name: Aleksandra Gwiazda
  title: "Attribute-Regularized VAEs for Controlled and Interpretable Antimicrobial Peptide Design"
  author-title: "Warsaw University of Technology"
  abstract: >- 
    Antibiotic resistance is a growing global health threat, driving the need for alternative therapeutics. Antimicrobial peptides (AMPs) offer a promising solution due to their broad-spectrum activity and lower propensity to induce resistance. While deep learning–based generative models, such as variational autoencoders (VAEs), have been explored for designing novel AMPs, their limited controllability and interpretability hinder practical application. In this work we present Attribute-Regularized VAE (AR-VAE), a generative model that explicitly incorporates key peptide attributes directly into the training objective. A regularization loss is applied to structure the latent space, enabling controlled traversal along interpretable directions corresponding to charge, length, and hydrophobicity.  Experimental results demonstrate that AR-VAE achieves improved latent space disentanglement and enhanced performance on metrics of interpretability, modularity, and predictability. The model effectively captures and manipulates properties correlated with antimicrobial activity, enabling targeted AMP generation. AR-VAE offers a principled and interpretable approach for AMP design, addressing the urgent problem of AMR through targeted AMP generation.
  author-bio: >- 
    Aleksandra Gwiazda obtained her Bachelor's degree in Biomedical Engineering from the Warsaw University of Technology in February 2023. She is currently pursuing a specialization in Artificial Intelligence as part of the Informatics program at WuT. Aleksandra is collaborating with Prof. Ewa Szczurek's research group at Helmholt.
  co-authors: Paulina Szymczak, Ewa Szczurek
  date: Wednesday / 15 October
  time: 8:10 - 8:30
  room: Main Hall
  session: Student Research Workshop
  id: 1
  author-image: images/optimized/cfc-600x600/aleksandra_gwiazda.webp

- author-name: Łukasz Sztukiewicz
  title: "DetoxAI - Python Package for Debiasing Neural Networks"
  author-title: "Independent Researcher"
  abstract: >- 
    Despite growing awareness of fairness in machine learning, the lack of dedicated debiasing techniques and practical software frameworks remains a major barrier - especially in vision tasks. To address this, we introduce DetoxAI, a Python-based framework for post-hoc debiasing of neural networks in image classification. Built with deep learning workflows in mind, DetoxAI combines interventions, fairness metrics, and visualization tools into a single, production-ready package.  Our method uses post-training adaptations to reduce bias without degrading model accuracy. By operating on high-level semantic features, DetoxAI tackles the unique challenge of vision models, where sensitive attributes like race or gender are rarely explicitly represented. The toolkit offers a modular and accessible interface, making it suitable for real-world use across different domains.  Through experiments, we show that DetoxAI consistently improves the fairness-accuracy trade off over standard models. Attribution map analyses further confirm that DetoxAI reduces reliance on protected features. Parts of this work were published and presented at XAI Late-Breaking Work 2025, KDD UMC 2025, and the ECML Demo Track 2025.
  author-bio: >- 
    Łukasz Sztukiewicz holds a Bachelor of Science degree in Artificial Intelligence from Poznan University of Technology. He was a research fellow at Carnegie Mellon University and worked as a machine learning engineer at Molecule.one.
  co-authors: Ignacy Stępka, Michał Wiliński, Jerzy Stefanowski
  date: Wednesday / 15 October
  time: 8:30 - 8:50
  room: Main Hall
  session: Student Research Workshop
  id: 2
  author-image: images/optimized/cfc-600x600/lukasz_sztukiewicz.webp

- author-name: Mikołaj Janusz
  title: "OMENN: One Matrix to Explain Neural Networks"
  author-title: "Jagiellonian University"
  abstract: >- 
    Deep Learning (DL) models are often black boxes, which makes their decision-making processes difficult to interpret. This lack of transparency has driven advancements in eXplainable Artificial Intelligence (XAI), a field dedicated to clarifying the reasoning behind DL model predictions. Among these, attribution-based methods such as LRP and GradCAM are widely used, though they rely on approximations that can be imprecise.  To address these limitations, we introduce One Matrix to Explain Neural Networks (OMENN), a novel post-hoc method that represents a neural network as a single, interpretable matrix for each specific input. This matrix is constructed through a series of linear transformations that represent the processing of the input by each successive layer in the neural network. As a result, OMENN provides locally precise, attribution-based explanations of the input across various modern models, including ViTs and CNNs. We present a theoretical analysis of OMENN based on dynamic linearity property and validate its effectiveness with extensive tests on two XAI benchmarks, demonstrating that OMENN is competitive with state-of-the-art methods.  The work is available on Arxiv.
  author-bio: >- 
    Mikołaj Janusz is a Computer Science M.Sc. student at the Jagiellonian University and a Student Researcher at GMUM (gmum.net). During his studies, he conducted research on XAI for drug discovery as a student participant in the FIRST TEAM FENG program (grant "Interpretable and Interactive Multimodal Retrieval in Drug Discovery"), various topics in computer vision, and pruning regimes. Beyond his research, he gained practical software engineering experience in distributed systems and compute infrastructure during internships at Google, Meta, Amazon, and the systematic-trading firm Quadrature. Currently, he's mainly interested in topics of compute, applied machine learning, and software engineering.
  co-authors: Adam Wróbel, Bartosz Zieliński, Dawid Rymarczyk
  date: Wednesday / 15 October
  time: 8:50 - 9:10
  room: Main Hall
  session: Student Research Workshop
  id: 3
  author-image: images/optimized/cfc-600x600/mikolaj_janusz.webp

- author-name: Tomasz Dądela
  title: "From Blurry to Sharp: Enabling High-Frequency Detail in Implicit Neural Representations"
  author-title: "Jagiellonian University"
  abstract: >- 
    Implicit Neural Representations have recently gained attention as a powerful approach for continuously representing signals – such as images, videos, and 3D shapes – using multilayer perceptrons (MLPs). However, MLPs are known to exhibit a low-frequency bias, which limits their ability to capture high-frequency details accurately. Our aim is to find optimal parameters using a compute-efficient method, without the need to perform multiple rounds of representation learning. Such a configuration should enable the model to learn the details of the representation more quickly. We explore the relationship between model performance and the frequency of the embedding, the frequency of the target image, as well as key MLP design choices such as the number of features and layers. Alongside experiments with real-world images, we created a synthetic dataset to identify individual factors that determine the performance of a particular model.
  author-bio: >- 
    Tomasz Dądela is a final year Machine Learning M.Sc. student at the Jagiellonian University.  Currently, he is actively involved in projects with the Group of Machine Learning Research (GMUM) at the Jagiellonian University.
  co-authors: Adam Kania, Przemysław Spurek, Maciej Rut
  date: Wednesday / 15 October
  time: 9:10 - 9:30
  room: Main Hall
  session: Student Research Workshop
  id: 4
  author-image: images/optimized/cfc-600x600/tomasz_dadela.webp

- author-name: Rafał Malcewicz
  title: "Semantic Label Reconstruction: How to breach privacy in Federated Learning"
  author-title: "Carnegie Mellon University, GHOST Day"
  abstract: >- 
    Federated Learning enables clients to collaboratively train models by sharing gradients with a central server or with each other, offering both computational efficiency and enhanced privacy compared to sharing raw data. However, prior research has demonstrated that gradient inversion attacks can partially reconstruct the original input data from shared gradients. Unfortunately, this approach faces significant limitations, particularly in high-batch-size settings, due to the inherent information loss during gradient computation, which severely degrades reconstruction quality. In this work, we propose a shift in focus from input reconstruction to task reconstruction, specifically targeting the recovery of semantic labels from shared gradients. While this form of attack does not reveal full input data, it still constitutes a meaningful privacy breach. Importantly, semantic label reconstruction remains more robust under increasing batch sizes compared to full data reconstruction, making it a viable and concerning threat vector in practical federated learning scenarios.
  author-bio: >- 
    Rafał Malcewicz is pursuing a Bachelor of Science and Technology at Aalto University. He has research experience at the Auton Lab, Carnegie Mellon University, where he worked on gradient inversion attacks in the federated learning setting. Currently, he serves as the Project Leader of GHOST Day AMLC (Applied Machine Learning Conference).
  co-authors: Ignacy Stępka, Abby Turner, Artur Dubrawski
  date: Wednesday / 15 October
  time: 9:50 - 10:10
  room: Main Hall
  session: Student Research Workshop
  id: 5
  author-image: images/optimized/cfc-600x600/rafal_malcewicz.webp

- author-name: Nikodem Świerkowski
  title: "Filling in the Blanks: Redefining Inpainting with a Novel Geometrical Latent Space VAE Architecture"
  author-title: "Wrocław University of Science and Technology"
  abstract: >- 
    Image inpainting — reconstructing missing parts of an image — is a crucial task in computer vision with applications in photo restoration, image editing, and beyond. This task requires generative models that not only produce visually coherent outputs but also reason about the uncertainty and semantic context inherent in incomplete data. While lightweight convolutional autoencoders and GANs are commonly used due to their simplicity and training speed, they lack a probabilistic treatment of uncertainty and limit the interpretability and exploration of latent space. In contrast, Variational Autoencoders (VAEs) offer a more expressive framework for modeling the data distribution and generating diverse, plausible reconstructions.  We compare four VAE-based models: the standard VAE, VQ-VAE (which uses latent space quantization), VAE-GAN (incorporating an adversarial component), and TreeVI — a model proposed at NeurIPS 2024 that captures inter-sample correlations using a tree-structured latent space built via a Minimum Spanning Tree (MST). While TreeVI improves reconstruction quality, its computational overhead and non-differentiable graph structure make it difficult to scale in practice.  To address these limitations, we introduce GeoVAE — a novel model that treats the latent space as a graph, where edges represent correlations between dimensions. Unlike TreeVI, GeoVAE learns these correlations dynamically through two graph convolutional networks (GNNs): GNNinst, which captures inter-sample relationships, and GNNdim, which estimates the importance of individual latent dimensions. The reparameterization trick is extended into an adaptive mechanism that allows for scalable, fully differentiable correlation modeling. This enables learning on true correlation structures, rather than approximating them through trees, showcasing the potential of integrating geometric learning into standard deep generative models.  We evaluate all models on a dense inpainting task involving 64×64 RGB images with randomly placed square masks of varying size and location. The models are trained to reconstruct the missing regions conditioned on the visible context. GeoVAE achieves the lowest MSE across all models, with competitive SSIM and PSNR. Notably, its per-epoch training time is only ~1.5× that of the base VAE and significantly faster than TreeVI, while delivering better semantic and perceptual coherence.
  author-bio: >- 
    Nikodem Świerkowski is a Master's student in Artificial Intelligence at Wrocław University of Science and Technology. He holds a Bachelor's degree in Applied Computer Science from the same university. His current research focuses on enhancing the effectiveness of state-of-the-art video plagiarism detection methods. Enthusiast of probabilistic graphs models, explainable AI and cooking :)
  co-authors: Daniel Borkowski, Mikołaj Jastrzębski
  date: Wednesday / 15 October
  time: 10:10 - 10:30
  room: Main Hall
  session: Student Research Workshop
  id: 6
  author-image: images/optimized/cfc-600x600/nikodem_swierkowski.webp

- author-name: Paulina Hładki
  title: "GraphaFold: Graph Neural Network for predicting non-canonical RNA base pairing"
  author-title: "Poznan University of Technology"
  abstract: >- 
    Authors: Paulina Hładki, Marek Justyna, Maciej Antczak, Marta Szachniuk  Recent breakthroughs in biomedicine, such as mRNA vaccines and gene-editing technologies, have highlighted the critical role of RNA molecules in health and disease. RNA (ribonucleic acid) is not just a carrier of genetic information; it also regulates cellular processes, assembles complex molecular machines, and can even act as a biological catalyst. The function of RNA depends largely on its three-dimensional structure, which is formed through networks of hydrogen bonds - similar to magnets holding different parts of the molecule together. These bonds create base pairs, which come in two types: canonical (making up about 70% of all base pairs in RNA) and non-canonical (alternative, which can constitute up to 30%). While most computational tools focus on canonical base pairs, non-canonical interactions are crucial for shaping RNA's structure, especially in flexible regions and in contacts that determine how RNA interacts with proteins and other molecules. However, predicting these non-canonical base pairs from sequence data remains a major challenge, as they are highly variable and less well-represented in existing training data. In this work, we introduce GraphaFold, a graph neural network (GNN)-based approach designed to predict non-canonical RNA base pairs. Our method starts with known canonical interactions - either from experiments or existing software - and represents the RNA molecule as a graph, where each nucleotide is a node and possible interactions are edges. We use advanced neural embeddings, generated by a pretrained RNA language model, to provide rich input features. The GNN learns to recognize complex patterns associated with non-canonical base pairing by leveraging features of the sequence, structural context, and graph connectivity. To address the problem of class imbalance (since non-canonical pairs are relatively rare), we use a reweighted loss function during training. We created a comprehensive dataset of RNA fragments from high-resolution 3D structures, capturing a wide variety of non-canonical motifs, to train and rigorously test the model. Benchmarks show that GraphaFold outperforms current deep learning tools in predicting non-canonical interactions, while scaling well to different RNA types and sizes. The method offers a practical solution for advancing RNA structure modeling, as GraphaFold’s predictions can enrich 2D structural maps and serve as valuable constraints for more detailed 3D modeling.   Funding:  This research was supported by grant 2024/53/B/ST6/02789 from the National Science Centre, Poland.
  author-bio: >- 
    Paulina Hładki is a master’s student in computer science with a specialization in artificial intelligence at Poznan University of Technology. She is currently working on deep learning models for RNA structure prediction. With experience in both academic research and international IT environments, she bridges theoretical insight with practical machine learning applications.
  co-authors: Marek Justyna, Maciej Antczak, Marta Szachniuk
  date: Wednesday / 15 October
  time: 10:30 - 10:50
  room: Main Hall
  session: Student Research Workshop
  id: 7
  author-image: images/optimized/cfc-600x600/paulina_hladki.webp

- author-name: Łukasz Janisiów
  title: "Enhancing Chemical Explainability Through Counterfactual Masking"
  author-title: "Jagiellonian University"
  abstract: >- 
    Molecular property prediction is a crucial task that guides the design of new compounds, including drugs and materials. While explainable artificial intelligence methods aim to scrutinize model predictions by identifying influential molecular substructures, many existing approaches rely on masking strategies that remove either atoms or atom-level features to assess importance via fidelity metrics. These methods, however, often fail to adhere to the underlying molecular distribution and thus yield unintuitive explanations. In this work, we propose counterfactual masking, a novel framework that replaces masked substructures with chemically reasonable fragments sampled from generative models trained to complete molecular graphs. Rather than evaluating masked predictions against implausible zeroed-out baselines, we assess them relative to counterfactual molecules drawn from the data distribution. Our method offers two key benefits: (1) molecular realism underpinning robust and distribution-consistent explanations, and (2) meaningful counterfactuals that directly indicate how structural modifications may affect predicted properties. We demonstrate that counterfactual masking is well-suited for benchmarking model explainers and yields more actionable insights across multiple datasets and property prediction tasks. Our approach bridges the gap between explainability and molecular design, offering a principled and generative path toward explainable machine learning in chemistry.
  author-bio: >- 
    Łukasz Janisiów is a first-year doctoral student in the Group of Machine Learning Research at Jagiellonian University and a participant in the ELLIS PhD Program. His research focuses on the application of explainable artificial intelligence (XAI) in drug discovery.
  co-authors: Marek Kochańczyk, Bartosz Zieliński, Tomasz Danel
  date: Wednesday / 15 October
  time: 10:50 - 11:10
  room: Main Hall
  session: Student Research Workshop
  id: 8
  author-image: images/optimized/cfc-600x600/lukasz_janisiow.webp
