- author-name: Klaudia Balcer
  title: "Exceeding historical exposure in session-based recommender systems"
  author-title: "Computational Intelligence Research Group, University of Wrocław"
  abstract: >- 
    Recommender systems (RS) are invisible artificial intelligence tools accompanying us in our daily lives online: on streaming platforms, social media, banner ads, or online shops, providing us with personalised content, offers, training programs etc. There are different scenarios of recommendations. Sometimes we track the user activity through the years, gathering explicit opinions about the items. In session-based RS (SBRS), we track only short, anonymous sessions of user actions (like clicks) without direct feedback. Methods applied for modelling RS highly rely on the nature of the data.   In SBRS, surprisingly good accuracy can be achieved by using the bigram model, which recommends the most common successors of the last item in the session prefix. It suggests how strongly are the users biased with exposure (with what the previously used RS showed them). Training on biased data, it is hard to obtain non-biased results. Also, if we change the exposure (present new recommendations to the user), their preferences may also change (as they will be conditioned on different exposure), which breaks the silent assumption in Machine Learning about the identical distribution of the data. To handle the issues caused by exposure, we propose to incorporate the uncertainty of the collected data in the training process.   In our recent work, we proposed to treat sessions as realizations of a stochastic process and train the model with random realizations of the underlying process in each epoch. As recent research suggests the supremacy of spherical embeddings, we decided to use the von Mises-Fisher distribution (Gaussian conditioned on a sphere). It allowed us to directly include the uncertainty of the user behaviour and to model the dense user interest (directed to items similar to what the user was looking for, not to a specific one). Additionally, we used disrupted targets (session suffixes of length 1) during the training. Instead of optimizing the model to focus on a unique target, we used the true target and a number of fake targets (sampled with consideration of the similarity to the true one) in the loss function. It allowed us to simulate the change in the exposure. We also provided a broad evaluation of the proposed approach, including datasets with various levels of popularity bias. We have also used several metrics scoring recommendation relevance (recall, distance in embeddings space to the taregt), recommendation quality (average recommendation popularity, coverage) and embedding quality (radial basis function). We have also perfomed evaluation in groups defined by item popularity.   The results showed that our approach improves the overall recommendation quality. The exact consequences of using stochastic augmentations in SBRS depend on the strength of popularity bias in data. For less biased data, we obtained an improved recommendation hit-rate. For more biased data, we obtained improvements in coverage and reduced the propagation of popularity into recommendations, while keeping the hit-rate stable.   In the talk, we propose to give a short introduction to session-based recommendations and present our findings. We will also get into the details of evaluation, to present various aspects of recommendation quality.
  author-bio: >- 
    Klaudia Balcer is a PhD Student and Research Assistant in the Computational Intelligence Research Group at the University of Wrocław. Using her mathematical background, she bridges between a stochastic interpretation of data uncertainty and deep learning models for recommender systems. She focuses on reducing exposure and popularity bias.
  co-authors: Piotr Lipinski
  date: 08.11.2024
  time: 10:35 - 11:00
  room: A
  session: CfC Session 1
  id: 1
  author-image: images/optimized/cfc-600x600/klaudia_balcer.webp

- author-name: Tudor Coman
  title: "Leveraging Multi-Armed Bandit Algorithms for Dynamic Decision Making"
  author-title: "Software Development Engineer @ Adobe"
  abstract: >- 
    Consider the challenge of allocating resources efficiently across multiple options, where each choice's potential benefit is initially unknown. Multi-armed bandit algorithms provide a robust solution by dynamically adjusting decisions based on real-time feedback, maximizing outcomes across various sectors. From enhancing user engagement through smart A/B testing in web development to optimizing investment strategies in finance and personalizing treatment plans in healthcare, these algorithms are pivotal.   Multi-armed bandit (MAB) algorithms have become a cornerstone in various fields due to their ability to balance exploration and exploitation effectively. This approach is used in contexts where decision-making under uncertainty is crucial, such as finance, healthcare, marketing, and more. The presentation will explore the broader applications of MAB algorithms, demonstrating their versatility and effectiveness in dynamic environments.   Bandits are considered a typical Reinforcement Learning problem, but they are not currently as popular as other AI algorithms (such as Neural Networks, GPT etc.). However, due to the large number of applications that require informed decision-making, this is a topic of interest to the industry.  At Adobe, we are using multi-armed bandits in Adobe Target for allocating traffic in A/B tests dynamically and automatically, and we are currently working on implementing this feature in Adobe Experience Platform for a similar use case.  This talk will explore how multi-armed bandit algorithms use advanced statistical methods to revolutionize decision-making processes, making them more data-driven and results-oriented. The demo will be oriented towards A/B testing, but no prior background is necessary to be able to understand the concepts, as they are easily applicable to other fields as well. Join us to learn how integrating these algorithms into your strategies can lead to significant improvements in performance and resource utilization.
  author-bio: >- 
    I am a software engineer, working at Adobe for the past 6 years, since I was at the young age of 15. At first, I tackled and helped develop complex fraud prevention systems for online video platforms. My past experience also includes working with ranking/recommendation algorithms and MLOps.  Moving on, the work I do now enables customers get the most out of Adobe products. This includes using Generative AI and Large Language Models to answer user questions about feature documentation and usage insights. I am also involved in the development of a large-scale experimentation platform that instruments A/B testing.  Previously, I have been recognized by Forbes Romania, who featured me in their 30 Under 30 list in 2020 for my achievements.
  co-authors:
  date: 08.11.2024
  time: 11:05 - 11:30
  room: A
  session: CfC Session 1
  id: 2
  author-image: images/optimized/cfc-600x600/tudor_coman.webp

- author-name: Patryk Wielopolski
  title: "From Theory to Practice: A Practitioner's Journey with Knowledge Graphs"
  author-title: "DataWalk"
  abstract: >- 
    Large Language Models (LLMs) and Knowledge Graphs (KGs) are emerging as significant technological trends, as highlighted in recent industry reports. These technologies offer promising avenues for enhancing data-driven decision-making and operational efficiency across various sectors. While LLMs have recently gained significant attention, KGs remain less widely understood.  This presentation draws on six years of experience in designing and implementing solutions with DataWalk, a Knowledge Graph platform, to offer a clear and practical introduction to Knowledge Graphs. It will explore real-world applications across diverse industries, illustrating how Knowledge Graphs can independently provide substantial value to organizations. Additionally, the talk will demonstrate the synergy between Knowledge Graphs and AI techniques, showcasing their combined potential to address complex challenges.
  author-bio: >- 
    Patryk Wielopolski is an R&D leader at DataWalk and a Ph.D. candidate in Artificial Intelligence at Wrocław University of Science and Technology. His work focuses on Knowledge Graphs and AI, where he has contributed to designing and implementing solutions in the finance, insurance, and law enforcement sectors. Patryk’s efforts connect academic research with practical applications, advancing innovation in data-driven technologies.
  co-authors:
  date: 08.11.2024
  time: 11:35 - 12:00
  room: A
  session: CfC Session 1
  id: 3
  author-image: images/optimized/cfc-600x600/patryk_wielopolski.webp

- author-name: Adriana Borowa
  title: "Deep Learning for effective analysis of High Content Screening"
  author-title: "Ardigen SA"
  abstract: >- 
    High Content Screening (HCS) is a powerful technique that facilitates complex cellular analysis by integrating fluorescence microscopy with automated high-throughput image acquisition. This approach enables the detailed examination and comparison of various cell phenotypes, generating extensive image datasets that can reveal subtle biological effects. However, these datasets often suffer from challenges such as sparse and imbalanced labeling, where the underlying chemical or biological effects are not fully annotated or are unevenly distributed. Recent advancements in Deep Learning have shown great promise in overcoming these challenges. By leveraging sophisticated algorithms, Deep Learning can extract rich, high-dimensional representations from HCS images, enabling more accurate and efficient analysis even in the face of limited or imbalanced labels. These methods can enhance our understanding of the complex interactions captured in HCS datasets, providing insights that were previously difficult to achieve with traditional analysis techniques. This talk will focus on the transformative potential of Deep Learning in High Content Screening, highlighting its ability to address the limitations of traditional analysis methods. We will explore the latest developments in Deep Learning techniques tailored for high-dimensional image data, emphasizing their applications in overcoming challenges such as sparse labeling and class imbalance.
  author-bio: >- 
    Adriana is Senior Data Scientist at Ardigen responsible for the development of Ardigen phenAID platform that enables the identification of small molecule candidates. Her diverse experience includes work in digital pathology and neuron imaging with commitment to making meaningful contributions in various domains of life sciences. Adriana is also pursuing PhD at Jagiellonian University and her research interests are focused on advancing the field of  biomedical imaging by leveraging AI models. Her scientific work on cutting-edge deep learning algorithms aims to automate the analysis of High Content Screening images as well as microscopy images of bacteria.
  co-authors:
  date: 08.11.2024
  time: 10:35 - 11:00
  room: B
  session: CfC Session 2
  id: 4
  author-image: images/optimized/cfc-600x600/adriana_borowa.webp

- author-name: Maciej Chrabaszcz
  title: "Aggregated Attributions for Explanatory Analysis of 3D Segmentation Models"
  author-title: "NASK - National Research Institute / Warsaw University of Technology"
  abstract: >- 
    Analysis of 3D segmentation models, especially in the context of medical imaging, is often limited to segmentation performance metrics that overlook the crucial aspect of explainability and bias. Currently, effectively explaining these models with saliency maps is challenging due to the high dimensions of input images multiplied by the ever-growing number of segmented class labels. To this end, we introduce Agg$^2$Exp, a methodology for aggregating fine-grained voxel attributions of the segmentation model's predictions. Unlike classical explanation methods that primarily focus on the local feature attribution, Agg$^2$Exp enables a more comprehensive global view on the importance of predicted segments in 3D images. Our benchmarking experiments show that gradient-based voxel attributions are more faithful to the model's predictions than perturbation-based explanations. As a concrete use-case, we apply Agg$^2$Exp to discover knowledge acquired by the Swin UNEt TRansformer model trained on the TotalSegmentator v2 dataset for segmenting anatomical structures in computed tomography medical images. Agg$^2$Exp facilitates the explanatory analysis of large segmentation models beyond their predictive performance.
  author-bio: >- 
    Maciej Chrabąszcz is a dedicated researcher in the field of Artificial Intelligence, with a particular focus on AI model behavior analysis, alignment, and efficient computing. As a PhD student in Computer Science, his work contributes to the critical areas of AI development and understanding.  Having completed his Master's in Mathematical Statistics at the Warsaw University of Technology (WUT), Maciej is now pursuing his doctoral studies at the same institution. Concurrently, he contributes his expertise to NASK - National Research Institute.
  co-authors: Hubert Baniecki,Piotr Komorowski,Szymon Płotka,Przemysław Biecek
  date: 08.11.2024
  time: 11:05 - 11:30
  room: B
  session: CfC Session 2
  id: 5
  author-image: images/optimized/cfc-600x600/maciej_chrabaszcz.webp

- author-name: Barbara Klaudel
  title: "Towards Medical Foundation Model -- a Unified Dataset for Pretraining Medical Imaging Models"
  author-title: "TheLion.AI"
  abstract: >- 
    We present UMIE datasets, the largest publicly available collection of annotated medical imaging data to date. This resource combines over 1 million images from 20 open-source datasets, spanning X-ray, CT, and MRI modalities. The dataset includes images for both classification and segmentation tasks, with 40+ standardized labels and 15 annotation masks. A key contribution is the unified preprocessing pipeline that standardizes the heterogeneous source datasets into a common format, addressing challenges such as diverse file types, annotation styles, and labeling ontologies. We mapped all labels and masks to the RadLex ontology, ensuring consistency across datasets. The preprocessing scripts are modular and extensible, allowing researchers to easily incorporate new datasets. By providing this large-scale, standardized medical imaging resource, UMIE datasets aim to facilitate the development of more robust and generalizable medical foundation models akin to those in general-purpose computer vision. The associated code enabling exact replication of the dataset is publicly available, with select portions to be released on HuggingFace to comply with redistribution restrictions on some source datasets.
  author-bio: >- 
    Co-founder of a research group, TheLion.AI devoted to creating AI-based open source solutions for healthcare. Worked on projects such as the Universal Medical Image Encoder and the Polish medical language model Esculap. Creates educational materials, like "Computer Vision Worksheets" with video tutorials on YouTube. Awarded Forbes 25 under 25.
  co-authors: Piotr Frąckowski, Andrzej Komor, Aleksander Obuchowski, Wasyl Badyra, Kacper Bober, Kacper Rogala, Kacper Knitter, Mikołaj Badocha, Sebastian Cygert
  date: 08.11.2024
  time: 11:35 - 12:00
  room: B
  session: CfC Session 2
  id: 6
  author-image: images/optimized/cfc-600x600/barbara_klaudel.webp

- author-name: Marek Justyna
  title: "RNAgrail: GRAph neural network and diffusIon modeL for RNA 3D structure prediction"
  author-title: "Poznan University of Technology"
  abstract: >- 
    Accurate prediction of RNA 3D structures is crucial for understanding its diverse biological functions, yet current methods face significant challenges due to the limited availability of high-resolution RNA structures and the inherent data imbalance. Traditional approaches, such as those inspired by AlphaFold, rely heavily on multiple sequence alignment and template-based strategies, which are hindered by the scarcity of RNA data. To address these limitations, we propose a novel method combining Graph Neural Networks (GNNs) with generative diffusion models for RNA 3D structure prediction. Unlike existing methods that attempt to predict entire RNA structures, our approach focuses on predicting local RNA descriptors, which allows for more precise modeling of RNA’s complex secondary and tertiary interactions. By leveraging the structural and relational properties encoded in these local descriptors, our model can generate high-quality RNA structures even in the absence of extensive sequence data or templates. This method represents a significant departure from the traditional template-based models and has demonstrated superior performance in preliminary evaluations, particularly in cases where data is sparse. Our results suggest that this innovative approach not only addresses the current limitations in RNA 3D structure prediction but also opens new avenues for the application of machine learning in structural biology. We believe that this methodology could serve as a robust alternative to current state-of-the-art techniques, providing more reliable predictions and advancing our understanding of RNA structure and function.
  author-bio: >- 
    He is a PhD student supported by the prestigious PRELUDIUM BIS grant funded by the Polish National Science Center. His main interests lie in applying AI techniques to solve complex biological problems, with a particular focus on structural biology. His current research under this grant is dedicated to advancing the use of generative models in RNA 3D structure prediction.
  co-authors:
  date: 08.11.2024
  time: 14:30 - 14:55
  room: Main
  session: CfC Session 3
  id: 7
  author-image: images/optimized/cfc-600x600/marek_justyna.webp

- author-name: Krzysztof Maziarz
  title: "Fake it till you make it: planning chemical syntheses for drug discovery"
  author-title: "Microsoft Research"
  abstract: >- 
    Recent advances in Deep Learning are powering increasingly sophisticated generative models for the design of novel drugs, but these imagined molecules are only useful if we can synthesize them. In this talk, I will dive into our recent results on retrosynthesis, which is the task of coming up with “recipes” describing how a given molecule can be made in the lab. This requires first building a bespoke model to predict “single-step” chemical reactions, where we utilize a mix of symbolic and learned components, including graph rewriting transformations, Transformers, and Graph Neural Networks. The model is then combined with a planning algorithm akin to A* search, in order to find plausible trees of reactions describing how to synthesize a drug of interest from simple molecules that are commercially available. Finally, I will also connect this to our larger effort in Drug Discovery, and more broadly AI for Science, fuelled by a five-year collaboration between Microsoft Research and Novartis.
  author-bio: >- 
    Krzysztof is a Senior Researcher in the AI for Science team at Microsoft Research, where he works on applying Deep Learning to problems in Drug Discovery. Among other things, he has developed generative models of molecular graphs, few-shot molecular property prediction methods, and planning algorithms for sequences of chemical reactions. These works not only led to 4 publications at top ML conferences but also to application in a pharma company, with 150+ molecules proposed by his generative models successfully synthesised and tested in a lab. Before joining Microsoft nearly five years ago, Krzysztof studied Theoretical Computer Science, and was a serial intern (including three research internships at Google). Before settling on Deep Learning, he also had decent success in competitive programming, advancing to finals of ACM ICPC, Facebook HackerCup and Distributed Google CodeJam.
  co-authors:
  date: 08.11.2024
  time: 15:00 - 15:25
  room: Main
  session: CfC Session 3
  id: 8
  author-image: images/optimized/cfc-600x600/krzysztof_maziarz.webp

- author-name: France ROSE
  title: "Uncertainty-aware self-supervised learning on multi-dimensional time series for animal behavior"
  author-title: "University of Cologne"
  abstract: >- 
    Studying freely moving animals is essential to understand how animals behave and make decisions -- e.g. when they escape predators, find mates, or raise their young -- in an undisturbed manner. Although animal behavior has been studied for decades, animal movements can only now be recorded at high throughput thanks to recent technical progress. On one hand, videos from synchronized cameras can be coupled with deep learning pose estimation methods, automatically tracking the trajectories of a few keypoints. On the other hand, motion capture systems directly outputs the 3D trajectories of physical reflectors apposed on the body (reflectors on a suit for humans, reflecting piercings for rodents). However, these methods are not perfect and contain missing data. Since animal behavior cannot be easily scripted and additional recordings are not always possible due to constraints in experimental design, missing data is a more pressing problem in animal compared to human behavior analysis. So far, few works have effectively addressed these issues in animal recordings, with most relying on linear interpolation and smoothing (e.g. Kalman filter) only suitable for short gaps, or lacking large-scale testing.   We hypothesized that recent advances in deep learning architectures and self-supervised learning (SSL) can help recover missing data by learning dynamics within and between keypoints. Specifically masked modeling has proven to be successful in recent large language models and computer vision transformers.  Mimicking the missing data during training via masked modeling, we tested several neural network architectures: Gated Recurrent Unit (GRU), Temporal Convolutional network (TCN), Spatio-Temporal Graph Convolutional Network (ST-GCN), Space-Time-Separable Graph Convolutional Network (STS-GCN), and a custom transformer encoder named DISK (Deep Imputation for Skeleton data). For testing, we gathered seven datasets, covering five species (human, fly, mouse, rat, fish), in 2D and 3D, from one to two animals, and a variety of number of keypoints (from 3 to 38 per animal). Furthermore we adapted a probabilistic head, initially proposed for probabilistic forecasting of time-series, to assess the reliability of the imputed data at inference time.   We found that DISK outperformed other architectures and linear interpolation baseline (42% to 89% root mean square error improvement compared to linear interpolation, calculated between true coordinates and imputed ones on a held-out test set - one value per dataset). DISK probabilistic head outputs an estimated error linearly correlated with the real error (Pearson correlation coefficient: 0.746 to 0.890 - one value per dataset). This estimated error allows to filter out less reliable predictions and control the amount of noise in the imputed dataset.  As SSL methods are known to learn general properties about input data, we further explored the latent space of DISK and showed motion sequences clustered by behavior categories (e.g. attack, mount, investigation).   While animal behavior experiments are expensive and complex, tracking errors make sometimes large portions of the experimental data unusable. DISK allows for filling in the missing information and for taking full advantage of the rich behavioral data. Available as a stand-alone imputation package (github.com/bozeklab/DISK.git), DISK is applicable to results of any tracking method (cameras or motion capture) and allows for any type of downstream an
  author-bio: >- 
    I am France ROSE (she/her), a post-doctoral researcher at the University Hospital of Cologne. My research topics cover biomedical image and time-series analysis. At the time of exploding data generation in Biology and Medical Sciences, it is exciting to meet the needs in image analysis and challenge current scientific knowledge.
  co-authors: Monika Michaluk, Timon Blindauer, Bogna M. Ignatowska-Jankowska, Liam O’Shaughnessy, Greg J. Stephens, Talmo D. Pereira, Marylka Y. Uusisaari, Katarzyna Bozek
  date: 08.11.2024
  time: 15:30 - 15:55
  room: Main
  session: CfC Session 3
  id: 9
  author-image: images/optimized/cfc-600x600/france_rose.webp

- author-name: Natasha Alkhatib
  title: "How LLMs are Revolutionizing the cybersecurity field"
  author-title: "Cybersecurity and AI researcher"
  abstract: >- 
    The ever-evolving threat landscape demands constant adaptation. Traditional methods struggle. Large Language Models (LLMs) emerge, wielding the power of language. This talk explores LLMs' revolution in cybersecurity.  LLMs are AI models trained on massive text and code datasets. This grants them an understanding of complex linguistic patterns, invaluable in cybersecurity. Firstly, LLMs excel at advanced threat detection. Analyzing vast amounts of data, they identify subtle anomalies indicating brewing attacks. Traditional methods rely on pre-defined rules, vulnerable to novel attack vectors. LLMs, with their ability to learn and adapt, identify unseen threats, providing a crucial early warning system.  Secondly, LLMs offer proactive threat analysis. By ingesting vast quantities of threat intelligence data, including past attack methods and attacker motivations, LLMs uncover patterns and predict future attack vectors. This allows security teams to take a pre-emptive approach, focusing resources on fortifying potential weaknesses  before attackers exploit them. Imagine an LLM analyzing a hacker forum, identifying discussions about targeting a specific software vulnerability. This foresight empowers security professionals to patch the vulnerability before a widespread breach.  Furthermore, LLMs can revolutionize vulnerability research . Traditionally, identifying vulnerabilities is time-consuming and laborious. LLMs, with their ability to analyze vast code repositories, pinpoint potential vulnerabilities through code patterns and language constructs associated with known weaknesses. This streamlines the vulnerability discovery process, allowing security teams to address critical issues  before attackers identify them.  While LLMs offer a powerful new frontier, challenges remain. Issues surrounding explainability, bias in training data, and potential misuse require careful consideration. However, the potential benefits are undeniable. As these models continue to evolve and integrate with existing security solutions, they hold the promise of a more secure and resilient digital landscape.
  author-bio: >- 
    Dr.Natasha Alkhatib  Researcher & Engineer - Cybersecurity & AI for Automotive  Dr.Natasha Alkhatib is a researcher and engineer with expertise in cybersecurity and artificial intelligence (AI) for the automotive industry. Her passion for securing vehicles against cyber threats led her to pursue a Ph.D. thesis at the prestigious Institut Polytechnique de Paris. Her doctoral research focused on leveraging AI to develop robust solutions against cyberattacks in connected and autonomous vehicles. Currently, Dr.Natasha Alkhatib applies her expertise at ETAS Bosch, a leading provider of embedded systems for the automotive industry.  In this role, she is instrumental in developing AI-based solutions that enhance the cybersecurity of automotive products.  She plays a key role in ensuring the safety and security of future generations of vehicles.
  co-authors:
  date: 08.11.2024
  time: 14:30 - 14:55
  room: A
  session: CfC Session 4
  id: 10
  author-image: images/optimized/cfc-600x600/natasha_alkhatib.webp

- author-name: Klaudia Bałazy
  title: "Efficient Fine-Tuning of LLMs: Exploring PEFT Methods and LoRA-XS Insights"
  author-title: "NVIDIA | Jagiellonian University"
  abstract: >- 
    The rapid scaling of large language models (LLMs) has underscored the need for parameter-efficient fine-tuning (PEFT) methods to manage increasing computational and storage demands. Among these methods, Low-Rank Adaptation (LoRA) has emerged as a prominent solution, often matching or exceeding the performance of full fine-tuning with significantly fewer parameters. Despite its success, LoRA faces challenges related to the storage of numerous task-specific or user-specific modules on top of a base model.  In this talk, I will discuss the importance of parameter-efficient fine-tuning in natural language processing (NLP) and provide an overview of various PEFT approaches for large language models. I will introduce our latest research, LoRA-XS (Low-Rank Adaptation with eXtremely Small number of parameters), which leverages Singular Value Decomposition (SVD) to further enhance parameter efficiency. I will also highlight emerging trends and future possibilities in efficient fine-tuning.
  author-bio: >- 
    Klaudia Bałazy is a Senior Deep Learning Engineer at NVIDIA and a PhD student at the Jagiellonian University. She is also an active member of the Group of Machine Learning Research (GMUM). Her research primarily focuses on enhancing the efficiency of deep learning solutions, with particular emphasis on model compression, dynamic neural networks, and the parameter efficiency of large language models. Klaudia holds both a Master's and an Engineer's degree in Computer Science from the AGH University of Science and Technology. Throughout her career, she has led and participated in various AI-based projects across several tech startups, contributing to the development of practical AI applications.
  co-authors: Mohammadreza Banaei, Karl Aberer, Jacek Tabor
  date: 08.11.2024
  time: 15:00 - 15:25
  room: A
  session: CfC Session 4
  id: 11
  author-image: images/optimized/cfc-600x600/klaudia_balazy.webp

- author-name: Adam Dziedzic
  title: "Open LLMs are Necessary for Private Adaptations and Outperform their Closed Alternatives"
  author-title: "CISPA Helmholtz Center for Information Security"
  abstract: >- 
    While open Large Language Models (LLMs) have made significant progress, they still fall short of matching the performance of their closed, proprietary counterparts, making the latter attractive even for the use on highly private data. Recently, various new methods have been proposed to adapt closed LLMs to private data without leaking private information to third parties and/or the LLM provider. In this talk, we will analyze the privacy protection and performance of the four most recent methods for private adaptation of closed LLMs. By examining their threat models and thoroughly comparing their performance under different privacy levels according to differential privacy (DP), various LLM architectures, and multiple datasets for classification and generation tasks, we found that: (1) all the methods leak query data, i.e., the (potentially sensitive) user data that is queried at inference time, to the LLM provider, (2) three out of four methods also leak large fractions of private training data to the LLM provider while the method that protects private data requires a local open LLM, (3) all the methods exhibit lower performance compared to three private gradient-based adaptation methods for local open LLMs, and (4) the private adaptation methods for closed LLMs incur higher monetary training and query costs than running the alternative methods on local open LLMs. This yields the conclusion that to achieve truly privacy-preserving LLM adaptations that yield high performance and more privacy at lower costs, one should use open LLMs.
  author-bio: >- 
    Adam is a Tenure Track Faculty Member at CISPA Helmholtz Center for Information Security, co-leading the SprintML group. His research is focused on secure and trustworthy Machine Learning as a Service (MLaaS). Adam designs robust and reliable machine learning methods for training and inference of ML models while preserving data privacy and model confidentiality. Adam was a Postdoctoral Fellow at the Vector Institute and the University of Toronto, and a member of the CleverHans Lab, advised by Prof. Nicolas Papernot. He earned his PhD at the University of Chicago, where he was advised by Prof. Sanjay Krishnan and worked on input and model compression for adaptive and robust neural networks. Adam obtained his Bachelor's and Master's degrees from Warsaw University of Technology in Poland. He was also studying at DTU (Technical University of Denmark) and carried out research at EPFL, Switzerland. Adam also worked at CERN (Geneva, Switzerland), Barclays Investment Bank in London (UK), Microsoft Research (Redmond, USA), and Google (Madison, USA).
  co-authors: Franziska Boenisch
  date: 08.11.2024
  time: 15:30 - 15:55
  room: A
  session: CfC Session 4
  id: 12
  author-image: images/optimized/cfc-600x600/adam_dziedzic.webp

- author-name: Kamil Deja
  title: "Personalisation of large-scale diffusion models"
  author-title: "Warsaw University of Technology/IDEAS NCBR"
  abstract: >- 
    -Mum, Can we have a diffusion model?  -We have a diffusion model at home!  Diffusion model at home: Well, come and listen :)  In this talk, I will discuss recent advances in large-scale diffusion model personalisation methods. I will overview and explain techniques for finetuning off-the-shelf models to generate images with desired concepts or styles, starting from naive finetuning through low-rank adaptation to data-free model editing techniques. On top of adding new concepts to the existing model, I will outline state-of-the-art unlearning approaches that allow for the precise removal of unwanted content.
  author-bio: >- 
    Kamil Deja is a postdoctoral researcher at IDEAS NCBR and Warsaw University of Technology where he obtained a Ph.D. His research focuses on Generative Modelling with applications to Continual Learning. He has previously interned at Virje Universiteit in Amsterdam and twice at Amazon Alexa. His research work has been published in prestigious conferences such as NeurIPS, IJCAI, and Interspeech. In recognition of his accomplishments, Kamil received the FNP Start scholarship in 2023, awarded to the top-100 young researchers in Poland.
  co-authors:
  date: 08.11.2024
  time: 14:30 - 14:55
  room: B
  session: CfC Session 5
  id: 13
  author-image: images/optimized/cfc-600x600/kamil_deja.webp

- author-name: Dawid Rymarczyk
  title: "Current trends in intrinsically interpretable deep learning"
  author-title: "Jagiellonian University; Ardigen SA"
  abstract: >- 
    The talk will focus on intrinsically interpretable deep learning models, where the transparent reasoning process is integral to the prediction, eliminating the need for an explainer to interpret the results. I will discuss current trends in this field, including continual learning of these models using prototypical parts architecture (Rymarczyk@ICCV2023), the limitations of prototypical parts in their interpretations (Sacha@AAAI2024, Ma@NeurIPS2023, Pach@arxiv2024), and ways to involve users in interacting with interpretations to create more reliable models (Kim@ECCV2022, Bontempelli@ICLR2023).
  author-bio: >- 
    In 2024, I earned a PhD with distinction in a topic related to interpretable neural networks. Since 2017, I have been working as a Data Scientist at Ardigen, where I was recently promoted to Director of Data Science and Lead Data Scientist. My research interests include computer vision, prototypical parts for deep learning architectures, and AI applications in the drug discovery process. I am actively involved in publishing and collaborating with the GMUM and SINN research groups. Additionally, I completed an internship with Dr. Joost van de Weijer's group and attended the International Computer Vision Summer School (ICVSS).
  co-authors:
  date: 08.11.2024
  time: 15:00 - 15:25
  room: B
  session: CfC Session 5
  id: 14
  author-image: images/optimized/cfc-600x600/dawid_rymarczyk.webp

- author-name: Przemysław Spurek
  title: "Neural rendering: the future of 3D modeling"
  author-title: "Jagiellonian University"
  abstract: >- 
    The presentation will present the central concept of neural rendering for modeling 3D objects. We concentrate on Neural Radiation Fields (NeRFs) and Gaussian Splatting (GS). Then, new results obtained by the GMUM Neural Rendering group will be presented. NeRF has demonstrated the remarkable potential of neural networks to capture the intricacies of 3D objects. NeRFs excel at producing strikingly sharp novel views of 3D objects by encoding the shape and color information within neural network weights. Recently, numerous generalizations of NeRFs utilizing generative models have emerged, expanding its versatility. In contrast, GS offers a similar render quality with faster training and inference, as it does not need neural networks to work. It encodes information about the 3D objects in the set of Gaussian distributions that can be rendered in 3D similarly to classical meshes.
  author-bio: >- 
    Przemysław Spurek is the leader of the Neural Rendering research team at IDEAS NCBR and a researcher in the GMUM group operating at the Jagiellonian University in Krakow. In 2014, he defended his PhD in machine learning and information theory. In 2023, he obtained his habilitation degree and became a university professor. He has published articles at prestigious international conferences such as NeurIPS, ICML, IROS, AISTATS, ECML. He co-authored the book Głębokie uczenie. Wprowadzenie [Deep Learning. Introduction] – a compendium of knowledge about the basics of AI. He was the director of PRELUDIUM, SONATA, OPUS and SONATA BIS NCN grants. Currently, his research focuses mainly on neural rendering, in particular NeRF and Gaussian Splatting models.
  co-authors: Joanna Waczyńska, Piotr Borycki, Weronika Smolak, Dawid Malarz
  date: 08.11.2024
  time: 15:30 - 15:55
  room: B
  session: CfC Session 5
  id: 15
  author-image: images/optimized/cfc-600x600/przemyslaw_spurek.webp

- author-name: Franziska Boenisch
  title: "Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models"
  author-title: "CISPA Helmholtz Center for Information Security"
  abstract: >- 
    Diffusion models (DMs) produce very detailed and high-quality images. Their power results from extensive training on large amounts of data usually scraped from the internet without proper attribution or consent from content creators. Unfortunately, this practice raises privacy and intellectual property concerns, as DMs can memorize and later reproduce their potentially sensitive or copyrighted training images at inference time. Prior efforts prevent this issue by either changing the input to the diffusion process, thereby preventing the DM from generating memorized samples during inference or removing the memorized data from training altogether. While those are viable solutions when the DM is developed and deployed in a secure and constantly monitored environment, they hold the risk of adversaries circumventing the safeguards and are not effective when the DM itself is publicly released. To solve the problem, we introduce NeMo, the first method to localize the memorization of individual data samples down to the level of neurons in DMs' cross-attention layers. Through our experiments, we make the intriguing finding that in many cases, single neurons are responsible for memorizing particular training samples. By deactivating these memorization neurons, we can avoid the replication of training data at inference time, increase the diversity in the generated outputs, and mitigate the leakage of private and copyrighted data. In this way, our NeMo contributes to a more responsible deployment of DMs.
  author-bio: >- 
    Franziska is a tenure-track faculty at the CISPA Helmholtz Center for Information Security where she co-leads the SprintML lab. Before, she was a Postdoctoral Fellow at the University of Toronto and Vector Institute advised by Prof. Nicolas Papernot. Her current research centers around private and trustworthy machine learning. Franziska obtained her Ph.D. at the Computer Science Department at Freie University Berlin, where she pioneered the notion of individualized privacy in machine learning. During her Ph.D., Franziska was a research associate at the Fraunhofer Institute for Applied and Integrated Security (AISEC), Germany. She received a Fraunhofer TALENTA grant for outstanding female early career researchers, the German Industrial Research Foundation prize for her research on machine learning privacy, and the Fraunhofer ICT Dissertation Award 2023, and was named a GI-Junior Fellow in 2024.
  co-authors: Dominik Hintersdorf, Lukas Struppek, Kristian Kersting, Adam Dziedzic
  date: 09.11.2024
  time: 12:00 - 12:25
  room: Main
  session: CfC Session 6
  id: 16
  author-image: images/optimized/cfc-600x600/franziska_boenisch.webp

- author-name: Jan Dubiński
  title: "CDI: Copyrighted Data Identification in Diffusion Models"
  author-title: "Warsaw University of Technology; IDEAS NCBR"
  abstract: >- 
    Diffusion Models (DMs) benefit from large and diverse datasets for their training. Since this data is often scraped from the internet without permission from the data owners, this raises concerns about copyright and intellectual property protections. While (illicit) use of data is easily detected for training samples perfectly re-created by a DM at inference time, it is much harder for data owners to verify if their data was used for training when the outputs from the suspect DM are not close replicas. Conceptually, membership inference attacks (MIAs), which detect if a given data point was used during training, present themselves as a suitable tool to address this challenge. However, we demonstrate that existing MIAs are ineffective in determining the membership of individual images in large DMs. To overcome this limitation, we propose Copyrighted Data Identification (CDI), a framework for data owners to identify whether their dataset was used to train a given DM. CDI relies on dataset inference techniques, i.e., instead of using the membership signal from a single data point, CDI leverages the fact that most data owners, such as providers of stock photography, visual media companies, or even individual artists, own datasets with multiple publicly exposed data points which might all be included in the training of a given DM. By selectively aggregating signals from existing MIAs and using new handcrafted methods to extract features for these datasets, feeding them to a scoring model, and applying rigorous statistical testing, CDI allows data owners with as little as 70 data points to identify with a confidence of more than 99% whether their data was used to train a DM. Thereby, CDI represents a valuable tool for data owners to claim illegitimate use of their copyrighted data.
  author-bio: >- 
    Jan Dubiński is pursuing a PhD in deep learning at the Warsaw University of Technology. He is a member of the ALICE Collaboration at LHC CERN. Jan has been working on fast simulation methods for High Energy Physics experiments at the Large Hadron Collider at CERN. The methods developed in this research leverage generative deep learning models such as GANs to provide a computationally efficient alternative to existing Monte Carlo-based methods. More recently, he has focused on issues related to the security of machine learning models and data privacy. His latest efforts aim to improve the security of self-supervised and generative methods, which are often overlooked compared to supervised models.
  co-authors: Antoni Kowalczuk; Franziska Boenisch; Adam Dziedzic
  date: 09.11.2024
  time: 12:30 - 12:55
  room: Main
  session: CfC Session 6
  id: 17
  author-image: images/optimized/cfc-600x600/jan_dubinski.webp

- author-name: Bartlomiej Sobieski
  title: "Global Counterfactual Directions"
  author-title: "MI2.ai, University of Warsaw"
  abstract: >- 
    Explaining the decision-making process of image classifiers is a long-standing problem for which, as of today's state of knowledge, no ultimate solution exists. Counterfactual explanations aim to provide such explanation by presenting the user with the answer to a specific what-if question, such as "what would be the hair color classifier's decision if the eye color changed". Crucially, this type of explanation stands at the highest level of Pearl’s causality ladder as they help humans in identifying the cause-effect relations of the model’s decision and its input. However, constructing these explanations is extremely difficult, as they require precise control over the image content conditioned on the model's inference process. Therefore, previous works made strong assumptions about the model's availability, e.g. so-called white-box access which assumes that one can utilize fully the classifier's gradients. Unfortunately, this scenario is often not observed in practice. Many models, such as the latest ChatGPT, allow only black-box access, i.e. observing only the input and the model's output through an API.  In this work, we propose a novel state-of-the-art solution to finding visual counterfactual explanations in a black-box scenario. We discover a remarkable property of Diffusion Autoencoders, a type of diffusion model, whose latent space encodes the decision-making process of a classifier in a form of global directions. Despite assuming black-box access to the model of interest, our method finds these directions using only a single image, which allows for limiting the generation of explanations to pure inference of the generative model. In addition, we show that the nature of our approach can be utilized to improve the understanding of the explanations themselves by extending the Latent Integrated Gradients method to black-box case. Overall, our method pushes the boundaries of explaining models with greatly limited access, while also shedding light at interesting properties of Diffusion Autoencoders.  This work has been accepted as a conference paper on the upcoming European Conference on Computer Vision (ECCV) 2024, rated as A* conference in the CORE ranking.  Paper link: https://arxiv.org/abs/2404.12488
  author-bio: >- 
    I am an AI researcher passionate about combining image generative models and explainable computer vision. I believe that highly advanced mathematics is the key for developing better AI models and explaining their decision-making process.
  co-authors: Przemysław Biecek
  date: 09.11.2024
  time: 13:00 - 13:25
  room: Main
  session: CfC Session 6
  id: 18
  author-image: images/optimized/cfc-600x600/bartlomiej_sobieski.webp

- author-name: Michał Bortkiewicz
  title: "Accelerating Goal-Conditioned RL Algorithms and Research"
  author-title: "Warsaw University of Technology"
  abstract: >- 
    Self-supervision has the potential to transform reinforcement learning (RL), paralleling the breakthroughs it has enabled in other areas of machine learning. While self-supervised learning in other domains aims to find patterns in a fixed dataset, self-supervised goal-conditioned reinforcement learning (GCRL) agents discover new behaviors by learning from the goals achieved during unstructured interaction with the environment. However, these methods have failed to see similar success, both due to a lack of data from slow environments as well as a lack of stable algorithms. We take a step toward addressing both of these issues by releasing a high-performance codebase and benchmark JaxGCRL for self-supervised GCRL, enabling researchers to train agents for millions of environment steps in minutes on a single GPU. The key to this performance is a combination of GPU-accelerated environments and a stable, batched version of the contrastive reinforcement learning algorithm, based on an infoNCE objective, that effectively makes use of this increased data throughput. With this approach, we provide a foundation for future research in self-supervised GCRL, enabling researchers to quickly iterate on new ideas and evaluate them in a diverse set of challenging environments.
  author-bio: >- 
    Michał Bortkiewicz is a PhD student at Warsaw University of Technology, where his research centres on Continual and Reinforcement Learning. As a data scientist, he advises companies on implementing deep learning methods for data-intensive tasks. Michał has previously worked as a deep learning engineer at Samsung Research, focusing on audio intelligence projects, at Scope Fluidics, where he specialized in computer vision, and at Airspace Intelligence, where he dealt with tabular machine learning.
  co-authors: Michał Bortkiewicz, Władek Pałucki, Vivek Myers, Tadeusz Dziarmaga, Tomasz Arczewski, Łukasz Kuciński, Benjamin Eysenbach
  date: 09.11.2024
  time: 12:00 - 12:25
  room: A
  session: CfC Session 7
  id: 19
  author-image: images/optimized/cfc-600x600/michal_bortkiewicz.webp

- author-name: Bartłomiej Cupiał
  title: "Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem"
  author-title: "University of Warsaw / IDEAS NCBR"
  abstract: >- 
    Fine-tuning is a widespread technique that allows practitioners to transfer pre-trained capabilities, as recently showcased by the successful applications of foundation models. However, fine-tuning reinforcement learning (RL) models remains a challenge. This work conceptualizes one specific cause of poor transfer, accentuated in the RL setting by the interplay between actions and observations: forgetting of pre-trained capabilities. Namely, a model deteriorates on the state subspace of the downstream task not visited in the initial phase of fine-tuning, on which the model behaved well due to pre-training. This way, we lose the anticipated transfer benefits. We identify conditions when this problem occurs, showing that it is common and, in many cases, catastrophic. Through a detailed empirical analysis of the challenging NetHack and Montezuma's Revenge environments, we show that standard knowledge retention techniques mitigate the problem and thus allow us to take full advantage of the pre-trained capabilities. In particular, in NetHack, we achieve a new state-of-the-art for neural models, improving the previous best score from 5K to over 10K points in the Human Monk scenario.
  author-bio: >- 
    Bartłomiej Cupiał is a PhD student at IDEAS NCBR and the University of Warsaw. He finished his master's degree at Jagiellonian University and bachelor's degree at Wrocław University of Science and Technology. Currently, he is working on combining reinforcement learning with large language models.  In particular, how to improve exploration in RL with the help of LLMs and how to integrate external knowledge into RL agents.
  co-authors: Maciej Wołczyk, Mateusz Ostaszewski, Michał Bortkiewicz, Michał Zając, Razvan Pascanu, Łukasz Kuciński, Piotr Miłoś
  date: 09.11.2024
  time: 12:30 - 12:55
  room: A
  session: CfC Session 7
  id: 20
  author-image: images/optimized/cfc-600x600/bartlomiej_cupial.webp

- author-name: Adam Pardyl
  title: "AdaGlimpse: Active Visual Exploration with Arbitrary Glimpse Position and Scale"
  author-title: "IDEAS NCBR; Jagiellonian University"
  abstract: >- 
    Active Visual Exploration (AVE) is a task that involves dynamically selecting observations (glimpses), which is critical to facilitate comprehension and navigation within an environment. While modern AVE methods have demonstrated impressive performance, they are constrained to fixed-scale glimpses from rigid grids. In contrast, existing mobile platforms equipped with optical zoom capabilities can capture glimpses of arbitrary positions and scales. To address this gap between software and hardware capabilities, we introduce AdaGlimpse. It uses Soft Actor-Critic, a reinforcement learning algorithm tailored for exploration tasks, to select glimpses of arbitrary position and scale. This approach enables our model to rapidly establish a general awareness of the environment before zooming in for detailed analysis. Experimental results demonstrate that AdaGlimpse surpasses previous methods across various visual tasks while maintaining greater applicability in realistic AVE scenarios.
  author-bio: >- 
    Researcher @ Sustainable Machine Learning For Autonomous Machines team, IDEAS NCBR PhD candidate @ GMUM, UJ
  co-authors: Michał Wronka, Maciej Wołczyk, Kamil Adamczewski, Tomasz Trzciński, Bartosz Zieliński
  date: 09.11.2024
  time: 13:00 - 13:25
  room: A
  session: CfC Session 7
  id: 21
  author-image: images/optimized/cfc-600x600/adam_pardyl.webp

- author-name: Tomasz Piotrowski
  title: "Fixed points of nonnegative neural networks"
  author-title: "Nicolaus Copernicus University in Toruń"
  abstract: >- 
    We use fixed point theory to analyze nonnegative neural networks, which we define as neural networks that map nonnegative vectors to nonnegative vectors. We first show that nonnegative neural networks with nonnegative weights and biases can be recognized as monotonic and (weakly) scalable mappings within the framework of nonlinear Perron-Frobenius theory. This fact enables us to provide conditions for the existence of fixed points of nonnegative neural networks having inputs and outputs of the same dimension, and these conditions are weaker than those recently obtained using arguments in convex analysis. Furthermore, we prove that the shape of the fixed point set of nonnegative neural networks with nonnegative weights and biases is an interval, which under mild conditions degenerates to a point. These results are then used to obtain the existence of fixed points of more general nonnegative neural networks. From a practical perspective, our results contribute to the understanding of the behavior of autoencoders, and we also offer valuable mathematical machinery for future developments in deep equilibrium models.
  author-bio: >- 
    Tomasz Piotrowski received the M.Sc. degree in Mathematics from SilesianUniversity of Technology, Poland, in 2004, the M.Sc. degree in Information Processing & Neural Networks from King’s College London, UK, in 2005, the Ph.D. degree from Tokyo Institute of Technology, Japan, in 2008, and the D.Sc. degree from Systems Research Institute, Polish Academy of Sciences, in 2021.  From 2009 to 2010 he worked in industry as a data analyst at Comarch SA. In 2011, he joined Nicolaus Copernicus University (NCU) in Toruń, Poland as an Assistant Professor. Since 2022, he is an Associate Professor at NCU. He is involved in brain research, signal processing, and mathematical foundations of deep learning.
  co-authors: R L G Cavalcante, M Gabor
  date: 09.11.2024
  time: 12:00 - 12:25
  room: B
  session: CfC Session 8
  id: 22
  author-image: images/optimized/cfc-600x600/tomasz_piotrowski.webp

- author-name: Marcin Przewięźlikowski
  title: "Augmentation-aware Self-supervised Learning with Conditioned Projector"
  author-title: "GMUM (Jagiellonian University) / IDEAS NCBR"
  abstract: >- 
    Self-supervised learning (SSL) is a powerful technique for learning robust representations from unlabeled data. By learning to remain invariant to applied data augmentations, methods such as SimCLR and MoCo are able to reach quality on par with supervised approaches. However, this invariance may be harmful to solving some downstream tasks which depend on traits affected by augmentations used during pretraining, such as color. In this paper, we propose to foster sensitivity to such characteristics in the representation space by modifying the projector network, a common component of self-supervised architectures. Specifically, we supplement the projector with information about augmentations applied to images. In order for the projector to take advantage of this auxiliary conditioning when solving the SSL task, the feature extractor learns to preserve the augmentation information in its representations. Our approach, coined Conditional Augmentation-aware Self-supervised Learning (CASSLE), is directly applicable to typical joint-embedding SSL methods regardless of their objective functions. Moreover, it does not require major changes in the network architecture or prior knowledge of downstream tasks. In addition to an analysis of sensitivity towards different data augmentations, we conduct a series of experiments, which show that CASSLE improves over various SSL methods, reaching state-of-the-art performance in multiple downstream tasks.
  author-bio: >- 
    Marcin Przewięźlikowski is a PhD Student with Group of Machine Learning Research at Jagiellonian University in Kraków, Poland, and IDEAS NCBR. He is interested in data-effciency and works on topics such as Meta-Learning and Self-Supervised Learning.
  co-authors: Mateusz Pyla, Bartosz Zieliński, Bartłomiej Twardowski, Jacek Tabor, Marek Śmieja
  date: 09.11.2024
  time: 12:30 - 12:55
  room: B
  session: CfC Session 8
  id: 23
  author-image: images/optimized/cfc-600x600/marcin_przewiezlikowski.webp

- author-name: Omar Rivasplata
  title: "Meta-analysis of Bayesian Analyses"
  author-title: "University of Manchester"
  abstract: >- 
    Meta-analysis aims to generalize results from multiple related statistical analyses through a combined analysis. While the natural outcome of a Bayesian study is a posterior distribution, traditional Bayesian meta-analyses proceed by combining summary statistics (i.e. point-valued estimates) computed from data. In this talk, I will present work with collaborators proposing a framework for combining posterior distributions from multiple related Bayesian studies into a meta-analysis. Importantly, the method is capable of reusing pre-computed posteriors from computationally costly analyses, without needing the implementation details from each study. Besides providing a consensus across studies, the method enables updating the local posteriors post-hoc and therefore refining them by sharing statistical strength between the studies, without rerunning the original analyses. The wide applicability of the framework is illustrated by combining results from likelihood-free Bayesian analyses, which would be difficult to carry out using standard methodology.
  author-bio: >- 
    My top-level topics of interest are statistical learning theory and machine learning theory. In the limit of tending to praxis, these days I am very interested in strategies to train and certify machine learning models.   Currently I am Senior Lecturer (Associate Professor) in Machine Learning in the Department of Computer Science at The University of Manchester, where I am a member of the Manchester Centre for AI Fundamentals and a supervisor at the UKRI AI CDT in Decision-Making for Complex Systems.  Before joining The University of Manchester (July 2024), I had positions at University College London and DeepMind. I have a PhD in Mathematics (University of Alberta, 2012) and a PhD in Statistical Learning Theory (University College London, 2022).   Back in the day I studied undergraduate maths (BSc 2000, Pontificia Universidad Católica del Perú).
  co-authors: Paul Blomstedt, Diego Mesquita, Yours Truly, Jarno Lintusaari, Tuomas Sivula, Jukka Corander, Samuel Kaski
  date: 09.11.2024
  time: 13:00 - 13:25
  room: B
  session: CfC Session 8
  id: 24
  author-image: images/optimized/cfc-600x600/omar_rivasplata.webp

